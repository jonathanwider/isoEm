{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Output/Reproduce_new\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 matching runs found\n",
      "Loss: Masked_MSELoss, CoordConv: True, CylindricalPadding: True, R2 = nan +/- nan\n",
      "0 matching runs found\n",
      "Loss: Masked_MSELoss, CoordConv: True, CylindricalPadding: False, R2 = nan +/- nan\n",
      "10 matching runs found\n",
      "Loss: Masked_MSELoss, CoordConv: False, CylindricalPadding: True, R2 = 0.217 +/- 0.009\n",
      "10 matching runs found\n",
      "Loss: Masked_MSELoss, CoordConv: False, CylindricalPadding: False, R2 = 0.213 +/- 0.010\n",
      "0 matching runs found\n",
      "Loss: Masked_AreaWeightedMSELoss, CoordConv: True, CylindricalPadding: True, R2 = nan +/- nan\n",
      "0 matching runs found\n",
      "Loss: Masked_AreaWeightedMSELoss, CoordConv: True, CylindricalPadding: False, R2 = nan +/- nan\n",
      "0 matching runs found\n",
      "Loss: Masked_AreaWeightedMSELoss, CoordConv: False, CylindricalPadding: True, R2 = nan +/- nan\n",
      "0 matching runs found\n",
      "Loss: Masked_AreaWeightedMSELoss, CoordConv: False, CylindricalPadding: False, R2 = nan +/- nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldap-server/firenze/venv/GrouPyTorch/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/ldap-server/firenze/venv/GrouPyTorch/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/ldap-server/firenze/venv/GrouPyTorch/lib/python3.8/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ldap-server/firenze/venv/GrouPyTorch/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/ldap-server/firenze/venv/GrouPyTorch/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for loss in [\"Masked_MSELoss\", \"Masked_AreaWeightedMSELoss\"]:\n",
    "    for use_coord_conv in [True, False]:\n",
    "        for use_cylindrical_padding in [True, False]:\n",
    "            conditions = {\n",
    "                \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"tsurf\": [\"tsurf\"],\n",
    "                                                                 \"prec\": [\"prec\"]},\n",
    "                                        \"PRECIP_WEIGHTING\" : False\n",
    "                                       },\n",
    "                \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\",\n",
    "                                              \"USE_COORD_CONV\": use_coord_conv,\n",
    "                                              \"USE_CYLINDRICAL_PADDING\": use_cylindrical_padding,\n",
    "                                              \"LOSS\": loss,\n",
    "                                              \"LEARNING_RATE\": 5e-3\n",
    "                                              }\n",
    "            }\n",
    "            descriptions, predictions, gt, masks = load_data_for_comparison(base_folder, conditions)\n",
    "            r2 = np.zeros(len(predictions))\n",
    "            for i in range(len(predictions)):\n",
    "                r2[i] = get_weighted_average(get_r2(predictions[i], gt[i]), descriptions[i][\"DATASET_DESCRIPTION\"])\n",
    "            print('Loss: {}, CoordConv: {}, CylindricalPadding: {}, R2 = {:.3f} +/- {:.3f}'.format(loss, use_coord_conv, use_cylindrical_padding, np.mean(r2), np.std(r2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Interpolations: Requires cdo.\n",
    "\n",
    "Flat grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_baseline_c = {\n",
    "    \"DATASET_DESCRIPTION\": {},\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"LinReg_Pixelwise\"}\n",
    "}\n",
    "\n",
    "randomforest_baseline_c = {\n",
    "    \"DATASET_DESCRIPTION\": {},\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"RandomForest_Pixelwise\"}\n",
    "}\n",
    "\n",
    "pca_baseline_c = {\n",
    "    \"DATASET_DESCRIPTION\": {},\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"PCA_Flat\",\n",
    "                                  \"REGTYPE\": \"linreg\"}\n",
    "}\n",
    "\n",
    "unet_unmodified_c = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"tsurf\": [\"tsurf\"],\n",
    "                                                                 \"prec\": [\"prec\"]},\n",
    "                                        \"PRECIP_WEIGHTING\" : False\n",
    "                                       },\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\",\n",
    "                                  \"USE_COORD_CONV\": False,\n",
    "                                  \"USE_CYLINDRICAL_PADDING\": False,\n",
    "                                  \"LEARNING_RATE\": 5e-3,                                   \n",
    "                                  \"LOSS\": \"Masked_MSELoss\"}\n",
    "}\n",
    "\n",
    "unet_modified_c = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"tsurf\": [\"tsurf\"],\n",
    "                                                                 \"prec\": [\"prec\"]},\n",
    "                                        \"PRECIP_WEIGHTING\" : False\n",
    "                                       },\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\",\n",
    "                                  \"USE_COORD_CONV\": True,\n",
    "                                  \"USE_CYLINDRICAL_PADDING\": True,\n",
    "                                  \"LEARNING_RATE\": 5e-3,\n",
    "                                  \"LOSS\": \"Masked_AreaWeightedMSELoss\"}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 matching runs found\n",
      "10 matching runs found\n",
      "1 matching runs found\n",
      "1 matching runs found\n",
      "1 matching runs found\n",
      "Unmodified UNet: $R2 = 0.214 \\pm 0.006$\n",
      "Modified UNet: $R2 = 0.228 \\pm 0.005$\n",
      "Random Forest: $R2 = 0.130 \\pm 0.000$\n",
      "Pixelwise Linear regression: $R2 = 0.150 \\pm 0.000$\n",
      "PCA Regression: $R2 = 0.178 \\pm 0.000$\n"
     ]
    }
   ],
   "source": [
    "\n",
    "descriptions_u_u, predictions_u_u, gt_u_u, masks_u_u = load_data_for_comparison(base_folder, unet_unmodified_c)\n",
    "descriptions_m_u, predictions_m_u, gt_m_u, masks_m_u = load_data_for_comparison(base_folder, unet_modified_c)\n",
    "descriptions_rf, predictions_rf, gt_rf, masks_rf = load_data_for_comparison(base_folder, randomforest_baseline_c)\n",
    "\n",
    "descriptions_lr, predictions_lr, gt_lr, masks_lr = load_data_for_comparison(base_folder, linreg_baseline_c)\n",
    "descriptions_pca, predictions_pca, gt_pca, masks_pca = load_data_for_comparison(base_folder, pca_baseline_c)\n",
    "\n",
    "\n",
    "r2_u_u = np.zeros(len(predictions_u_u))\n",
    "r2_m_u = np.zeros(len(predictions_m_u))\n",
    "r2_rf = np.zeros(len(predictions_rf))\n",
    "\n",
    "r2_lr = np.zeros(len(predictions_lr))\n",
    "r2_pca = np.zeros(len(predictions_pca))\n",
    "\n",
    "\n",
    "for i in range(len(predictions_u_u)):\n",
    "    r2_u_u[i] = get_weighted_average(get_r2(predictions_u_u[i], gt_u_u[i]), descriptions_u_u[i][\"DATASET_DESCRIPTION\"])\n",
    "\n",
    "for i in range(len(predictions_m_u)):\n",
    "    r2_m_u[i] = get_weighted_average(get_r2(predictions_m_u[i], gt_m_u[i]), descriptions_m_u[i][\"DATASET_DESCRIPTION\"])\n",
    "    \n",
    "for i in range(len(predictions_rf)):\n",
    "    r2_rf[i] = get_weighted_average(get_r2(predictions_rf[i], gt_rf[i]), descriptions_rf[i][\"DATASET_DESCRIPTION\"])\n",
    "    \n",
    "for i in range(len(predictions_lr)):\n",
    "    r2_lr[i] = get_weighted_average(get_r2(predictions_lr[i], gt_lr[i]), descriptions_lr[i][\"DATASET_DESCRIPTION\"])\n",
    "    \n",
    "for i in range(len(predictions_pca)):\n",
    "    r2_pca[i] = get_weighted_average(get_r2(predictions_pca[i], gt_pca[i]), descriptions_pca[i][\"DATASET_DESCRIPTION\"])\n",
    "\n",
    "\n",
    "print(r\"Unmodified UNet: $R2 = {:.3f} \\pm {:.3f}$\".format(np.mean(r2_u_u), np.std(r2_u_u)))\n",
    "print(r\"Modified UNet: $R2 = {:.3f} \\pm {:.3f}$\".format(np.mean(r2_m_u), np.std(r2_m_u)))\n",
    "print(r\"Random Forest: $R2 = {:.3f} \\pm {:.3f}$\".format(np.mean(r2_rf), np.std(r2_rf)))\n",
    "\n",
    "print(r\"Pixelwise Linear regression: $R2 = {:.3f} \\pm {:.3f}$\".format(np.mean(r2_lr), np.std(r2_lr)))\n",
    "print(r\"PCA Regression: $R2 = {:.3f} \\pm {:.3f}$\".format(np.mean(r2_pca), np.std(r2_pca)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "icosahedral grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ico_baseline_c = {\n",
    "    \"DATASET_DESCRIPTION\": {},\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"PCA_Ico\",\n",
    "                                  \"REGTYPE\": \"linreg\"}\n",
    "}\n",
    "\n",
    "ico_unet_c = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"tsurf\": [\"tsurf\"],\n",
    "                                                                 \"prec\": [\"prec\"]},\n",
    "                                        \"PRECIP_WEIGHTING\" : False\n",
    "                                       },\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Ico\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 matching runs found\n",
      "1 matching runs found\n",
      "Ico Unet: R2 = 0.238 \\pm 0.000\n",
      "Ico Baseline: R2 = 0.203 \\pm 0.000\n"
     ]
    }
   ],
   "source": [
    "descriptions_ico_unet, predictions_ico_unet, gt_ico_unet, masks_ico_unet = load_data_for_comparison(base_folder, ico_unet_c)\n",
    "descriptions_ico_bl, predictions_ico_bl, gt_ico_bl, masks_ico_bl = load_data_for_comparison(base_folder, ico_baseline_c)\n",
    "\n",
    "r2_ico_unet = np.zeros(len(predictions_ico_unet))\n",
    "r2_ico_bl = np.zeros(len(predictions_ico_bl))\n",
    "\n",
    "for i in range(len(predictions_ico_unet)):\n",
    "    r2_ico_unet[i] = np.mean(get_r2(predictions_ico_unet[i], gt_ico_unet[i]), axis=(1,2))\n",
    "\n",
    "for i in range(len(predictions_ico_bl)):\n",
    "    r2_ico_bl[i] = np.mean(get_r2(predictions_ico_bl[i], gt_ico_bl[i]), axis=(1,2))\n",
    "    \n",
    "print('Ico Unet: R2 = {:.3f} \\pm {:.3f}'.format(np.mean(r2_ico_unet), np.std(r2_ico_unet)))\n",
    "print('Ico Baseline: R2 = {:.3f} \\pm {:.3f}'.format(np.mean(r2_ico_bl), np.std(r2_ico_bl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 matching runs found\n",
      "10 matching runs found\n",
      "10 matching runs found\n",
      "10 matching runs found\n",
      "10 matching runs found\n",
      "Tas: R2 = 0.145 \\pm 0.003\n",
      "Precip: R2 = 0.195 \\pm 0.003\n",
      "Slp: R2 = 0.165 \\pm 0.003\n",
      "Tas, precip, slp: R2 = 0.238 \\pm 0.004\n",
      "Tas, precip, oro: R2 = 0.228 \\pm 0.002\n"
     ]
    }
   ],
   "source": [
    "# predictor variables:\n",
    "conditions_tas = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"tsurf\": [\"tsurf\"]},\n",
    "                            \"PRECIP_WEIGHTING\" : False\n",
    "                           },\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\",\n",
    "                                  \"USE_COORD_CONV\": True,\n",
    "                                  \"USE_CYLINDRICAL_PADDING\": True,\n",
    "                                  \"LOSS\": \"Masked_AreaWeightedMSELoss\",\n",
    "                                  }\n",
    "}\n",
    "\n",
    "conditions_pr = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"prec\": [\"prec\"]},\n",
    "                            \"PRECIP_WEIGHTING\" : False\n",
    "                           },\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\",\n",
    "                                  \"USE_COORD_CONV\": True,\n",
    "                                  \"USE_CYLINDRICAL_PADDING\": True,\n",
    "                                  \"LOSS\": \"Masked_AreaWeightedMSELoss\",\n",
    "                                  }\n",
    "}\n",
    "\n",
    "conditions_slp = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"slp\": [\"p\"]},\n",
    "                            \"PRECIP_WEIGHTING\" : False\n",
    "                           },\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\",\n",
    "                                  \"USE_COORD_CONV\": True,\n",
    "                                  \"USE_CYLINDRICAL_PADDING\": True,\n",
    "                                  \"LOSS\": \"Masked_AreaWeightedMSELoss\",\n",
    "                                  }\n",
    "}\n",
    "\n",
    "conditions_tps = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"tsurf\": [\"tsurf\"],\n",
    "                                                     \"prec\": [\"prec\"],\n",
    "                                                     \"slp\": [\"p\"]},\n",
    "                            \"PRECIP_WEIGHTING\" : False\n",
    "                           },\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\",\n",
    "                                  \"USE_COORD_CONV\": True,\n",
    "                                  \"USE_CYLINDRICAL_PADDING\": True,\n",
    "                                  \"LOSS\": \"Masked_AreaWeightedMSELoss\",\n",
    "                                  \"LEARNING_RATE\": 5e-3,\n",
    "                                  \"DEPTH\": 3,\n",
    "                                   \"FMAPS\": (32,32,64,64)\n",
    "                                  }\n",
    "}\n",
    "\n",
    "conditions_tpo = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"tsurf\": [\"tsurf\"],\n",
    "                                                     \"prec\": [\"prec\"],\n",
    "                                                     \"oro\": [\"ht\"]},\n",
    "                            \"PRECIP_WEIGHTING\" : False\n",
    "                           },\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\",\n",
    "                                  \"USE_COORD_CONV\": True,\n",
    "                                  \"USE_CYLINDRICAL_PADDING\": True,\n",
    "                                  \"LOSS\": \"Masked_AreaWeightedMSELoss\",\n",
    "                                  }\n",
    "}\n",
    "\n",
    "descriptions_tas, predictions_tas, gt_tas, masks_tas = load_data_for_comparison(base_folder, conditions_tas)\n",
    "descriptions_pr, predictions_pr, gt_pr, masks_pr = load_data_for_comparison(base_folder, conditions_pr)\n",
    "descriptions_slp, predictions_slp, gt_slp, masks_slp = load_data_for_comparison(base_folder, conditions_slp)\n",
    "descriptions_tps, predictions_tps, gt_tps, masks_tps = load_data_for_comparison(base_folder, conditions_tps)\n",
    "descriptions_tpo, predictions_tpo, gt_tpo, masks_tpo = load_data_for_comparison(base_folder, conditions_tpo)\n",
    "\n",
    "r2_tas = np.zeros(len(predictions_tas))\n",
    "r2_pr = np.zeros(len(predictions_pr))\n",
    "r2_slp = np.zeros(len(predictions_slp))\n",
    "r2_tps = np.zeros(len(predictions_tps))\n",
    "r2_tpo = np.zeros(len(predictions_tpo))\n",
    "\n",
    "for i in range(len(predictions_tas)):\n",
    "    r2_tas[i] = get_weighted_average(get_r2(predictions_tas[i], gt_tas[i]), descriptions_tas[i][\"DATASET_DESCRIPTION\"])\n",
    "\n",
    "for i in range(len(predictions_pr)):\n",
    "    r2_pr[i] = get_weighted_average(get_r2(predictions_pr[i], gt_pr[i]), descriptions_pr[i][\"DATASET_DESCRIPTION\"])\n",
    "    \n",
    "for i in range(len(predictions_slp)):\n",
    "    r2_slp[i] = get_weighted_average(get_r2(predictions_slp[i], gt_slp[i]), descriptions_slp[i][\"DATASET_DESCRIPTION\"])\n",
    "    \n",
    "for i in range(len(predictions_tps)):\n",
    "    r2_tps[i] = get_weighted_average(get_r2(predictions_tps[i], gt_tps[i]), descriptions_tps[i][\"DATASET_DESCRIPTION\"])\n",
    "    \n",
    "for i in range(len(predictions_tpo)):\n",
    "    r2_tpo[i] = get_weighted_average(get_r2(predictions_tpo[i], gt_tpo[i]), descriptions_tpo[i][\"DATASET_DESCRIPTION\"])\n",
    "    \n",
    "print('Tas: R2 = {:.3f} \\pm {:.3f}'.format(np.mean(r2_tas), np.std(r2_tas)))\n",
    "print('Precip: R2 = {:.3f} \\pm {:.3f}'.format(np.mean(r2_pr), np.std(r2_pr)))\n",
    "print('Slp: R2 = {:.3f} \\pm {:.3f}'.format(np.mean(r2_slp), np.std(r2_slp)))\n",
    "print('Tas, precip, slp: R2 = {:.3f} \\pm {:.3f}'.format(np.mean(r2_tps), np.std(r2_tps)))\n",
    "print('Tas, precip, oro: R2 = {:.3f} \\pm {:.3f}'.format(np.mean(r2_tpo), np.std(r2_tpo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 matching runs found\n",
      "0 matching runs found\n",
      "Deeper: R2 = nan \\pm nan\n",
      "Wider: R2 = nan \\pm nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "conditions_wider = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"tsurf\": [\"tsurf\"],\n",
    "                                                     \"prec\": [\"prec\"],\n",
    "                                                     \"slp\": [\"p\"]},\n",
    "                            \"PRECIP_WEIGHTING\" : False\n",
    "                           },\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\",\n",
    "                                  \"USE_COORD_CONV\": True,\n",
    "                                  \"USE_CYLINDRICAL_PADDING\": True,\n",
    "                                  \"LOSS\": \"Masked_AreaWeightedMSELoss\",\n",
    "                                  \"LEARNING_RATE\": 5e-3,\n",
    "                                  \"DEPTH\": 3,\n",
    "                                   \"FMAPS\": (64,64,128,128)\n",
    "                                  }\n",
    "}\n",
    "\n",
    "conditions_deeper = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"tsurf\": [\"tsurf\"],\n",
    "                                                     \"prec\": [\"prec\"],\n",
    "                                                     \"slp\": [\"p\"]},\n",
    "                            \"PRECIP_WEIGHTING\" : False\n",
    "                           },\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\",\n",
    "                                  \"USE_COORD_CONV\": True,\n",
    "                                  \"USE_CYLINDRICAL_PADDING\": True,\n",
    "                                  \"LOSS\": \"Masked_AreaWeightedMSELoss\",\n",
    "                                  \"LEARNING_RATE\": 5e-3,\n",
    "                                  \"DEPTH\": 4\n",
    "                                  }\n",
    "}\n",
    "\n",
    "descriptions_deeper, predictions_deeper, gt_deeper, masks_deeper = load_data_for_comparison(base_folder, conditions_deeper)\n",
    "descriptions_wider, predictions_wider, gt_wider, masks_wider = load_data_for_comparison(base_folder, conditions_wider)\n",
    "\n",
    "r2_deeper = np.zeros(len(predictions_deeper))\n",
    "r2_wider = np.zeros(len(predictions_wider))\n",
    "\n",
    "for i in range(len(predictions_deeper)):\n",
    "    r2_deeper[i] = get_weighted_average(get_r2(predictions_deeper[i], gt_deeper[i]), descriptions_deeper[i][\"DATASET_DESCRIPTION\"])\n",
    "\n",
    "for i in range(len(predictions_wider)):\n",
    "    r2_wider[i] = get_weighted_average(get_r2(predictions_wider[i], gt_wider[i]), descriptions_wider[i][\"DATASET_DESCRIPTION\"])\n",
    "    \n",
    "print('Deeper: R2 = {:.3f} \\pm {:.3f}'.format(np.mean(r2_deeper), np.std(r2_deeper)))\n",
    "print('Wider: R2 = {:.3f} \\pm {:.3f}'.format(np.mean(r2_wider), np.std(r2_wider)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 matching runs found\n"
     ]
    }
   ],
   "source": [
    "conditions_lrs = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"tsurf\": [\"tsurf\"],\n",
    "                                                     \"prec\": [\"prec\"],\n",
    "                                                     \"slp\": [\"p\"]},\n",
    "                            \"PRECIP_WEIGHTING\" : False\n",
    "                           },\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\",\n",
    "                                  \"USE_COORD_CONV\": True,\n",
    "                                  \"USE_CYLINDRICAL_PADDING\": True,\n",
    "                                  \"LOSS\": \"Masked_AreaWeightedMSELoss\",\n",
    "                                  \"DEPTH\": 3\n",
    "                                  }\n",
    "}\n",
    "\n",
    "descriptions_lrs, predictions_lrs, gt_lrs, masks_lrs = load_data_for_comparison(base_folder, conditions_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_lrs = np.zeros(len(predictions_lrs))\n",
    "\n",
    "for i in range(len(predictions_lrs)):\n",
    "    r2_lrs[i] = get_weighted_average(get_r2(predictions_lrs[i], gt_lrs[i]), descriptions_lrs[i][\"DATASET_DESCRIPTION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001 R2 = nan \\pm nan\n",
      "lr: 0.0001438449888287663 R2 = nan \\pm nan\n",
      "lr: 0.00020691380811147902 R2 = nan \\pm nan\n",
      "lr: 0.00029763514416313193 R2 = nan \\pm nan\n",
      "lr: 0.00042813323987193956 R2 = nan \\pm nan\n",
      "lr: 0.0006158482110660267 R2 = nan \\pm nan\n",
      "lr: 0.0008858667904100823 R2 = nan \\pm nan\n",
      "lr: 0.0012742749857031334 R2 = nan \\pm nan\n",
      "lr: 0.0018329807108324356 R2 = nan \\pm nan\n",
      "lr: 0.0026366508987303583 R2 = nan \\pm nan\n",
      "lr: 0.00379269019073225 R2 = nan \\pm nan\n",
      "lr: 0.005455594781168515 R2 = nan \\pm nan\n",
      "lr: 0.007847599703514606 R2 = nan \\pm nan\n",
      "lr: 0.011288378916846883 R2 = nan \\pm nan\n",
      "lr: 0.01623776739188721 R2 = nan \\pm nan\n",
      "lr: 0.023357214690901212 R2 = nan \\pm nan\n",
      "lr: 0.03359818286283781 R2 = nan \\pm nan\n",
      "lr: 0.04832930238571752 R2 = nan \\pm nan\n",
      "lr: 0.06951927961775606 R2 = nan \\pm nan\n",
      "lr: 0.1 R2 = nan \\pm nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'R2 score')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lrs = [d[\"MODEL_TRAINING_DESCRIPTION\"][\"LEARNING_RATE\"] for d in descriptions_lrs]\n",
    "\n",
    "r2_lrs_mean = []\n",
    "r2_lrs_std = []\n",
    "\n",
    "ls = np.logspace(-4,-1,20)\n",
    "for i, l in enumerate(ls):\n",
    "    indices = np.where(l==lrs)[0]\n",
    "    print('lr: {} R2 = {:.3f} \\pm {:.3f}'.format(l, np.mean(r2_lrs[indices]), np.std(r2_lrs[indices])))\n",
    "    r2_lrs_mean.append(np.mean(r2_lrs[indices]))\n",
    "    r2_lrs_std.append(np.std(r2_lrs[indices]))\n",
    "    \n",
    "plt.plot(ls, r2_lrs_mean)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"R2 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.3 Precip weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 matching runs found\n",
      "41 matching runs found\n",
      "No precip weighting: R2 = 0.227 \\pm 0.004\n",
      "Precip weighting: R2 = nan \\pm nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "conditions_pw = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PRECIP_WEIGHTING\" : True},\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {}\n",
    "}\n",
    "\n",
    "conditions_no_pw = {\n",
    "    \"DATASET_DESCRIPTION\": {\"PREDICTOR_VARIABLES\" : {\"tsurf\": [\"tsurf\"],\n",
    "                                                     \"prec\": [\"prec\"]},\n",
    "                            \"PRECIP_WEIGHTING\" : False},\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\",\n",
    "                                  \"USE_COORD_CONV\": True,\n",
    "                                  \"USE_CYLINDRICAL_PADDING\": True,\n",
    "                                  \"LOSS\": \"Masked_AreaWeightedMSELoss\",\n",
    "                                  \"DEPTH\": 3\n",
    "                                  }\n",
    "}\n",
    "\n",
    "descriptions_pw, predictions_pw, gt_pw, masks_pw = load_data_for_comparison(base_folder, conditions_pw)\n",
    "descriptions_no_pw, predictions_no_pw, gt_no_pw, masks_no_pw = load_data_for_comparison(base_folder, conditions_no_pw)\n",
    "\n",
    "r2_pw = np.zeros(len(predictions_pw))\n",
    "r2_no_pw = np.zeros(len(predictions_no_pw))\n",
    "\n",
    "for i in range(len(predictions_pw)):\n",
    "    r2_pw[i] = get_weighted_average(get_r2(predictions_pw[i], gt_pw[i]), descriptions_pw[i][\"DATASET_DESCRIPTION\"])\n",
    "\n",
    "for i in range(len(predictions_no_pw)):\n",
    "    r2_no_pw[i] = get_weighted_average(get_r2(predictions_no_pw[i], gt_no_pw[i]), descriptions_no_pw[i][\"DATASET_DESCRIPTION\"])\n",
    "    \n",
    "print('No precip weighting: R2 = {:.3f} \\pm {:.3f}'.format(np.mean(r2_no_pw), np.std(r2_no_pw)))\n",
    "print('Precip weighting: R2 = {:.3f} \\pm {:.3f}'.format(np.mean(r2_pw), np.std(r2_pw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GrouPyTorch_kernel",
   "language": "python",
   "name": "groupytorch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
