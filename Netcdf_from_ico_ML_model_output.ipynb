{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to compare to other methods we need to interpolate data back to regular grid. To be able to interpolate back to regular data, we need to create a .nc file that we can give to cdo.\n",
    "\n",
    "Only process one dataset folder at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=E1101,R,C\n",
    "import numpy as np\n",
    "import gzip\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from icosahedron import Icosahedron, rand_rotation_icosahedron, rand_rotation_matrix, plot_voronoi, plot_voronoi_charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY_DATASETS_INTERPOLATED = \"Datasets/Interpolated/\"\n",
    "DIRECTORY_DATASETS_ORIGINAL = \"Datasets/Original/\"\n",
    "DIRECTORY_IMAGES = \"Images/\"\n",
    "DIRECTORY_SCRIPTS = \"Scripts/\"\n",
    "DIRECTORY_OUTPUTS = \"Output/Compare_UNet_architectures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dict_conditions(dic, conditions):\n",
    "    \"\"\"\n",
    "    Test whether dict \"dic\" fullfills the given conditions \"conditions\". \n",
    "    The latter are given as a array of key-value pairs.\n",
    "    \"\"\"\n",
    "    for key, value in conditions:\n",
    "        if key in dic.keys():\n",
    "            if not dic[key] == value:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  -0xb4eecf0bc51a89e\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  5\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  0x73a3d33d45d81cf6\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  -0x59c939c9644cd2d1\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  6\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  -0x39f24f424678fa8d\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  0\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  -0x2af1a428d0ed58f7\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  8\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  0x733aec9ad36b8ed2\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  2\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  -0xbbb6baeba7d1aca\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  4\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  -0x269d850aaa25baa9\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  9\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  classical_-0x6b61818b90a28ee3\n",
      "MODELTYPE :  Classical_ico\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "REGTYPE :  lasso\n",
      "n_pc_in :  300\n",
      "n_pc_target :  450\n",
      "\n",
      "\n",
      "Path:  -0x3e4e083ad549554a\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  1\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  -0x2b4ef4d287af07c8\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  7\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset parameters. To leave unspecified use: \"*\"\n",
    "PREFIX = \"HadCM3-ico\"\n",
    "RESOLUTION = 5\n",
    "DO_SHUFFLE = False\n",
    "INTERPOLATION = \"cons1\"\n",
    "INTERPOLATE_CORNERS = True\n",
    "ALL_VARIABLES = np.sort([\"temp_1\",\"precip\",\"dO18\"]) #\"*\" # get all possible combinations # np.sort([\"temp_1\",\"precip\",\"dO18\",\"p\"])\n",
    "DSET_NR = \"1\"\n",
    "\n",
    "# helping vars\n",
    "shuffle_dict = {True:\"shuffle\", False:\"no-shuffle\", \"*\": \"*\"}\n",
    "corners_dict = {True: \"interp-corners\", False: \"zero-fill-corners\", \"*\": \"*\"}\n",
    "\n",
    "# wildcards can be used in this filename.\n",
    "DATASET_FOLDER = \"{}_{}_{}_{}_{}_{}_\".format(PREFIX, RESOLUTION, shuffle_dict[DO_SHUFFLE], INTERPOLATION, \n",
    "                                         corners_dict[INTERPOLATE_CORNERS], DSET_NR)\n",
    "DATASET_FOLDER = DATASET_FOLDER + \"-\".join(ALL_VARIABLES)\n",
    "DATASET_FOLDER = os.path.join(DIRECTORY_OUTPUTS, DATASET_FOLDER)\n",
    "\n",
    "if not os.path.exists(DATASET_FOLDER):\n",
    "    raise OSError(\"There exists no folder for the given specifications\")\n",
    "\n",
    "    \n",
    "DATASET_DESCRIPTION_FILE = os.path.join(DATASET_FOLDER, \"dataset-description.gz\")\n",
    "\n",
    "with gzip.open(DATASET_DESCRIPTION_FILE, 'rb') as f:\n",
    "    dataset_description = pickle.load(f)\n",
    "\n",
    "    \n",
    "    \n",
    "model_descriptions = []\n",
    "testset_predictions = []\n",
    "model_descriptions_paths = []\n",
    "\n",
    "# specify the conditions that we want the runs to match\n",
    "conditions = []# [()\"NUM_EPOCHS\",3)]\n",
    "\n",
    "\n",
    "subdirs = [d for d in os.listdir(DATASET_FOLDER) if os.path.isdir(os.path.join(DATASET_FOLDER, d))]\n",
    "\n",
    "for subdir in subdirs:\n",
    "    files = [f for f in os.listdir(os.path.join(DATASET_FOLDER, subdir)) if os.path.isfile(os.path.join(DATASET_FOLDER, subdir, f))]   \n",
    "    if \"model_training_description.gz\" in files and \"predictions.gz\" in files:        \n",
    "        # this is a valid description of a model run. Store path and print description\n",
    "        with gzip.open(os.path.join(DATASET_FOLDER, subdir, \"model_training_description.gz\"), 'rb') as f:\n",
    "            tmp_description = pickle.load(f)\n",
    "            if check_dict_conditions(tmp_description, conditions):  # check if the description satisfies our conditions\n",
    "                model_descriptions.append(tmp_description)      \n",
    "                model_descriptions_paths.append(os.path.join(DATASET_FOLDER, subdir))\n",
    "                print(\"Path: \", subdir)\n",
    "                for key, value in model_descriptions[-1].items():\n",
    "                    print(key,\": \", value)\n",
    "                print(\"\\n\")\n",
    "\n",
    "                with gzip.open(os.path.join(DATASET_FOLDER, subdir, \"predictions.gz\"), 'rb') as g:\n",
    "                    testset_predictions.append(pickle.load(g))       \n",
    "    else:\n",
    "        print(\"Encountered Invalid directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Get required ground truth\n",
    "(Requires grid_description only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable: ['dO18']\n"
     ]
    }
   ],
   "source": [
    "print(\"Target variable:\", dataset_description[\"target_variables\"])\n",
    "\n",
    "required_files = []\n",
    "\n",
    "if dataset_description[\"target_variables\"][0] == \"dO18\":\n",
    "    for filename in dataset_description[\"files_used\"]:\n",
    "        if \"isotopes\" in filename:\n",
    "            required_files.append(filename)\n",
    "else:\n",
    "    raise NotImplementedError(\"Currently only d18O is a valid target variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_dict(path_ds_6_nb, path_ds_5_nb=None):\n",
    "    \"\"\"\n",
    "    Returns a dict that contains the Datasets stored in path_ds_5_nb and path_ds_6_nb. As the names suggest,\n",
    "    these should be the the datasets containing all points with 5 and all points with six neighbors.\n",
    "    If only one dataset is used (should be path_ds_6_nb), set the other argument to None.\n",
    "    \"\"\"\n",
    "    import netCDF4\n",
    "    assert \"nbs_6\" in path_ds_6_nb\n",
    "    datasets = {}\n",
    "    \n",
    "    datasets[\"6_nb\"] = netCDF4.Dataset(path_ds_6_nb, \"a\")\n",
    "    if path_ds_5_nb is not None:\n",
    "        datasets[\"5_nb\"] = netCDF4.Dataset(path_ds_5_nb, \"a\")\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def get_indices_charts_shape(res):\n",
    "    \"\"\"\n",
    "    Get indices of the two groups: Pixels that have 5 nbs and pixels that have 6 nbs.\n",
    "    Also return the shape of charts bc we need it later\n",
    "    \"\"\"\n",
    "    ico = Icosahedron(r=res)\n",
    "    regions, vertices = ico.get_voronoi_regions_vertices()\n",
    "    charts = ico.get_charts_cut()\n",
    "    indices_six_nb = []\n",
    "    indices_five_nb = []\n",
    "    for i in range(len(regions)):\n",
    "        if len(regions[i])>5:\n",
    "            indices_six_nb.append(i)\n",
    "        else:\n",
    "            indices_five_nb.append(i)\n",
    "    # create numpy arrays\n",
    "    indices_six_nb = np.array(indices_six_nb)\n",
    "    indices_five_nb = np.array(indices_five_nb)\n",
    "    return indices_five_nb, indices_six_nb, charts.shape\n",
    "\n",
    "\n",
    "def combine_datasets(dataset_dict, indices_five_nb, indices_six_nb):\n",
    "    \"\"\"\n",
    "    We need to combine the datasets from the seperate files for points with 5 nbs and points with 6 nbs.\n",
    "    If there only is a file with six-neighbor points, we fill with zeros. \n",
    "    \"\"\"\n",
    "    assert \"6_nb\" in dataset_dict.keys()\n",
    "    combined_data = np.zeros(dataset_dict[\"6_nb\"].shape[:-1] + (dataset_dict[\"6_nb\"].shape[-1]+10,))\n",
    "    if \"5_nb\" in dataset_dict.keys():\n",
    "        combined_data[:,indices_six_nb] = dataset_dict[\"6_nb\"]\n",
    "        combined_data[:,indices_five_nb] = dataset_dict[\"5_nb\"]\n",
    "    else:\n",
    "        combined_data[:,indices_six_nb] = dataset_dict[\"6_nb\"]\n",
    "        combined_data[:,indices_five_nb] = 0\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "isotopes = get_dataset_dict(required_files[0], required_files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of datasets to which we want not to be missing at any timestep.\n",
    "dnames = [DIRECTORY_DATASETS_ORIGINAL+\"xnapa_isotopes.nc\",\\\n",
    "          DIRECTORY_DATASETS_ORIGINAL+\"xnapa_precip.nc\",\\\n",
    "          DIRECTORY_DATASETS_ORIGINAL+\"xnapa_slp.nc\",\\\n",
    "          DIRECTORY_DATASETS_ORIGINAL+\"xnapa_temp.nc\"]\n",
    "\n",
    "def get_shared_timesteps(dataset_names):\n",
    "    \"\"\"\n",
    "    Not all datasets share the same timesteps. The biggest problems occur in the slp dataset. We want to exclude all\n",
    "    time steps where one of the variables is missing\n",
    "    \"\"\"\n",
    "    \n",
    "    # get indices of elements that are shared for all variables.\n",
    "    from functools import reduce\n",
    "    ts = tuple([nc.Dataset(dataset_name,\"a\").variables[\"t\"][:].data for dataset_name in dataset_names])\n",
    "    common_dates = reduce(np.intersect1d, ts)\n",
    "    \n",
    "    return common_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d18O = {}\n",
    "\n",
    "\n",
    "t = isotopes[\"6_nb\"].variables[\"t\"][:].data\n",
    "t_bnds = isotopes[\"6_nb\"].variables[\"t_bnds\"][:]\n",
    "\n",
    "\n",
    "for name, dset in isotopes.items():  \n",
    "    d18O[name] = np.squeeze(dset.variables[\"dO18\"][:])\n",
    "    \n",
    "for name, array in d18O.items():  \n",
    "    c_dates = get_shared_timesteps(dnames)\n",
    "    # get the corresponding indices:\n",
    "    indices = []\n",
    "    for j, t_ in enumerate(isotopes[\"6_nb\"].variables[\"t\"][:].data):\n",
    "        if t_ in c_dates:\n",
    "            indices.append(j)\n",
    "    indices = np.array(indices)\n",
    "    index_mask = np.logical_and(isotopes[\"6_nb\"].variables[\"t\"][indices].data // 360 >= 654, \\\n",
    "                                isotopes[\"6_nb\"].variables[\"t\"][indices].data // 360 < 1654)    \n",
    "    indices = indices[index_mask]\n",
    "\n",
    "    d18O[name] = array[indices,...]\n",
    "    \n",
    "indices_five_nb, indices_six_nb, cs = get_indices_charts_shape(dataset_description[\"RESOLUTION\"])\n",
    "d18O = combine_datasets(d18O, indices_five_nb, indices_six_nb)\n",
    "d18O = d18O.reshape(d18O.shape[0],-1,cs[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d18O_ico_train = d18O[dataset_description[\"indices_train\"],...]\n",
    "t_train = t[dataset_description[\"indices_train\"],...]\n",
    "t_bnds_train = t_bnds[dataset_description[\"indices_train\"],...]\n",
    "\n",
    "d18O_ico_test = d18O[dataset_description[\"indices_test\"],...]\n",
    "t_test = t[dataset_description[\"indices_test\"],...]\n",
    "t_bnds_test = t_bnds[dataset_description[\"indices_test\"],...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 a) Undo the standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_predictions = []\n",
    "\n",
    "for i, description in enumerate(model_descriptions):\n",
    "    rescaled_predictions.append([])\n",
    "    for j, mode in enumerate(description[\"S_MODE_TARGETS\"]):\n",
    "        if mode == \"Global\":\n",
    "            std = np.mean(np.std(d18O_ico_train, axis=(0,), keepdims=True), axis=(2,3), keepdims=True)\n",
    "            std[std==0] = 1\n",
    "            mean = np.mean(d18O_ico_train, axis=(0,2,3), keepdims=True)\n",
    "            rescaled_predictions[-1].append((testset_predictions[i][\"predictions\"][:,j,...] * std) + mean)             \n",
    "        elif mode == \"Pixelwise\":        \n",
    "            std = np.std(d18O_ico_train, axis=(0), keepdims=True)\n",
    "            std[std==0] = 1\n",
    "            mean = np.mean(d18O_ico_train, axis=(0), keepdims=True)\n",
    "            rescaled_predictions[-1].append((testset_predictions[i][\"predictions\"][:,j,...] * std) + mean)   \n",
    "        elif mode == \"Global_mean_pixelwise_std\":\n",
    "            std = np.mean(np.std(d18O_ico_train, axis=(0,), keepdims=True), axis=(2,3), keepdims=True)\n",
    "            std[std==0] = 1\n",
    "            mean = np.mean(d18O_ico_train, axis=(0), keepdims=True)\n",
    "            rescaled_predictions[-1].append((testset_predictions[i][\"predictions\"][:,j,...] * std) + mean)           \n",
    "        elif mode == \"Pixelwise_mean_global_std\":\n",
    "            std = np.std(d18O_ico_train, axis=(0), keepdims=True)\n",
    "            std[std==0] = 1\n",
    "            mean = np.mean(d18O_ico_train, axis=(0,2,3), keepdims=True)\n",
    "            rescaled_predictions[-1].append((testset_predictions[i][\"predictions\"][:,j,...] * std) + mean)  \n",
    "        elif mode == \"None\":\n",
    "            rescaled_predictions[-1].append(testset_predictions[i][\"predictions\"])\n",
    "        else:\n",
    "            raise NotImplementedError(\"{} is not a valid keyword for standardization\".format(mode))\n",
    "    rescaled_predictions[-1] = np.stack(rescaled_predictions[-1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 a) Split the dataset into pixels with five and six neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_predictions_five_nb = np.zeros((len(rescaled_predictions), d18O_ico_test.shape[0], len(indices_five_nb)))\n",
    "rescaled_predictions_six_nb = np.zeros((len(rescaled_predictions), d18O_ico_test.shape[0], len(indices_six_nb)))\n",
    "\n",
    "for i in range(len(rescaled_predictions)):\n",
    "    rescaled_predictions[i] = rescaled_predictions[i].reshape(d18O_ico_test.shape[0],-1)\n",
    "    rescaled_predictions_five_nb[i] = rescaled_predictions[i][:,indices_five_nb]\n",
    "    rescaled_predictions_six_nb[i] = rescaled_predictions[i][:,indices_six_nb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 b) Save these as two seperate .nc files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Datasets/Interpolated/xnapa_isotopes_r_5_nbs_6_cons1.nc',\n",
       " 'Datasets/Interpolated/xnapa_isotopes_r_5_nbs_5_cons1.nc']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tocopy = ['lon', 'lon_bnds', 'lat', 'lat_bnds']\n",
    "dimscopy =['t', 'bnds', 'ncells','vertices']\n",
    "\n",
    "paths_5_nbs = []\n",
    "paths_6_nbs = []\n",
    "\n",
    "\n",
    "for i, model_description_path in enumerate(model_descriptions_paths):\n",
    "    for filename in required_files:\n",
    "        original_dimensions  = nc.Dataset(filename).variables[\"dO18\"].dimensions\n",
    "        necessary_dimensions = (original_dimensions[0], original_dimensions[2])\n",
    "        original_dataype     = nc.Dataset(filename).variables[\"dO18\"].datatype\n",
    "\n",
    "        if \"nbs_6\" in filename:\n",
    "            netcdf4_path = os.path.splitext(model_description_path)[0]+\"_6_nbs.nc\"\n",
    "            paths_6_nbs.append(netcdf4_path)\n",
    "        elif \"nbs_5\" in filename:\n",
    "            netcdf4_path = os.path.splitext(model_description_path)[0]+\"_5_nbs.nc\"     \n",
    "            paths_5_nbs.append(netcdf4_path)\n",
    "        src = nc.Dataset(filename)\n",
    "        dst = nc.Dataset(netcdf4_path, \"w\")\n",
    "        # copy global attributes all at once via dictionary\n",
    "        dst.setncatts(src.__dict__)\n",
    "        # copy dimensions\n",
    "        for name, dimension in src.dimensions.items():\n",
    "            if name in dimscopy:\n",
    "                dst.createDimension(name, (len(dimension) if not dimension.isunlimited() else None))\n",
    "        # copy all file data except for the excluded\n",
    "        for name, variable in src.variables.items():\n",
    "            if name in tocopy:\n",
    "                x = dst.createVariable(name, variable.datatype, variable.dimensions)\n",
    "                dst[name][:] = src[name][:]\n",
    "                # copy variable attributes all at once via dictionary\n",
    "                dst[name].setncatts(src[name].__dict__)\n",
    "\n",
    "        target_var_attribute_dict = nc.Dataset(filename).variables[\"dO18\"].__dict__\n",
    "        dst.createVariable(\"dO18\", original_dataype, necessary_dimensions)\n",
    "        dst.variables[\"dO18\"].setncatts(target_var_attribute_dict)\n",
    "        dst.createVariable(\"t\", \"float64\", (\"t\"))\n",
    "        dst.createVariable(\"t_bnds\", \"float64\", (\"t\",\"bnds\"))\n",
    "        dst.variables[\"t\"][:] = t_test\n",
    "        dst.variables[\"t_bnds\"][:] = t_bnds_test\n",
    "\n",
    "\n",
    "        if \"nbs_6\" in filename:\n",
    "            dst.variables[\"dO18\"][:] = rescaled_predictions_six_nb[i]\n",
    "        elif \"nbs_5\" in filename:\n",
    "            dst.variables[\"dO18\"][:] = rescaled_predictions_five_nb[i]  \n",
    "\n",
    "        # print(dst.)\n",
    "        dst.close()\n",
    "        src.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GrouPyTorch_kernel",
   "language": "python",
   "name": "groupytorch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
