{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540064cc",
   "metadata": {},
   "source": [
    "# Crossprediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c710f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3642ded9",
   "metadata": {},
   "source": [
    "### Create HadCM3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867152b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\",\n",
    "                                   ] # \"slp\"\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1, -1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\"\"\"\n",
    "description[\"RESOLUTION\"] = 5\n",
    "description[\"INTERPOLATE_CORNERS\"] = True\n",
    "description[\"INTERPOLATION\"] = \"cons1\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68825fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f9b101",
   "metadata": {},
   "source": [
    "### Create GISS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cfa4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description_GISS = {}\n",
    "\n",
    "description_GISS[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                        \"tsurf\", \n",
    "                                        \"prec\"]\n",
    "\n",
    "description_GISS[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                              \"prec\": [\"prec\"]}\n",
    "\n",
    "description_GISS[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description_GISS[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                           \"tsurf\", \n",
    "                                           \"prec\",\n",
    "                                           ] # \"slp\"\n",
    "\n",
    "description_GISS[\"CLIMATE_MODEL\"] = \"GISS\"\n",
    "description_GISS[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description_GISS[\"START_YEAR\"] = 850\n",
    "description_GISS[\"END_YEAR\"] = 1850\n",
    "description_GISS[\"LATITUDES_SLICE\"] = [1, -1]\n",
    "\n",
    "description_GISS[\"TEST_FRACTION\"] = 0.1\n",
    "description_GISS[\"DO_SHUFFLE\"] = False\n",
    "description_GISS[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\"\"\"\n",
    "description_GISS[\"RESOLUTION\"] = 5\n",
    "description_GISS[\"INTERPOLATE_CORNERS\"] = True\n",
    "description_GISS[\"INTERPOLATION\"] = \"cons1\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "description_GISS[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069f63b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description_GISS, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d924fab",
   "metadata": {},
   "source": [
    "### Create iCESM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2beffde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description_iCESM = {}\n",
    "\n",
    "description_iCESM[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                        \"tsurf\", \n",
    "                                        \"prec\"]\n",
    "\n",
    "description_iCESM[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                              \"prec\": [\"prec\"]}\n",
    "\n",
    "description_iCESM[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description_iCESM[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                           \"tsurf\", \n",
    "                                           \"prec\",\n",
    "                                           ] # \"slp\"\n",
    "\n",
    "description_iCESM[\"CLIMATE_MODEL\"] = \"iCESM\"\n",
    "description_iCESM[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description_iCESM[\"START_YEAR\"] = 850\n",
    "description_iCESM[\"END_YEAR\"] = 1850\n",
    "description_iCESM[\"LATITUDES_SLICE\"] = [1, -1]\n",
    "\n",
    "description_iCESM[\"TEST_FRACTION\"] = 0.1\n",
    "description_iCESM[\"DO_SHUFFLE\"] = False\n",
    "description_iCESM[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\"\"\"\n",
    "description_iCESM[\"RESOLUTION\"] = 5\n",
    "description_iCESM[\"INTERPOLATE_CORNERS\"] = True\n",
    "description_iCESM[\"INTERPOLATION\"] = \"cons1\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "description_iCESM[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14cca0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description_iCESM, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db84172",
   "metadata": {},
   "source": [
    "### Create isoGSM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "499c1816",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description_isoGSM = {}\n",
    "\n",
    "description_isoGSM[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                        \"tsurf\", \n",
    "                                        \"prec\"]\n",
    "\n",
    "description_isoGSM[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                              \"prec\": [\"prec\"]}\n",
    "\n",
    "description_isoGSM[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description_isoGSM[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                           \"tsurf\", \n",
    "                                           \"prec\",\n",
    "                                           ] # \"slp\"\n",
    "\n",
    "description_isoGSM[\"CLIMATE_MODEL\"] = \"isoGSM\"\n",
    "description_isoGSM[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description_isoGSM[\"START_YEAR\"] = 850\n",
    "description_isoGSM[\"END_YEAR\"] = 1850\n",
    "description_isoGSM[\"LATITUDES_SLICE\"] = [1, -1]\n",
    "\n",
    "description_isoGSM[\"TEST_FRACTION\"] = 0.1\n",
    "description_isoGSM[\"DO_SHUFFLE\"] = False\n",
    "description_isoGSM[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\"\"\"\n",
    "description_isoGSM[\"RESOLUTION\"] = 5\n",
    "description_isoGSM[\"INTERPOLATE_CORNERS\"] = True\n",
    "description_isoGSM[\"INTERPOLATION\"] = \"cons1\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "description_isoGSM[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa88f49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description_isoGSM, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac4ff3",
   "metadata": {},
   "source": [
    "### Create old iHadCM3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "657c947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets_old\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description_old = {}\n",
    "\n",
    "description_old[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                        \"temp\", \n",
    "                                        \"precip\"]\n",
    "\n",
    "description_old[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                              \"precip\": [\"precip\"]}\n",
    "\n",
    "description_old[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description_old[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                           \"temp\", \n",
    "                                           \"precip\",\n",
    "                                           ] # \"slp\"\n",
    "\n",
    "description_old[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description_old[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description_old[\"START_YEAR\"] = 850\n",
    "description_old[\"END_YEAR\"] = 1850\n",
    "description_old[\"LATITUDES_SLICE\"] = [1, -1]\n",
    "\n",
    "description_old[\"TEST_FRACTION\"] = 0.1\n",
    "description_old[\"DO_SHUFFLE\"] = False\n",
    "description_old[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\"\"\"\n",
    "description_old[\"RESOLUTION\"] = 5\n",
    "description_old[\"INTERPOLATE_CORNERS\"] = True\n",
    "description_old[\"INTERPOLATION\"] = \"cons1\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "description_old[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2cb634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description_old, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea886dcc",
   "metadata": {},
   "source": [
    "### Train on iHadCM3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5878af93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldap-server/firenze/venv/GrouPyTorch/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\",\n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\"\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "# training parameters\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 4 # this changes compared to standard UNet\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 5e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,128,128)\n",
    "\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b7db9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2925880/751018307.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_training_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/IcoCNN_new/train.py\u001b[0m in \u001b[0;36mtrain_unet\u001b[0;34m(dataset_description, model_training_description, base_folder, use_tensorboard)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid grid type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdataset_description\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GRID_TYPE\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Ico\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/GrouPyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IcoCNN_new/ico_unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;34mf'Input shape {input_.shape[2:]} not suited for downsampling with factors {self.scale_factors}.'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0;34mf'Lengths of spatial axes must be multiples of {self.divisibility_constraint}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_input_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IcoCNN_new/ico_unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mencoded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_modules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsampling_modules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/GrouPyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IcoCNN_new/CoordConv/coordconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCoordConv2d\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcoords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"circular\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/GrouPyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IcoCNN_new/CoordConv/coordconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mcos_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0myy_channel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mxx_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxx_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0msin_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msin_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/GrouPyTorch/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW"
     ]
    }
   ],
   "source": [
    "unet = train_unet(description, model_training_description, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311869b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87246756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ec6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_save_unet(description, model_training_description, output_folder, unet, output_folder)\n",
    "predict_save_unet(description_iCESM, model_training_description, output_folder, unet, output_folder)\n",
    "predict_save_unet(description_GISS, model_training_description, output_folder, unet, output_folder)\n",
    "predict_save_unet(description_isoGSM, model_training_description, output_folder, unet, output_folder)\n",
    "predict_save_unet(description_old, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcab9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf06706",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {\n",
    "    \"DATASET_DESCRIPTION\": {},\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {\"MODEL_TYPE\": \"UNet_Flat\"}\n",
    "}\n",
    "descriptions, predictions, gt, masks = load_data_for_comparison(output_folder, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332ba468",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(gt)):\n",
    "    print(descriptions[i][\"DATASET_DESCRIPTION\"][\"CLIMATE_MODEL\"])\n",
    "    gt_mean = np.nanmean(gt[i],axis=(0,1))\n",
    "    plt.imshow(gt_mean)\n",
    "    plt.show()\n",
    "    plt.imshow(gt[i][0,0,...] - gt_mean, vmin=-3, vmax=3, cmap=\"RdBu\")\n",
    "    plt.show()\n",
    "    plt.imshow(predictions[i][0,0,...] - gt_mean, vmin=-3, vmax=3, cmap=\"RdBu\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f3252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.sum(masks[0],axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8353cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_mean = np.zeros(len(gt))\n",
    "r2 = np.zeros((len(gt), gt[0].shape[-2], gt[0].shape[-1]))\n",
    "for i in range(len(gt)):\n",
    "    mask = np.logical_or(masks[i], np.isnan(gt[i]))\n",
    "    r2[i] = get_r2(predictions[i], gt[i], mask)\n",
    "    r2_mean[i] = get_weighted_average(get_r2(predictions[i], gt[i], mask), descriptions[i][\"DATASET_DESCRIPTION\"])\n",
    "    print(descriptions[i][\"DATASET_DESCRIPTION\"][\"CLIMATE_MODEL\"], \", R2 = {:.3f}\".format(r2_mean[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04212be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(gt)):\n",
    "    print(descriptions[i][\"DATASET_DESCRIPTION\"][\"CLIMATE_MODEL\"])\n",
    "    plt.imshow(r2[i], vmin=-1, vmax=1, cmap=\"RdBu\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa087c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=2, subplot_kw={'projection': r2_style[\"PROJECTION\"]}, figsize=r2_style[\"FIGSIZE\"])\n",
    "for i in range(len(gt)):\n",
    "    plot_map(ax[i//2,i%2], r2[i], descriptions[i][\"DATASET_DESCRIPTION\"], r2_style, \n",
    "             title=descriptions[i][\"DATASET_DESCRIPTION\"][\"CLIMATE_MODEL\"]+r\", $R^2$ = {:.3f}\".format(r2_mean[i]))\n",
    "\n",
    "plt.savefig(\"Images/crossprediction.pdf\")\n",
    "plt.savefig(\"Images/crossprediction.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d1414",
   "metadata": {},
   "source": [
    "# Test plotting part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af97b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=mean_style[\"FIGSIZE\"], subplot_kw={'projection': mean_style[\"PROJECTION\"]})\n",
    "for i in range(len(gt)):\n",
    "    plot_map(ax[i//2,i%2], np.nanmean(gt[i],axis=(0,1)), descriptions[i][\"DATASET_DESCRIPTION\"], mean_style, \n",
    "             title=descriptions[i][\"DATASET_DESCRIPTION\"][\"CLIMATE_MODEL\"]+\" Testsetmean\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2be9fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=std_style[\"FIGSIZE\"], subplot_kw={'projection': std_style[\"PROJECTION\"]})\n",
    "for i in range(len(gt)):\n",
    "    plot_map(ax[i//2,i%2], np.nanstd(gt[i],axis=(0,1)), descriptions[i][\"DATASET_DESCRIPTION\"], std_style, \n",
    "             title=descriptions[i][\"DATASET_DESCRIPTION\"][\"CLIMATE_MODEL\"]+\" Testsetstd\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c28dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = []\n",
    "for d in descriptions:\n",
    "    dsets.append(find_and_load_dataset(output_folder, d[\"DATASET_DESCRIPTION\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f74744",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts = []\n",
    "for ds in dsets:\n",
    "    t = ds[\"train\"][\"predictors\"][:,:1,...]  # second index is for specifying the variables\n",
    "    p = ds[\"train\"][\"predictors\"][:,1:,...]  # second index is for specifying the variables\n",
    "    o = ds[\"train\"][\"targets\"][:]\n",
    "    \n",
    "    c_t = get_correlation(t,o)[0,...]\n",
    "    c_p = get_correlation(p,o)[0,...]\n",
    "\n",
    "    max_cor = np.amax([abs(c_p),abs(c_t)], axis=0)\n",
    "    argmax_cor = np.argmax([abs(c_p),abs(c_t)],axis=0)\n",
    "    \n",
    "    tas_mask = np.where((argmax_cor == 1),True,False)\n",
    "    pr_mask = np.where((argmax_cor == 0),True,False)\n",
    "\n",
    "    tas_img = np.ma.masked_array(max_cor, np.invert(tas_mask))\n",
    "    pr_img = np.ma.masked_array(max_cor, np.invert(pr_mask))\n",
    "\n",
    "    data_dict = {\"tsurf\": tas_img,\n",
    "                 \"prec\": pr_img}\n",
    "    data_dicts.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178bbe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from plotting import plot_map, r2_style, mean_style, std_style, corr_style, plot_masked_data\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a34d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=corr_style[\"FIGSIZE\"], subplot_kw={'projection': mean_style[\"PROJECTION\"]})\n",
    "for i in range(4):\n",
    "    plot_masked_data(ax[i//2,i%2], data_dicts[i], descriptions[i][\"DATASET_DESCRIPTION\"], corr_style, \n",
    "                     title=descriptions[i][\"DATASET_DESCRIPTION\"][\"CLIMATE_MODEL\"]+\"Correlations\")\n",
    "    \n",
    "    divider = make_axes_locatable(ax[i//2,i%2])\n",
    "    for j, key in enumerate(list(data_dicts[i].keys())):\n",
    "        if j==0:\n",
    "            ax_cb = divider.new_horizontal(size=\"3%\", pad=0.3, axes_class=plt.Axes)\n",
    "        else:\n",
    "            ax_cb = divider.new_horizontal(size=\"3%\", pad=0.8, axes_class=plt.Axes)            \n",
    "        fig.add_axes(ax_cb)\n",
    "        cbar = fig.colorbar(\n",
    "            matplotlib.cm.ScalarMappable(cmap=corr_style[\"CMAPS\"][key], norm=corr_style[\"NORM\"]),\n",
    "            spacing='proportional',\n",
    "            orientation='vertical',\n",
    "            extend=corr_style[\"CBAR_EXTEND\"], cax=ax_cb)\n",
    "        cbar.set_label(corr_style[\"CBAR_LABELS\"][key], fontsize=corr_style[\"CBAR_FONTSIZE\"])\n",
    "        cbar.ax.tick_params(labelsize=corr_style[\"CBAR_FONTSIZE\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c33b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=corr_style[\"FIGSIZE\"], subplot_kw={'projection': mean_style[\"PROJECTION\"]})\n",
    "i=3\n",
    "plot_masked_data(ax, data_dicts[i], descriptions[i][\"DATASET_DESCRIPTION\"], corr_style, \n",
    "                 title=descriptions[i][\"DATASET_DESCRIPTION\"][\"CLIMATE_MODEL\"]+\"Correlations\")\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "for j, key in enumerate(list(data_dicts[i].keys())):\n",
    "    if j==0:\n",
    "        ax_cb = divider.new_horizontal(size=\"3%\", pad=0.3, axes_class=plt.Axes)\n",
    "    else:\n",
    "        ax_cb = divider.new_horizontal(size=\"3%\", pad=0.8, axes_class=plt.Axes)            \n",
    "    fig.add_axes(ax_cb)\n",
    "    cbar = fig.colorbar(\n",
    "        matplotlib.cm.ScalarMappable(cmap=corr_style[\"CMAPS\"][key], norm=corr_style[\"NORM\"]),\n",
    "        spacing='proportional',\n",
    "        orientation='vertical',\n",
    "        extend=corr_style[\"CBAR_EXTEND\"], cax=ax_cb)\n",
    "    cbar.set_label(corr_style[\"CBAR_LABELS\"][key], fontsize=corr_style[\"CBAR_FONTSIZE\"])\n",
    "    cbar.ax.tick_params(labelsize=corr_style[\"CBAR_FONTSIZE\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548de66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=corr_style[\"FIGSIZE\"], subplot_kw={'projection': mean_style[\"PROJECTION\"]})\n",
    "i=1\n",
    "plot_masked_data(ax, data_dicts[i], descriptions[i][\"DATASET_DESCRIPTION\"], corr_style, \n",
    "                 title=descriptions[i][\"DATASET_DESCRIPTION\"][\"CLIMATE_MODEL\"]+\"Correlations\")\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "for j, key in enumerate(list(data_dicts[i].keys())):\n",
    "    if j==0:\n",
    "        ax_cb = divider.new_horizontal(size=\"3%\", pad=0.3, axes_class=plt.Axes)\n",
    "    else:\n",
    "        ax_cb = divider.new_horizontal(size=\"3%\", pad=0.8, axes_class=plt.Axes)            \n",
    "    fig.add_axes(ax_cb)\n",
    "    cbar = fig.colorbar(\n",
    "        matplotlib.cm.ScalarMappable(cmap=corr_style[\"CMAPS\"][key], norm=corr_style[\"NORM\"]),\n",
    "        spacing='proportional',\n",
    "        orientation='vertical',\n",
    "        extend=corr_style[\"CBAR_EXTEND\"], cax=ax_cb)\n",
    "    cbar.set_label(corr_style[\"CBAR_LABELS\"][key], fontsize=corr_style[\"CBAR_FONTSIZE\"])\n",
    "    cbar.ax.tick_params(labelsize=corr_style[\"CBAR_FONTSIZE\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e6ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dsets[1][\"train\"][\"predictors\"][:,:1,...]  # second index is for specifying the variables\n",
    "p = dsets[1][\"train\"][\"predictors\"][:,1:,...]  # second index is for specifying the variables\n",
    "o = dsets[1][\"train\"][\"targets\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031613aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(t,axis=(1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776faf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(p,axis=(1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d342e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(o,axis=(1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"Output/Crossprediction/testHadCM3-flat_no-shuffle_1_dO18-precip-temp_1/dataset.gz\", 'r') as f:\n",
    "    ds_old_method = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_o = ds_old_method[\"train\"][\"predictors\"][:,:1,...]  # second index is for specifying the variables\n",
    "p_o = ds_old_method[\"train\"][\"predictors\"][:,1:,...]  # second index is for specifying the variables\n",
    "o_o = ds_old_method[\"train\"][\"targets\"][:]\n",
    "\n",
    "c_t_o = get_correlation(t_o,o_o)[0,...]\n",
    "c_p_o = get_correlation(p_o,o_o)[0,...]\n",
    "\n",
    "max_cor_o = np.amax([abs(c_p_o),abs(c_t_o)], axis=0)\n",
    "argmax_cor_o = np.argmax([abs(c_p_o),abs(c_t_o)],axis=0)\n",
    "\n",
    "tas_mask_o = np.where((argmax_cor_o == 1),True,False)\n",
    "pr_mask_o = np.where((argmax_cor_o == 0),True,False)\n",
    "\n",
    "tas_img_o = np.ma.masked_array(max_cor_o, np.invert(tas_mask_o))\n",
    "pr_img_o = np.ma.masked_array(max_cor_o, np.invert(pr_mask_o))\n",
    "\n",
    "data_dict_o = {\"tsurf\": tas_img_o,\n",
    "             \"prec\": pr_img_o}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b0bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=corr_style[\"FIGSIZE\"], subplot_kw={'projection': mean_style[\"PROJECTION\"]})\n",
    "i=1\n",
    "plot_masked_data(ax, data_dict_o, descriptions[i][\"DATASET_DESCRIPTION\"], corr_style, \n",
    "                 title=descriptions[i][\"DATASET_DESCRIPTION\"][\"CLIMATE_MODEL\"]+\"old\")\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "for j, key in enumerate(list(data_dicts[i].keys())):\n",
    "    if j==0:\n",
    "        ax_cb = divider.new_horizontal(size=\"3%\", pad=0.3, axes_class=plt.Axes)\n",
    "    else:\n",
    "        ax_cb = divider.new_horizontal(size=\"3%\", pad=0.8, axes_class=plt.Axes)            \n",
    "    fig.add_axes(ax_cb)\n",
    "    cbar = fig.colorbar(\n",
    "        matplotlib.cm.ScalarMappable(cmap=corr_style[\"CMAPS\"][key], norm=corr_style[\"NORM\"]),\n",
    "        spacing='proportional',\n",
    "        orientation='vertical',\n",
    "        extend=corr_style[\"CBAR_EXTEND\"], cax=ax_cb)\n",
    "    cbar.set_label(corr_style[\"CBAR_LABELS\"][key], fontsize=corr_style[\"CBAR_FONTSIZE\"])\n",
    "    cbar.ax.tick_params(labelsize=corr_style[\"CBAR_FONTSIZE\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f33de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=corr_style[\"FIGSIZE\"], subplot_kw={'projection': mean_style[\"PROJECTION\"]})\n",
    "i=1\n",
    "plot_masked_data(ax, data_dicts[i], descriptions[i][\"DATASET_DESCRIPTION\"], corr_style, \n",
    "                 title=descriptions[i][\"DATASET_DESCRIPTION\"][\"CLIMATE_MODEL\"]+\"Correlations\")\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "for j, key in enumerate(list(data_dicts[i].keys())):\n",
    "    if j==0:\n",
    "        ax_cb = divider.new_horizontal(size=\"3%\", pad=0.3, axes_class=plt.Axes)\n",
    "    else:\n",
    "        ax_cb = divider.new_horizontal(size=\"3%\", pad=0.8, axes_class=plt.Axes)            \n",
    "    fig.add_axes(ax_cb)\n",
    "    cbar = fig.colorbar(\n",
    "        matplotlib.cm.ScalarMappable(cmap=corr_style[\"CMAPS\"][key], norm=corr_style[\"NORM\"]),\n",
    "        spacing='proportional',\n",
    "        orientation='vertical',\n",
    "        extend=corr_style[\"CBAR_EXTEND\"], cax=ax_cb)\n",
    "    cbar.set_label(corr_style[\"CBAR_LABELS\"][key], fontsize=corr_style[\"CBAR_FONTSIZE\"])\n",
    "    cbar.ax.tick_params(labelsize=corr_style[\"CBAR_FONTSIZE\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d6e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = 1 / (30*24*60*60)\n",
    "plt.plot(np.mean(t_o,axis=(1,2,3)))\n",
    "plt.plot(np.mean(t,axis=(1,2,3))+273.16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a1d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(p_o,axis=(1,2,3))*fc)\n",
    "plt.plot(np.mean(p,axis=(1,2,3)))\n",
    "plt.xlim(0,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d420c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(t[0,0,...])\n",
    "plt.show()\n",
    "plt.imshow(t_o[0,0,...])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(t[0,0,...])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
