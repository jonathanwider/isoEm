{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca31692e",
   "metadata": {},
   "source": [
    "# Base notebook\n",
    "\n",
    "We used this notebook to develop plotting and loading functions on the icosahedral grid. In the end, it wasn't used to produce results for the thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37a4d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "import gzip\n",
    "import netCDF4 as nc\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "\n",
    "\n",
    "from icosahedron import Icosahedron, rand_rotation_icosahedron, rand_rotation_matrix, plot_voronoi, plot_voronoi_charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40bfd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY_DATASETS_INTERPOLATED = \"Datasets/Interpolated/\"\n",
    "DIRECTORY_DATASETS_ORIGINAL = \"Datasets/Original/\"\n",
    "DIRECTORY_IMAGES = \"Images/\"\n",
    "DIRECTORY_OUTPUTS = \"Output/Compare_UNet_architectures/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6833635a",
   "metadata": {},
   "source": [
    "# Give criteria for the dataset and open all files that match these criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5bc7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folders matching the given specifications:\n",
      "Output/Compare_UNet_architectures/HadCM3-ico_5_no-shuffle_cons1_interp-corners_1_dO18-precip-temp_1\n"
     ]
    }
   ],
   "source": [
    "# dataset parameters. To leave unspecified use: \"*\"\n",
    "PREFIX = \"HadCM3-ico\"\n",
    "RESOLUTION = 5\n",
    "DO_SHUFFLE = False\n",
    "INTERPOLATION = \"cons1\"\n",
    "INTERPOLATE_CORNERS = True\n",
    "ALL_VARIABLES = np.sort([\"temp_1\",\"precip\",\"dO18\"]) # get all possible combinations # np.sort([\"temp_1\",\"precip\",\"dO18\",\"p\"])\n",
    "DSET_NR = \"*\"\n",
    "\n",
    "# helping vars\n",
    "shuffle_dict = {True:\"shuffle\", False:\"no-shuffle\", \"*\": \"*\"}\n",
    "corners_dict = {True: \"interp-corners\", False: \"zero-fill-corners\", \"*\": \"*\"}\n",
    "\n",
    "# wildcards can be used in this filename.\n",
    "DATASET_FOLDER = \"{}_{}_{}_{}_{}_{}_\".format(PREFIX, RESOLUTION, shuffle_dict[DO_SHUFFLE], INTERPOLATION, \n",
    "                                         corners_dict[INTERPOLATE_CORNERS], DSET_NR)\n",
    "DATASET_FOLDER = DATASET_FOLDER + \"-\".join(ALL_VARIABLES)\n",
    "DATASET_FOLDER = os.path.join(DIRECTORY_OUTPUTS, DATASET_FOLDER)\n",
    "\n",
    "\n",
    "dataset_description_files = []  # list to collect the paths to the configuration files\n",
    "dataset_folders = []  # list to collect all the matching folders.\n",
    "folder_exists = False\n",
    "\n",
    "print(\"Data folders matching the given specifications:\")\n",
    "for dirname in glob.glob(DATASET_FOLDER):\n",
    "    print(dirname)\n",
    "    folder_exists = True\n",
    "    dataset_folders.append(dirname)\n",
    "    dataset_description_files.append(os.path.join(dirname, \"dataset-description.gz\"))\n",
    "if folder_exists == False:\n",
    "    raise OSError(\"There exists no folder for the given specifications\")\n",
    "\n",
    "dataset_descriptions = []\n",
    "for i, file in enumerate(dataset_description_files):\n",
    "    with gzip.open(file, 'rb') as f:\n",
    "        dataset_descriptions.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aaa1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dict_conditions(dic, conditions):\n",
    "    \"\"\"\n",
    "    Test whether dict \"dic\" fullfills the given conditions \"conditions\". \n",
    "    The latter are given as a array of key-value pairs.\n",
    "    \"\"\"\n",
    "    for key, values in conditions:\n",
    "        if key in dic.keys():\n",
    "            if not dic[key] in values:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d202f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available runs from all previously specified folders, that match specifications:\n",
      "Path:  -0xb4eecf0bc51a89e\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  5\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  0x73a3d33d45d81cf6\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  -0x59c939c9644cd2d1\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  6\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  -0x39f24f424678fa8d\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  0\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  -0x2af1a428d0ed58f7\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  8\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  0x733aec9ad36b8ed2\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  2\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  -0xbbb6baeba7d1aca\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  4\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  -0x269d850aaa25baa9\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  9\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  classical_-0x6b61818b90a28ee3\n",
      "MODELTYPE :  Classical_ico\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "REGTYPE :  lasso\n",
      "n_pc_in :  300\n",
      "n_pc_target :  450\n",
      "\n",
      "\n",
      "Path:  -0x3e4e083ad549554a\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  1\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n",
      "Path:  -0x2b4ef4d287af07c8\n",
      "MODELTYPE :  UNet\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "RUN_NR :  7\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "DEPTH :  3\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm3d'>\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "#params :  1884369\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_descriptions = []\n",
    "testset_predictions = []\n",
    "indices_dataset = [] # store the index of the dataset-directory to which each run belongs\n",
    "model_descriptions_paths = []\n",
    "\n",
    "# specify the conditions that we want the runs to match\n",
    "conditions = []# [(\"NUM_EPOCHS\",3)]\n",
    "\n",
    "\n",
    "print(\"Available runs from all previously specified folders, that match specifications:\")\n",
    "\n",
    "for i, dataset_folder in enumerate(dataset_folders):\n",
    "    subdirs = [d for d in os.listdir(dataset_folder) if os.path.isdir(os.path.join(dataset_folder, d))]\n",
    "    for subdir in subdirs:\n",
    "        files = [f for f in os.listdir(os.path.join(dataset_folder, subdir)) if os.path.isfile(os.path.join(dataset_folder, subdir, f))]\n",
    "        if \"model_training_description.gz\" in files and \"predictions.gz\" in files:        \n",
    "            # this is a valid description of a model run. Store path and print description\n",
    "            with gzip.open(os.path.join(dataset_folder, subdir, \"model_training_description.gz\"), 'rb') as f:\n",
    "                tmp_description = pickle.load(f)\n",
    "                if check_dict_conditions(tmp_description, conditions):  # check if the description satisfies our conditions\n",
    "\n",
    "                    model_descriptions.append(tmp_description)      \n",
    "                    indices_dataset.append(i)\n",
    "                    model_descriptions_paths.append(os.path.join(subdir, file))\n",
    "                    print(\"Path: \", subdir)\n",
    "                    for key, value in model_descriptions[-1].items():\n",
    "                        print(key,\": \", value)\n",
    "                    print(\"\\n\")\n",
    "\n",
    "                    with gzip.open(os.path.join(dataset_folder, subdir, \"predictions.gz\"), 'rb') as g:\n",
    "                        testset_predictions.append(pickle.load(g))       \n",
    "        else:\n",
    "            print(\"Encountered Invalid directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e30bf8c",
   "metadata": {},
   "source": [
    "Check that we can handle the specified target variable and collect the required files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c61f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_files = []\n",
    "for i, description in enumerate(dataset_descriptions):\n",
    "    # print(\"Target variable:\", description[\"target_variables\"])\n",
    "    if description[\"target_variables\"] == [\"dO18\"]:\n",
    "        required_files.append([])\n",
    "    \n",
    "        for filename in description[\"files_used\"]:\n",
    "            if \"isotopes\" in filename:\n",
    "                required_files[-1].append(filename)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Currently only d18O is a valid target variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e5688",
   "metadata": {},
   "source": [
    "# Load data, especially ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d341ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_dict(path_ds_6_nb, path_ds_5_nb=None):\n",
    "    \"\"\"\n",
    "    Returns a dict that contains the Datasets stored in path_ds_5_nb and path_ds_6_nb. As the names suggest,\n",
    "    these should be the the datasets containing all points with 5 and all points with six neighbors.\n",
    "    If only one dataset is used (should be path_ds_6_nb), set the other argument to None.\n",
    "    \"\"\"\n",
    "    import netCDF4\n",
    "    assert \"nbs_6\" in path_ds_6_nb\n",
    "    datasets = {}\n",
    "    \n",
    "    datasets[\"6_nb\"] = nc.Dataset(path_ds_6_nb, \"a\")\n",
    "    if path_ds_5_nb is not None:\n",
    "        datasets[\"5_nb\"] = nc.Dataset(path_ds_5_nb, \"a\")\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def get_indices_charts_shape(res):\n",
    "    \"\"\"\n",
    "    Get indices of the two groups: Pixels that have 5 nbs and pixels that have 6 nbs.\n",
    "    Also return the shape of charts bc we need it later\n",
    "    \"\"\"\n",
    "    ico = Icosahedron(r=res)\n",
    "    regions, vertices = ico.get_voronoi_regions_vertices()\n",
    "    charts = ico.get_charts_cut()\n",
    "    indices_six_nb = []\n",
    "    indices_five_nb = []\n",
    "    for i in range(len(regions)):\n",
    "        if len(regions[i])>5:\n",
    "            indices_six_nb.append(i)\n",
    "        else:\n",
    "            indices_five_nb.append(i)\n",
    "    # create numpy arrays\n",
    "    indices_six_nb = np.array(indices_six_nb)\n",
    "    indices_five_nb = np.array(indices_five_nb)\n",
    "    return indices_five_nb, indices_six_nb, charts.shape\n",
    "\n",
    "\n",
    "def combine_datasets(dataset_dict, indices_five_nb, indices_six_nb):\n",
    "    \"\"\"\n",
    "    We need to combine the datasets from the seperate files for points with 5 nbs and points with 6 nbs.\n",
    "    If there only is a file with six-neighbor points, we fill with zeros. \n",
    "    \"\"\"\n",
    "    assert \"6_nb\" in dataset_dict.keys()\n",
    "    combined_data = np.zeros(dataset_dict[\"6_nb\"].shape[:-1] + (dataset_dict[\"6_nb\"].shape[-1]+10,))\n",
    "    if \"5_nb\" in dataset_dict.keys():\n",
    "        combined_data[:,indices_six_nb] = dataset_dict[\"6_nb\"]\n",
    "        combined_data[:,indices_five_nb] = dataset_dict[\"5_nb\"]\n",
    "    else:\n",
    "        combined_data[:,indices_six_nb] = dataset_dict[\"6_nb\"]\n",
    "        combined_data[:,indices_five_nb] = 0\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7003d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of datasets to which we want not to be missing at any timestep.\n",
    "dnames = [DIRECTORY_DATASETS_ORIGINAL+\"xnapa_isotopes.nc\",\\\n",
    "          DIRECTORY_DATASETS_ORIGINAL+\"xnapa_precip.nc\",\\\n",
    "          DIRECTORY_DATASETS_ORIGINAL+\"xnapa_slp.nc\",\\\n",
    "          DIRECTORY_DATASETS_ORIGINAL+\"xnapa_temp.nc\"]\n",
    "\n",
    "def get_shared_timesteps(dataset_names):\n",
    "    \"\"\"\n",
    "    Not all datasets share the same timesteps. The biggest problems occur in the slp dataset. We want to exclude all\n",
    "    time steps where one of the variables is missing\n",
    "    \"\"\"\n",
    "    \n",
    "    # get indices of elements that are shared for all variables.\n",
    "    from functools import reduce\n",
    "    ts = tuple([nc.Dataset(dataset_name,\"a\").variables[\"t\"][:].data for dataset_name in dataset_names])\n",
    "    common_dates = reduce(np.intersect1d, ts)\n",
    "    \n",
    "    return common_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48a7ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "isotopes_all_datasets = []\n",
    "for i in range(len(dataset_descriptions)):\n",
    "    isotopes_all_datasets.append(get_dataset_dict(*required_files[i]))\n",
    "\n",
    "# somehow two frames are excluded - why???? -> the dO18 datset is 2 timesteps smaller, but the time\n",
    "# axis actually has the same size...\n",
    "\n",
    "d18O_ico = []\n",
    "\n",
    "t = []\n",
    "t_bnds = []\n",
    "\n",
    "\n",
    "for i, iso_single_dataset in enumerate(isotopes_all_datasets):\n",
    "    t.append(iso_single_dataset[\"6_nb\"].variables[\"t\"][:].data)\n",
    "    t_bnds.append(iso_single_dataset[\"6_nb\"].variables[\"t_bnds\"][:])\n",
    "    d18O_ico.append({})\n",
    "    for name, dset in iso_single_dataset.items():  \n",
    "        d18O_ico[-1][name] = np.squeeze(dset.variables[\"dO18\"][:])\n",
    "\n",
    "for i in range(len(d18O_ico)):\n",
    "    for name, array in d18O_ico[i].items():  \n",
    "        c_dates = get_shared_timesteps(dnames)\n",
    "        # get the corresponding indices:\n",
    "        indices = []\n",
    "        for j, t_ in enumerate(isotopes_all_datasets[i][\"6_nb\"].variables[\"t\"][:].data):\n",
    "            if t_ in c_dates:\n",
    "                indices.append(j)\n",
    "        indices = np.array(indices)\n",
    "        index_mask = np.logical_and(isotopes_all_datasets[i][\"6_nb\"].variables[\"t\"][indices].data // 360 >= 654, \\\n",
    "                                    isotopes_all_datasets[i][\"6_nb\"].variables[\"t\"][indices].data // 360 < 1654)    \n",
    "        indices = indices[index_mask]\n",
    "        \n",
    "        d18O_ico[i][name] = array[indices,...]\n",
    "\n",
    "indices_five_nb = []\n",
    "indices_six_nb = []\n",
    "cs = []\n",
    "for description in dataset_descriptions:\n",
    "    tmp1, tmp2, tmp3 = get_indices_charts_shape(description[\"RESOLUTION\"])\n",
    "    indices_five_nb.append(tmp1)\n",
    "    indices_six_nb.append(tmp2)\n",
    "    cs.append(tmp3)\n",
    "    \n",
    "for i in range(len(d18O_ico)):\n",
    "    d18O_ico[i] = combine_datasets(d18O_ico[i], indices_five_nb[i], indices_six_nb[i])\n",
    "    d18O_ico[i] = d18O_ico[i].reshape(d18O_ico[i].shape[0],-1,cs[i][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e95ea25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d18O_ico_train = []\n",
    "t_train = []\n",
    "t_bnds_train = []\n",
    "\n",
    "d18O_ico_test = []\n",
    "t_test = []\n",
    "t_bnds_test = []\n",
    "\n",
    "for i, description in enumerate(dataset_descriptions):\n",
    "    d18O_ico_train.append(d18O_ico[i][description[\"indices_train\"],...])\n",
    "    t_train.append(t[i][description[\"indices_train\"],...])\n",
    "    t_bnds_train.append(t_bnds[i][description[\"indices_train\"],...])\n",
    "\n",
    "    d18O_ico_test.append(d18O_ico[i][description[\"indices_test\"],...])\n",
    "    t_test.append(t[i][description[\"indices_test\"],...])\n",
    "    t_bnds_test.append(t_bnds[i][description[\"indices_test\"],...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa6d8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_predictions = []\n",
    "\n",
    "for i, description in enumerate(model_descriptions):\n",
    "    rescaled_predictions.append([])\n",
    "    for j, mode in enumerate(description[\"S_MODE_TARGETS\"]):\n",
    "        if mode == \"Global\":\n",
    "            std = np.mean(np.std(d18O_ico_train[indices_dataset[i]], axis=(0,), keepdims=True), axis=(2,3), keepdims=True)\n",
    "            std[std==0] = 1\n",
    "            mean = np.mean(d18O_ico_train[indices_dataset[i]], axis=(0,2,3), keepdims=True)\n",
    "            rescaled_predictions[-1].append((testset_predictions[i][\"predictions\"][:,j,...] * std) + mean)             \n",
    "        elif mode == \"Pixelwise\":        \n",
    "            std = np.std(d18O_ico_train[indices_dataset[i]], axis=(0), keepdims=True)\n",
    "            std[std==0] = 1\n",
    "            mean = np.mean(d18O_ico_train[indices_dataset[i]], axis=(0), keepdims=True)\n",
    "            rescaled_predictions[-1].append((testset_predictions[i][\"predictions\"][:,j,...] * std) + mean)   \n",
    "        elif mode == \"Global_mean_pixelwise_std\":\n",
    "            std = np.mean(np.std(d18O_ico_train[indices_dataset[i]], axis=(0,), keepdims=True), axis=(2,3), keepdims=True)\n",
    "            std[std==0] = 1\n",
    "            mean = np.mean(d18O_ico_train[indices_dataset[i]], axis=(0), keepdims=True)\n",
    "            rescaled_predictions[-1].append((testset_predictions[i][\"predictions\"][:,j,...] * std) + mean)           \n",
    "        elif mode == \"Pixelwise_mean_global_std\":\n",
    "            std = np.std(d18O_ico_train[indices_dataset[i]], axis=(0), keepdims=True)\n",
    "            std[std==0] = 1\n",
    "            mean = np.mean(d18O_ico_train[indices_dataset[i]], axis=(0,2,3), keepdims=True)\n",
    "            rescaled_predictions[-1].append((testset_predictions[i][\"predictions\"][:,j,...] * std) + mean)  \n",
    "        elif mode == \"None\":\n",
    "            rescaled_predictions[-1].append(testset_predictions[i][\"predictions\"])\n",
    "        else:\n",
    "            raise NotImplementedError(\"{} is not a valid keyword for standardization\".format(mode))\n",
    "    rescaled_predictions[-1] = np.stack(rescaled_predictions[-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61f69614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ico_lattice_map(data, vertices, regions, cmap=None, norm=None, show_continents=True, \n",
    "                         figsize=(15,10), projection=ccrs.Robinson(), savename=None, title=None, cbar_title=None, title_fontsize=15):\n",
    "    \"\"\"\n",
    "    Plot a single image given in ico_resolution. Assume shape is (npixels,).\n",
    "    \"\"\"\n",
    "    assert len(data.shape) == 1\n",
    "    if vertices.shape[-1]!=2:  # 'if vertices are not in spherical format already'   \n",
    "        spherical_vertices = cartesian_to_spherical(vertices)\n",
    "        spherical_vertices_plot = np.zeros_like(spherical_vertices)\n",
    "        spherical_vertices_plot[:,0] = spherical_vertices[:,1]# longitude\n",
    "        spherical_vertices_plot[:,0][spherical_vertices_plot[:,0] == 360] = 0# longitude\n",
    "        spherical_vertices_plot[:,1] = spherical_vertices[:,0]# latitude\n",
    "    else:\n",
    "        spherical_vertices_plot = np.zeros_like(vertices)\n",
    "        spherical_vertices_plot[:,0] = vertices[:,1]# longitude\n",
    "        spherical_vertices_plot[:,0][spherical_vertices_plot[:,0] == 360] = 0# longitude\n",
    "        spherical_vertices_plot[:,1] = vertices[:,0]# latitude        \n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as mpatches\n",
    "    from matplotlib.collections import PatchCollection\n",
    "\n",
    "    # plotting\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(projection=projection)\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap(\"plasma\")\n",
    "    if norm is None:\n",
    "        dmin = min(data)\n",
    "        dmax = max(data)\n",
    "\n",
    "    patches = []\n",
    "\n",
    "\n",
    "    for i in range(len(regions)):\n",
    "        tmp = spherical_vertices_plot[regions[i]]\n",
    "        # Polygons that lie close to the 0°-360° continuity get connected wrongly by cartopy. We fix this for now\n",
    "        # Solution is not perfect.\n",
    "        if np.amax(tmp[:,0])- np.amin(tmp[:,0]) > 180: \n",
    "            tmp[tmp>180] = tmp[tmp>180]-360\n",
    "        polygon = mpatches.Polygon(tmp,\n",
    "                          transform=ccrs.PlateCarree())\n",
    "        if norm is None:\n",
    "            polygon.set_color(cmap(np.array((data[i]-dmin)/(dmax-dmin))))\n",
    "        else:\n",
    "            polygon.set_color(cmap(norm(data[i])))\n",
    "        ax.add_patch(polygon)\n",
    "        \n",
    "    cbar = fig.colorbar(\n",
    "        matplotlib.cm.ScalarMappable(cmap=cmap, norm=norm),\n",
    "        # ticks=bounds,\n",
    "        spacing='proportional',\n",
    "        orientation='horizontal',\n",
    "    ) \n",
    "    if cbar_title is None:\n",
    "        cbar.set_label(r\"1 - (RMSE/$\\sigma_{test})$\", fontsize = title_fontsize)\n",
    "    else:\n",
    "        cbar.set_label(cbar_title, fontsize = title_fontsize)\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    ax.set_global()\n",
    "    ax.coastlines(alpha=0.5)\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=title_fontsize)\n",
    "    if savename is not None:\n",
    "        plt.savefig(DIRECTORY_IMAGES+savename)\n",
    "    plt.show()\n",
    "    \n",
    "def cartesian_to_spherical(data):\n",
    "    \"\"\"\n",
    "    convert cartesian coordinates to spherical coordinates\n",
    "    Use answer to:\n",
    "    https://stackoverflow.com/questions/4116658/faster-numpy-cartesian-to-spherical-coordinate-conversion\n",
    "    \"\"\"\n",
    "    # takes list xyz (single coord)\n",
    "    x = data[..., 0]\n",
    "    y = data[..., 1]\n",
    "    z = data[..., 2]\n",
    "    r = np.sqrt(x * x + y * y + z * z)\n",
    "    # format in HadCM3: lat:(-90,90), lon(0,360)\n",
    "    theta = 90 - np.arccos(z / r) * 180 / np.pi  # to degrees\n",
    "    phi = 180 + np.arctan2(y, x) * 180 / np.pi\n",
    "    return np.array([theta, phi]).transpose((1, 0))  # careful, this will only work if the shape is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b462f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate colorscale such that all simulations share the same min and max\n",
    "vmin = min([np.amin(r_pred[0]) for r_pred in rescaled_predictions] + [np.amin(gt[0]) for gt in d18O_ico_test])\n",
    "vmax = max([np.amax(r_pred[0]) for r_pred in rescaled_predictions] + [np.amax(gt[0]) for gt in d18O_ico_test])\n",
    "\n",
    "norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax, clip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf52c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ico = []\n",
    "regions = []\n",
    "vertices = []\n",
    "for description in dataset_descriptions:\n",
    "    ico.append(Icosahedron(r=description[\"RESOLUTION\"]))\n",
    "    tmp1, tmp2 = ico[-1].get_voronoi_regions_vertices()\n",
    "    regions.append(tmp1)\n",
    "    vertices.append(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e27f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncomment this to get rescaled sample predictions.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i, i_j in enumerate(indices_dataset):\n",
    "    # for key, value in dataset_descriptions[i_j].items():\n",
    "        # print(key,\": \", value)\n",
    "    for key, value in model_descriptions[i].items():\n",
    "        print(key,\": \", value)\n",
    "    plot_ico_lattice_map(rescaled_predictions[i][0,0].flatten(), vertices[i_j], regions[i_j], norm=norm, cbar_title=r\"{}^{18}\\delta(O)}\")\n",
    "\"\"\"    \n",
    "print(\"uncomment this to get rescaled sample predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7900c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(predictions, targets):\n",
    "    \"\"\"\n",
    "    needs predictions in shape (n_predictions, lat*lon).\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    rmse = np.zeros((predictions.shape[1]))\n",
    "    for i in range(predictions.shape[1]):\n",
    "        rmse[i] = mean_squared_error(targets[:,i], predictions[:,i], squared=False)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "741fa0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_ico = []\n",
    "\n",
    "for i, rescaled_prediction in enumerate(rescaled_predictions):\n",
    "    rmse_ico.append(RMSE(rescaled_prediction.reshape(rescaled_prediction.shape[0],-1), d18O_ico_test[indices_dataset[i]].reshape(d18O_ico_test[indices_dataset[i]].shape[0],-1)))\n",
    "\n",
    "# compute explained variance by dividing rmse by standarddeviation on test set.\n",
    "metric_ico = []\n",
    "for i, rmse in enumerate(rmse_ico):\n",
    "    metric_ico.append(1 - rmse/np.std(d18O_ico_test[indices_dataset[i]].reshape(d18O_ico_test[indices_dataset[i]].shape[0],-1), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3ec8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up colormap\n",
    "colors = [\"#67001f\",\"#b2182b\",\"#d6604d\",\"#f4a582\",\"#fddbc7\",\"#d1e5f0\",\"#92c5de\",\"#4393c3\",\"#2166ac\",\"#053061\"]\n",
    "lim = 1 # math.ceil(np.max(metric))\n",
    "bounds = np.concatenate((np.array([-1.0,-0.8,-0.6,-0.4,-0.2]),np.linspace(0, lim, 6)))\n",
    "cmap= matplotlib.colors.ListedColormap(colors)\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d618859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncomment this to get performance maps for individual runs.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i, data in enumerate(metric_ico):\n",
    "    print(\"Predictor_vars: \", dataset_descriptions[indices_dataset[i]][\"predictor_variables\"])\n",
    "    for key, value in model_descriptions[i].items():\n",
    "        print(key,\": \", value)\n",
    "    plot_ico_lattice_map(data, vertices[indices_dataset[i]], regions[indices_dataset[i]], cmap=cmap, norm=norm, \n",
    "                         title=r\"$R^2$ score, \" + \"Global area weighted average: {:.3f}\".format(np.average(data)))\n",
    "\"\"\"\n",
    "print(\"uncomment this to get performance maps for individual runs.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
