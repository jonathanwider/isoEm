{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating IcoCNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to run the Icosahedral validation MNIST task. \n",
    "\n",
    "Tensorboard files that log the results get stored in the ```Validation/``` subdirectory (gets created if it doesn't exist). \n",
    "\n",
    "Before the notebook can be run, one needs to generate the icosahedral MNIST dataset using the ```validation_experiment_MNIST_gendata.py``` script. To produce the default setup, just run ```python validation_experiment_MNIST_gendata.py```, with no additional arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General description of this notebook\n",
    "The goal of this notebook is to find out whether we can reproduce the results given in \"Gauge Equivariant Convolutional Networks and the Icosahedral CNN\" by Cohen et al. \n",
    "\n",
    "There results from the paper are given in the following, they use the naming convention \"trainingsettype/testsettype\", where traininsettype and testsettype can be in {N, R, I}, where N corresponds to no-rotation, R to fully random rotation and I to a rotation of the symmetrygroup of the icosahedron.\n",
    "\n",
    "Test set accuracies (averaged over 3 runs):\n",
    "\n",
    "N/N: 99.43 <br>\n",
    "N/I: 99.43 <br>\n",
    "N/R: 69.99 <br>\n",
    "I/I: 99.38 <br>\n",
    "I/R: 66.26 <br>\n",
    "R/R: 99.31 <br>\n",
    "\n",
    "Our results (averaged over 3 runs):\n",
    "\n",
    "N/N: 99.23 <br>\n",
    "N/I: 99.34 <br>\n",
    "N/R: 68.57 <br>\n",
    "I/I: 99.27 <br>\n",
    "I/R: 69.31 <br>\n",
    "R/R: 99.37 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results here:\n",
    "\n",
    "# NN\n",
    "print(\"NN\",(99.32 + 99.33 + 99.03)/3)\n",
    "\n",
    "# NI\n",
    "print(\"NI\",(99.41 + 99.32 + 99.30)/3)\n",
    "\n",
    "# NR\n",
    "print(\"NR\",(69.00 + 70.72 + 66)/3)\n",
    "\n",
    "# II\n",
    "print(\"NI\",(99.17 + 99.29 + 99.36)/3)\n",
    "\n",
    "# IR\n",
    "print(\"IR\",(72.35 + 68.18 + 67.4)/3)\n",
    "\n",
    "# RR\n",
    "print(\"RR\",(99.29 + 99.44 + 99.38) / 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture\n",
    "In the supplementary material of their paper [Cohen et al.](https://arxiv.org/abs/1902.04615v1) give details on their architecture. They state:\n",
    "\"Our main model consists of 7 convolution layers and 3 linear layers. The first layer is a scalar-to-regular gauge equivariant convolution layer and the following 6 layers are regular-to-regular layers. These layers have 8,16,16,24,24,32,64 output channels and stride 1, 2,1,2,1,2,1, respectively.\n",
    "\n",
    "In between convolution layers, we use batch normalization and ReLU nonlinearities. When using batch normalization we average over groups of 6 feature maps, to make sure the operation is equivariant. [...].\n",
    "\n",
    "After the convolution layers, we perform global pooling over spatial and orientation channels, yielding an invariant representation. We map these through 3 FC layers (with 64,32,10 channels) before applying softmax.\n",
    "\n",
    "[...]\n",
    "\n",
    "The models were trained for 60 epochs, or 1 epoch of the 60x augmented dataset (where each instance is transformed by each icosahedron symmetry $g \\in \\mathcal{I}$, or by a random rotation $g \\in SO(3)$\"\n",
    "\n",
    "For this experiment, no specification for the batchsize is given. We try to reproduce their architecture as thoroghly as possible in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and definitions\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "from groupy.gconv.pytorch_gconv.p6_conv_axial import P6ConvZ2, P6ConvP6\n",
    "from torch.nn import BatchNorm3d as IcoBatchNorm2d\n",
    "from groupy.gconv.pytorch_gconv.pooling import plane_group_spatial_orientational_max_pooling\n",
    "\n",
    "from icosahedron import Icosahedron, rand_rotation_icosahedron, rand_rotation_matrix, plot_voronoi, plot_voronoi_charts\n",
    "\n",
    "from modules import g_padding_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the configuration of the run.\n",
    "\n",
    "# select which transformations we want to be applied in the dataset that we want to open.\n",
    "train_rot_type = \"no\"\n",
    "test_rot_type = \"no\"\n",
    "output_folder = \"Validate/\"\n",
    "run_nr = 0\n",
    "\n",
    "\n",
    "MNIST_PATH = \"MNIST_data/sph_ico_mnist_train_{}_rot_test_{}_rot.gz\".format(train_rot_type, test_rot_type)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if train_rot_type in [\"ico\", \"full\"]:\n",
    "    NUM_EPOCHS = 1\n",
    "elif train_rot_type == \"no\":\n",
    "    NUM_EPOCHS = 60\n",
    "else:    \n",
    "    raise ValueError(\"Training set rotation type is not valid\")\n",
    "    \n",
    "if test_rot_type in [\"ico\", \"full\"] and train_rot_type ==\"no\":\n",
    "    TEST_INTERVAL = 5 # in this cases the test set is much bigger than the training set - do not compute every epoch\n",
    "else:\n",
    "    TEST_INTERVAL = 1\n",
    "    \n",
    "if test_rot_type not in [\"ico\", \"full\", \"no\"]:\n",
    "    raise ValueError(\"Test set rotation type is not valid\")    \n",
    "\n",
    "# make sure that a MNIST file for the given configuration exists \n",
    "# and that we haven't run any experiments for this config yet    \n",
    "if os.path.isdir('{}/train_{}_rot_test_{}_rot_run_{}'.format(output_folder, train_rot_type, test_rot_type, run_nr)):\n",
    "    raise ValueError(\"A directory for this run already exists\")\n",
    "if not os.path.isfile(MNIST_PATH):\n",
    "    raise ValueError(\"No MNIST file with the given specifications exists.\")\n",
    "    \n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3  # use either this or default ADAM learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some helper layers.  \n",
    "class icoStridedP6ConvP6(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(icoStridedP6ConvP6, self).__init__()\n",
    "        self.conv = P6ConvP6(in_channels = in_channels, \n",
    "            out_channels=out_channels, \n",
    "            kernel_size=3,\n",
    "            stride=2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Because we have g-padding the strided convolution is not trivial. \n",
    "        We need to add rows in order to maintain the right shape. \n",
    "        We do this by adding one row at the bottom of each chart. Afterwards we also need to g_pad the results.\n",
    "        Assume x has shape (batchsize, n_channels, n_stabilizer, n_charts*height, width)\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.conv(x[...,1:,:])\n",
    "        x = F.pad(x,(1,1,1,0)) # pad a single line on the bottom of the image combining the 5 charts\n",
    "        x = x.view(x.shape[0], x.shape[1], x.shape[2], 5, -1, x.shape[-1])\n",
    "        x = F.pad(x,(0,0,0,1))\n",
    "        x = x.view(x.shape[0], x.shape[1], x.shape[2], -1, x.shape[-1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to give dataloaders and datasets\n",
    "\n",
    "def load_data(path, batch_size):\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "        \n",
    "    train_dataset = data_utils.TensorDataset(torch.from_numpy(\n",
    "        dataset[\"train\"][\"images\"][:, None, :, :].astype(np.float32)), torch.from_numpy(\n",
    "        dataset[\"train\"][\"labels\"].astype(np.int64)))\n",
    "    train_loader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    del train_dataset\n",
    "\n",
    "    test_dataset = data_utils.TensorDataset(torch.from_numpy(\n",
    "        dataset[\"test\"][\"images\"][:, None, :, :].astype(np.float32)), torch.from_numpy(\n",
    "        dataset[\"test\"][\"labels\"].astype(np.int64)))\n",
    "    test_loader = data_utils.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    del test_dataset\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reimplement the architecture from the paper:\n",
    "\n",
    "class icoNet_original(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(icoNet_original, self).__init__()        \n",
    "        conv_n_out_channels = [8,16,16,24,24,32,64]\n",
    "        fc_n_out_channels = [64,32,10]\n",
    "        \n",
    "        self.conv1 = P6ConvZ2(1, \n",
    "            out_channels=conv_n_out_channels[0], \n",
    "            kernel_size=3,\n",
    "            padding=1)\n",
    "        self.BN1 = IcoBatchNorm2d(conv_n_out_channels[0])\n",
    "\n",
    "        self.conv2 = icoStridedP6ConvP6(in_channels=conv_n_out_channels[0],\n",
    "            out_channels=conv_n_out_channels[1])\n",
    "        self.BN2 = IcoBatchNorm2d(conv_n_out_channels[1])\n",
    "\n",
    "        \n",
    "        self.conv3 = P6ConvP6(in_channels=conv_n_out_channels[1],\n",
    "            out_channels=conv_n_out_channels[2],\n",
    "            kernel_size=3,\n",
    "            padding=1)\n",
    "        self.BN3 = IcoBatchNorm2d(conv_n_out_channels[2])\n",
    "        \n",
    "        self.conv4 = icoStridedP6ConvP6(in_channels=conv_n_out_channels[2],\n",
    "            out_channels=conv_n_out_channels[3])\n",
    "        self.BN4 = IcoBatchNorm2d(conv_n_out_channels[3])\n",
    "\n",
    "        self.conv5 = P6ConvP6(in_channels=conv_n_out_channels[3],\n",
    "            out_channels=conv_n_out_channels[4],\n",
    "            kernel_size=3,\n",
    "            padding=1)\n",
    "        self.BN5 = IcoBatchNorm2d(conv_n_out_channels[4])\n",
    "        \n",
    "        self.conv6 = icoStridedP6ConvP6(in_channels=conv_n_out_channels[4],\n",
    "            out_channels=conv_n_out_channels[5])\n",
    "        self.BN6 = IcoBatchNorm2d(conv_n_out_channels[5])\n",
    "        \n",
    "        self.conv7 = P6ConvP6(in_channels=conv_n_out_channels[5],\n",
    "            out_channels=conv_n_out_channels[6],\n",
    "            kernel_size=3,\n",
    "            padding=1)\n",
    "        self.BN7 = IcoBatchNorm2d(conv_n_out_channels[6])\n",
    "        \n",
    "        self.FC1 = nn.Linear(conv_n_out_channels[6], fc_n_out_channels[0])\n",
    "        self.BN_FC1 = nn.BatchNorm1d(fc_n_out_channels[0])\n",
    "        self.FC2 = nn.Linear(fc_n_out_channels[0], fc_n_out_channels[1])\n",
    "        self.BN_FC2 = nn.BatchNorm1d(fc_n_out_channels[1])\n",
    "        \n",
    "        # this is the final layer before the output\n",
    "        self.FC3 = nn.Linear(fc_n_out_channels[1], fc_n_out_channels[2])\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Assume input has shape (batchsize, n_charts*height_chart, width)\"\"\"\n",
    "        \n",
    "        # first we need to pad the input with zeros, to have the right shape to apply g-padding\n",
    "        x = x.view(x.shape[0], 1, 5, -1, x.shape[-1])\n",
    "        x = F.pad(x,(1,1,1,1))\n",
    "        x = x.view(x.shape[0], 1, 1, -1, x.shape[-1])\n",
    "        \n",
    "        \n",
    "        #convolution 1\n",
    "        g_padding_full(x, in_stab_size=1) # modifies x\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.BN1(x))\n",
    "        # print(\"layer 1:\", x.shape)        \n",
    "        #convolution 2\n",
    "        g_padding_full(x, in_stab_size=6)\n",
    "        x = self.conv2(x)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.BN2(x))\n",
    "        # print(\"layer 2:\", x.shape) \n",
    "        \n",
    "        #convolution 3\n",
    "        g_padding_full(x, in_stab_size=6)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.BN3(x))\n",
    "        # print(\"layer 3:\", x.shape) \n",
    "        \n",
    "        #convolution 4\n",
    "        g_padding_full(x, in_stab_size=6)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.BN4(x))\n",
    "        # print(\"layer 4:\", x.shape) \n",
    "        \n",
    "        #convolution 5\n",
    "        g_padding_full(x, in_stab_size=6)\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(self.BN5(x))\n",
    "        # print(\"layer 5:\", x.shape) \n",
    "        \n",
    "        #convolution 6\n",
    "        g_padding_full(x, in_stab_size=6)\n",
    "        x = self.conv6(x)\n",
    "        x = F.relu(self.BN6(x))\n",
    "        # print(\"layer 6:\", x.shape) \n",
    "        \n",
    "        #convolution 7\n",
    "        g_padding_full(x, in_stab_size=6)\n",
    "        x = self.conv7(x)\n",
    "        x = F.relu(self.BN7(x))\n",
    "        # print(\"layer 7:\", x.shape) \n",
    "        \n",
    "        # pool over orientations and space\n",
    "        g_padding_full(x, in_stab_size=6)\n",
    "        x = plane_group_spatial_orientational_max_pooling(x)       \n",
    "        \n",
    "        # FC1:\n",
    "        x = F.relu(self.BN_FC1(self.FC1(x)))\n",
    "        \n",
    "        # FC2:\n",
    "        x = F.relu(self.BN_FC2(self.FC2(x)))\n",
    "        \n",
    "        # FC3: (final layer, so no BN and ReLU)\n",
    "        x = self.FC3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Load data\")\n",
    "\n",
    "train_loader, test_loader  = load_data(\n",
    "    MNIST_PATH, BATCH_SIZE)\n",
    "\n",
    "classifier = icoNet_original()\n",
    "classifier.to(DEVICE)\n",
    "\n",
    "running_loss = 0.0\n",
    "writer = SummaryWriter('{}/train_{}_rot_test_{}_rot_run_{}'.format(output_folder, train_rot_type, test_rot_type, run_nr))\n",
    "\n",
    "print(\"Set up model\")\n",
    "print(\"#params\", sum(x.numel() for x in classifier.parameters()))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(\"Start training\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        classifier.train()\n",
    "\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # every 100 mini-batches...\n",
    "            # ...log the running loss\n",
    "            print('\\rEpoch [{0}/{1}], Iter [{2}/{3}] Loss: {4:.4f}'.format(\n",
    "                epoch+1, NUM_EPOCHS, i+1, len(train_loader),\n",
    "                running_loss/100), end=\"\")\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 100,\n",
    "                            epoch * len(train_loader) + i)\n",
    "            running_loss = 0\n",
    "    running_loss = 0\n",
    "    print(\"\\n\")\n",
    "\n",
    "    if epoch % TEST_INTERVAL == TEST_INTERVAL-1:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "\n",
    "            classifier.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                images = images.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                outputs = classifier(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).long().sum().item()\n",
    "\n",
    "        writer.add_scalar('test accuracy',\n",
    "                            100 * correct / total,\n",
    "                            epoch)\n",
    "        print('Test Accuracy: {0}'.format(100 * correct / total))\n",
    "        \n",
    "del test_loader\n",
    "del train_loader\n",
    "del classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_isoem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "30ad1e9751a335964297ef996aff34ffc1f818b7ffbfece5b83cbe701e88e9d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
