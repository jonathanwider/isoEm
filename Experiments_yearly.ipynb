{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ddbeb10",
   "metadata": {},
   "source": [
    "# Notebook to reproduce isotope emulation experiments on yearly time scale."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d7c8a0e",
   "metadata": {},
   "source": [
    "This notebook requires the climate data sets to be downloaded. This can be done by running `python download_required_files.py --createico`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "from train import *\n",
    "from predict import *\n",
    "from evaluate import *\n",
    "from util import *\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edaa874e",
   "metadata": {},
   "source": [
    "## 1) Create datasets.\n",
    "\n",
    "As a first step, we need to create data sets that can be loaded by pytorch from the climate model data. \n",
    "\n",
    "In the following cells, this is done for all yearly configurations used in the paper."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1d5847b",
   "metadata": {},
   "source": [
    "### Dataset 1: Predictor variables: Surface temperature, precipitation amount, flat grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb49a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration choices: \n",
    "\n",
    "base_folder = \"Datasets\"  # location of the raw data set\n",
    "output_folder = \"Output/Reproduce_new\"  # location the data set will be output to\n",
    "\n",
    "description = {}  # dict to store parameters of the dataset creation\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\", \n",
    "                                \"prec\"]  # which data set files we want to use\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}  # which variables we want to use as inputs. Specified as \"filename\": [\"varname\"] (potentially also multiple variables can be imported from same file)\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}  # which variables we want to use as outputs.\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]  # data sets we require not to have any gaps in their time axis. This is mostly legacy code, there are no gaps in the current version of the raw data sets.\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"  # the climate model whose data we want to train on\n",
    "description[\"GRID_TYPE\"] = \"Flat\"  # the type of grid (Flat, Ico) we want to use\n",
    "\n",
    "description[\"START_YEAR\"] = 850  # only use time steps starting from this year within the data set (in CE)\n",
    "description[\"END_YEAR\"] = 1850  # only use time steps before this year within the data set (in CE)\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]  # there are no isotopes computed at the poles for iHadCM3. Thus we mask out the first and last value of the latitudes\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750  # year to use for splitting into train and test set. Splitting can also be performed by using TEST_FRACTION (e.g. description[\"TEST_FRACTION\"] = 0.1 to split of 10%) instead of specifying a fixed split year\n",
    "description[\"DO_SHUFFLE\"] = False  # whether to shuffle the data set before the split. Has no effect if using a split by year, only if using TEST_FRACTION.\n",
    "description[\"PRECIP_WEIGHTING\"] = False  # Whether or not to weight by precipitation amount, when computing yearly values\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\"  # timescale we operate on (alternative in other notebook: MONTHLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94133b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7a2902d",
   "metadata": {},
   "source": [
    "The data set will appear inside a new folder within the `output_folder`. The name of the created subfolder encodes the chosen data set configuration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5738b00a",
   "metadata": {},
   "source": [
    "### Dataset 2: Predictor variables: Surface temperature, flat grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330fd3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration choices: \n",
    "\n",
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c97e26d7",
   "metadata": {},
   "source": [
    "### Dataset 3: Predictor variables: Surface temperature, flat grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd2215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration choices:\n",
    "\n",
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af2d587",
   "metadata": {},
   "source": [
    "### Dataset 4: Predictor variables: Surface temperature, precipitation amount, flat grid, weigh by precipitation amount when computing yearly mean from monthly means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf89fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration choices:\n",
    "\n",
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = True  # take note: here we set this to true!\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734600ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_precip_weighted_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c38aa91",
   "metadata": {},
   "source": [
    "### Dataset 5: Predictor variables: Surface temperature, precipitation amount, icosahedral grid\n",
    "\n",
    "Running this cell requires climate data on the icosahedral grid. This can be done by setting `--createico` when running the `download_required_files.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4f2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration choices:\n",
    "\n",
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Ico\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "description[\"RESOLUTION\"] = 5  # refinement level of the icosahedral grid\n",
    "description[\"INTERPOLATE_CORNERS\"] = True  # whether or not also the corner pixels were interpolated (i.e. the 12 vertices of the unrefined icosahedron), by default this is True.\n",
    "description[\"INTERPOLATION\"] = \"cons1\"  # the interpolation scheme that was used to create the interpolated climate data set\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a25077f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e20c6e3",
   "metadata": {},
   "source": [
    "## 2) Run experiments yearly dataset\n",
    "\n",
    "Now we are ready to train ML methods on these data sets.\n",
    "\n",
    "Test set predictions are stored in the directory specified by `output_folder`. They can later be used in to evaluate performance and create plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b4b41ce",
   "metadata": {},
   "source": [
    "### Testing the effect of modifications to flat UNet:\n",
    "\n",
    "First task: Check, which effect the modifications to the standard flat UNet have on the performance. As a reminder, these modifications are: \n",
    "\n",
    "1) using CoordConv\n",
    "2) using cyclical padding in longitudinal direction\n",
    "3) using an area-weighted loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b4a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of the data set to be selected:\n",
    "\n",
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d242f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the input variables, can be chosen individually for each variable\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]  # how to standardize the output variables, can be chosen individually for each variable\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder  # folder in which the created datasets are located in, this is also the directory in which the results of the run will be stored in by default\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"  # the type of machine learning model\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True  # whether we want to create a validation set. Is necessary in some cases, e.g. when using early stopping.\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True  # whether to split up the validation set randomly or not\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # can also be set to integer values. However, than we don't need a validation set and the corresponding parameter choices need to be adjusted (model_training_description[\"CREATE_VALIDATIONSET\"] = False)\n",
    "model_training_description[\"PATIENCE\"] = 5  # how many consequtive epochs without a new global validation set minimum in the loss before we abort training\n",
    "model_training_description[\"BATCH_SIZE\"] = 8  # batch size of input data\n",
    "model_training_description[\"LEARNING_RATE\"] = 1e-3  # learning rate used by adam optimizer\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3  # 'depth' steps in the UNet architecture, see architecture sketch.\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))  # number of input channels to the network. Should match the number of input variables, i.e. 2 (precipitation amount, temperature) in default setup\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32  # channels after first convolutional layer\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))  # number of output channels, equals 1 in all applications here.\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)  # number of features at various depths in the UNet architecture. See architecture sketch for details.\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU  # nonlinearity used\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # the kind of normalization used\n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"  # the optimizer used for training\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # device to train on: GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bc42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [\"Masked_MSELoss\", \"Masked_AreaWeightedMSELoss\"]\n",
    "use_coord_conv = [False, True]\n",
    "use_cylindrical_padding = [False, True]\n",
    "n_runs = 10  # number of runs to do for each configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all possible configurations of using/not using certain modifications\n",
    "for l in loss:\n",
    "    for c_conv in use_coord_conv:\n",
    "        for c_pad in use_cylindrical_padding:\n",
    "            for i in range(n_runs):\n",
    "                print(l, c_conv, c_pad, i)\n",
    "                model_training_description[\"USE_CYLINDRICAL_PADDING\"] = c_pad\n",
    "                model_training_description[\"USE_COORD_CONV\"] = c_conv\n",
    "                model_training_description[\"LOSS\"] = l  # \"MSELoss\" # \"AreaWeightedMSELoss\"\n",
    "                model_training_description[\"RUN_NR\"] = i\n",
    "                unet = train_unet(description, model_training_description, output_folder)\n",
    "                predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79af46e8",
   "metadata": {},
   "source": [
    "### Comparing different ML methods:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26f322b3",
   "metadata": {},
   "source": [
    "In the following, we test a variety of different ML methods on the isotope emulation task. There are methods that work on the flat grid, and methods that work on the icosahedral grid.\n",
    "\n",
    "\n",
    "Results for different versions of the flat UNet are already obtained in last cell."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0b39d7a",
   "metadata": {},
   "source": [
    "### Methods that work on the flat grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404cf512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of the data set to be selected:\n",
    "\n",
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "468e92cc",
   "metadata": {},
   "source": [
    "### Linear regression baseline:\n",
    "\n",
    "Train a very simple pixel-wise linear regression baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3171580",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"LinReg_Pixelwise\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0629af",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = train_linreg_pixelwise(description, model_training_description, output_folder)\n",
    "predict_save_linreg_pixelwise(description, model_training_description, output_folder, models, output_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c61aba6b",
   "metadata": {},
   "source": [
    "### PCA-regression baseline:\n",
    "\n",
    "Reduce spaces of inputs and outputs, then do regression between reduced spaces, more details in paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"]\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"PCA_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = False\n",
    "\n",
    "model_training_description[\"REGTYPE\"] = \"linreg\"  # the type of regression used between the reduced spaces. Lasso regression can also be applied here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afb57476",
   "metadata": {},
   "source": [
    "We approximate the \"ideal\" dimensionalities of reduced input and output spaces by doing hyperparameter tuning.\n",
    "\n",
    "This is done by a simple grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73634a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pc_range = np.logspace(np.log10(3), np.log10(700), 50)\n",
    "n_pc_in, n_pc_out = np.meshgrid(n_pc_range, n_pc_range)\n",
    "n_pc_in = n_pc_in.flatten().astype(\"int\")\n",
    "n_pc_out = n_pc_out.flatten().astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ad49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_tune_pca import train_tune_pca\n",
    "pca, pca_targets, model = train_tune_pca(description, model_training_description, output_folder, \\\n",
    "                                                    n_pc_in=n_pc_in, n_pc_out=n_pc_out)\n",
    "predict_save_pca(description, model_training_description, output_folder, pca, pca_targets, model, output_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7bb4f1e",
   "metadata": {},
   "source": [
    "### Random-forest baseline:\n",
    "\n",
    "Train a single random forest regression model to work pixel-wise, but for all grid boxes. While training also coordinates get added to the intput variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb0233",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"]\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"RandomForest_Pixelwise\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74416dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_random_forest_pixelwise(description, model_training_description, output_folder, verbose=3, n_jobs=-1)\n",
    "predict_save_randomforest_pixelwise(description, model_training_description, output_folder, model, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d766e0bd",
   "metadata": {},
   "source": [
    "### Icosahedral grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f14fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of the data set to be loaded.\n",
    "\n",
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Ico\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "description[\"RESOLUTION\"] = 5\n",
    "description[\"INTERPOLATE_CORNERS\"] = True\n",
    "description[\"INTERPOLATION\"] = \"cons1\"\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d724648f",
   "metadata": {},
   "source": [
    "### PCA baseline on icosahedral grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7421985",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"PCA_Ico\"  # model type is now PCA_Ico instead of PCA_Flat\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = False\n",
    "\n",
    "model_training_description[\"REGTYPE\"] = \"linreg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01964634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid of values to seach to obtain ideal hyperparametrs\n",
    "n_pc_range = np.logspace(np.log10(3), np.log10(700), 20)\n",
    "n_pc_in, n_pc_out = np.meshgrid(n_pc_range, n_pc_range)\n",
    "n_pc_in = n_pc_in.flatten().astype(\"int\")\n",
    "n_pc_out = n_pc_out.flatten().astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f136a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_tune_pca import train_tune_pca\n",
    "pca, pca_targets, model = train_tune_pca(description, model_training_description, output_folder, \\\n",
    "                                                    n_pc_in=n_pc_in, n_pc_out=n_pc_out)\n",
    "\n",
    "predict_save_pca(description, model_training_description, output_folder, pca, pca_targets, model, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b4266",
   "metadata": {},
   "source": [
    "### Ico UNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534db2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Ico\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 1e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = IcoBatchNorm2d # the icosahedral UNet requires a special kind of batch norm to maintain its equivariance properties\n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "model_training_description[\"LOSS\"] = \"MSELoss\"  # in the icosahedral case, we don't weigh by area - all grid boxes in the icosahedral grid are of approximately identical size.\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90f139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "for i in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = i\n",
    "    unet = train_unet(description, model_training_description, output_folder)\n",
    "    predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eadbf8e0",
   "metadata": {},
   "source": [
    "## Comparing different predictor variables\n",
    "\n",
    "To assess what effects the individual input/predictor variables have on the emulation, we test using only one of them as input variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "771f8e08",
   "metadata": {},
   "source": [
    "### Using only surface temperature as input variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\"\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 1e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd01b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "for i in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = i\n",
    "    unet = train_unet(description, model_training_description, output_folder)\n",
    "    predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "075438b1",
   "metadata": {},
   "source": [
    "### Using only precipitation amount as input variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea388ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\"\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 1e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "for i in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = i\n",
    "    unet = train_unet(description, model_training_description, output_folder, use_tensorboard=True)\n",
    "    predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "781aad21",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "We test if we can further improve results by changing hyperparameters of the modified flat network architecture.\n",
    "\n",
    "### Learning rate tuning:\n",
    "We test a list of logarithmically spaced learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba323ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.logspace(-4,-1,20)\n",
    "runs_per_lr = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d75ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\",\n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\"\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all learning rates and save results\n",
    "for lr in lrs:\n",
    "    for i in range(runs_per_lr):\n",
    "        model_training_description[\"RUN_NR\"] = i\n",
    "        model_training_description[\"LEARNING_RATE\"] = lr \n",
    "        unet = train_unet(description, model_training_description, output_folder)\n",
    "        predict_save_unet(description, model_training_description, output_folder, unet, output_folder)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3a010c0",
   "metadata": {},
   "source": [
    "### UNet wider:\n",
    "\n",
    "A wider version of the modified flat UNet architecture, the numbers of features computed per channel are modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bda222",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\",\n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\"\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 1e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 64  # this is now twice the standard value\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (64,64,128,128)  # this is now twice the standard value\n",
    "\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "for i in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = i\n",
    "    unet = train_unet(description, model_training_description, output_folder)\n",
    "    predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e3898bb",
   "metadata": {},
   "source": [
    "### UNet deeper:\n",
    "\n",
    "Adding an additional \"depth step\" to the flat UNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d342a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\",\n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\"\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "# training parameters\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 4 # this changes compared to standard UNet\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 1e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,128,128) # this changes compared to standard UNet\n",
    "\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "for i in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = i\n",
    "    unet = train_unet(description, model_training_description, output_folder)\n",
    "    predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f98051b",
   "metadata": {},
   "source": [
    "# 3) Precipitation weighting \n",
    "\n",
    "Test how much the results differ if we weight by precipitation amount in the creation of the yearly dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"Output/Reproduce_new\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\",\n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = True\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\"\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 1e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b72386",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "for i in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = i\n",
    "    unet = train_unet(description, model_training_description, output_folder)\n",
    "    predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_isoem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "30ad1e9751a335964297ef996aff34ffc1f818b7ffbfece5b83cbe701e88e9d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
