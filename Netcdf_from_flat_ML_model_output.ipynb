{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to compare to other methods we need to interpolate data back to regular grid. To be able to interpolate back to regular data, we need to create a .nc file that we can give to cdo.\n",
    "\n",
    "Only process one dataset folder at a time.\n",
    "\n",
    "Doesn't work for precip weighted at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=E1101,R,C\n",
    "import numpy as np\n",
    "import gzip\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from braceexpand import braceexpand\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY_DATASETS_INTERPOLATED = \"Datasets/Interpolated/\"\n",
    "DIRECTORY_DATASETS_ORIGINAL = \"Datasets/Original/\"\n",
    "DIRECTORY_IMAGES = \"Images/\"\n",
    "DIRECTORY_SCRIPTS = \"Scripts/\"\n",
    "DIRECTORY_OUTPUTS = \"Output/Compare_UNet_architectures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dict_conditions(dic, conditions):\n",
    "    \"\"\"\n",
    "    Test whether dict \"dic\" fullfills the given conditions \"conditions\". \n",
    "    The latter are given as a array of key-value pairs.\n",
    "    \"\"\"\n",
    "    for key, value in conditions:\n",
    "        if key in dic.keys():\n",
    "            if not dic[key] == value:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def braced_glob(path):\n",
    "    l = []\n",
    "    for x in braceexpand(path):\n",
    "        l.extend(glob.glob(x))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  -0x5e008a71f7450afc\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  False\n",
      "USE_COORD_CONV :  False\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  6\n",
      "#params :  315809\n",
      "\n",
      "\n",
      "Path:  -0x6cfcd55c64e6f28f\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  6\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  -0x2b9c5a345d1c1235\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  False\n",
      "USE_COORD_CONV :  False\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  9\n",
      "#params :  315809\n",
      "\n",
      "\n",
      "Path:  -0x1e415b9efeb75e1c\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  False\n",
      "USE_COORD_CONV :  False\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  0\n",
      "#params :  315809\n",
      "\n",
      "\n",
      "Path:  -0x39a8d24453ce7c6d\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  7\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  0x6576e7bb3ff7d6ef\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  2\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  -0x3c8c7e92fe985678\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  AreaWeightedMSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  4\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  0x1694502457ea41fe\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  False\n",
      "USE_COORD_CONV :  False\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  2\n",
      "#params :  315809\n",
      "\n",
      "\n",
      "Path:  -0x567015d9e2421bb0\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  False\n",
      "USE_COORD_CONV :  False\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  8\n",
      "#params :  315809\n",
      "\n",
      "\n",
      "Path:  -0x7cce9452a7f01f0d\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  False\n",
      "USE_COORD_CONV :  False\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  4\n",
      "#params :  315809\n",
      "\n",
      "\n",
      "Path:  0x292a563e708dc410\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  0\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  -0x227ec182a88b84a3\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  4\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  0xa8fed26f2a4f010\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  AreaWeightedMSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  9\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  -0x18f52ab1deda33ba\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  1\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  0x2eca9a8e376a00d2\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  AreaWeightedMSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  3\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  -0x499545b75043a2a1\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  AreaWeightedMSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  0\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  -0x6a7dfc878d59fe87\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  AreaWeightedMSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  2\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  -0x557705cd7b2f9dc2\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  False\n",
      "USE_COORD_CONV :  False\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  1\n",
      "#params :  315809\n",
      "\n",
      "\n",
      "Path:  0x13f53aac95207893\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  AreaWeightedMSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  7\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  -0x107947d8c201f8c7\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  AreaWeightedMSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  1\n",
      "#params :  647685\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  -0x1d3e5b0d85482bc3\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  False\n",
      "USE_COORD_CONV :  False\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  3\n",
      "#params :  315809\n",
      "\n",
      "\n",
      "Path:  0x166c4e94b8f4cd1d\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  8\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  classical_-0x2707cda662bf4a04\n",
      "MODELTYPE :  Classical_flat\n",
      "S_MODE_PREDICTORS :  ('Global', 'Global')\n",
      "S_MODE_TARGETS :  ('Global',)\n",
      "REGTYPE :  lasso\n",
      "n_pc_in :  300\n",
      "n_pc_target :  450\n",
      "\n",
      "\n",
      "Path:  -0xe33b6bfe1f0c2c1\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  AreaWeightedMSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  6\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  -0x4e3b7bab066ac265\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  AreaWeightedMSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  5\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  0x71a97c7e93122c8b\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  AreaWeightedMSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  8\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  0x5ecce47718004c02\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  5\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  -0x2c4b271d357ed5a1\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  3\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  0x2af262d339463fe0\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  False\n",
      "USE_COORD_CONV :  False\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  5\n",
      "#params :  315809\n",
      "\n",
      "\n",
      "Path:  0x31f8698e665edbb5\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  True\n",
      "USE_COORD_CONV :  True\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  9\n",
      "#params :  647685\n",
      "\n",
      "\n",
      "Path:  -0x2c2e6fdc562a6e18\n",
      "MODELTYPE :  UNet_flat\n",
      "DEPTH :  3\n",
      "NUM_EPOCHS :  early_stopping\n",
      "BATCH_SIZE :  8\n",
      "LEARNING_RATE :  0.005\n",
      "IN_CHANNELS :  2\n",
      "CHANNELS_FIRST_CONV :  32\n",
      "OUT_CHANNELS :  1\n",
      "FMAPS :  (32, 32, 64, 64)\n",
      "USE_CYLINDRICAL_PADDING :  False\n",
      "USE_COORD_CONV :  False\n",
      "ACTIVATION :  <class 'torch.nn.modules.activation.ReLU'>\n",
      "NORMALIZATION :  <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "S_MODE_PREDICTORS :  ('Pixelwise', 'Pixelwise')\n",
      "S_MODE_TARGETS :  ('Pixelwise',)\n",
      "loss :  MSELoss\n",
      "optimizer :  Adam\n",
      "RUN_NR :  7\n",
      "#params :  315809\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset parameters. To leave unspecified use: \"*\"\n",
    "PREFIX = \"HadCM3-flat\"#{-precip*,}\"\n",
    "DO_SHUFFLE = False\n",
    "ALL_VARIABLES = np.sort([\"temp_1\",\"precip\",\"dO18\"])#np.sort([\"temp_1\",\"precip\",\"dO18\"])  # \"*\" get all possible combinations \n",
    "DSET_NR = \"1\"\n",
    "# helping vars\n",
    "shuffle_dict = {True:\"shuffle\", False:\"no-shuffle\", \"*\": \"*\"}\n",
    "\n",
    "# wildcards can be used in this filename.\n",
    "DATASET_FOLDER = \"{}_{}_{}_\".format(PREFIX, shuffle_dict[DO_SHUFFLE], DSET_NR)#shuffle_dict[DO_SHUFFLE]\n",
    "DATASET_FOLDER = DATASET_FOLDER + \"-\".join(ALL_VARIABLES) # using \"*\" + \"-\".join(ALL_VARIABLES) instead of DATASET_FOLDER + ... makes it possible to use ico folders too.\n",
    "DATASET_FOLDER = os.path.join(DIRECTORY_OUTPUTS, DATASET_FOLDER)\n",
    "\n",
    "\n",
    "dataset_description_files = []  # list to collect the paths to the configuration files\n",
    "dataset_folders = []  # list to collect all the matching folders.\n",
    "folder_exists = False\n",
    "\n",
    "if not os.path.exists(DATASET_FOLDER):\n",
    "    raise OSError(\"There exists no folder for the given specifications\")\n",
    "\n",
    "    \n",
    "DATASET_DESCRIPTION_FILE = os.path.join(DATASET_FOLDER, \"dataset-description.gz\")\n",
    "\n",
    "with gzip.open(DATASET_DESCRIPTION_FILE, 'rb') as f:\n",
    "    dataset_description = pickle.load(f)\n",
    "\n",
    "\n",
    "model_descriptions = []\n",
    "testset_predictions = []\n",
    "model_descriptions_paths = []\n",
    "\n",
    "# specify the conditions that we want the runs to match\n",
    "conditions = []# [()\"NUM_EPOCHS\",3)]\n",
    "\n",
    "\n",
    "subdirs = [d for d in os.listdir(DATASET_FOLDER) if os.path.isdir(os.path.join(DATASET_FOLDER, d))]\n",
    "\n",
    "for subdir in subdirs:\n",
    "    files = [f for f in os.listdir(os.path.join(DATASET_FOLDER, subdir)) if os.path.isfile(os.path.join(DATASET_FOLDER, subdir, f))]   \n",
    "    if \"model_training_description.gz\" in files and \"predictions.gz\" in files:        \n",
    "        # this is a valid description of a model run. Store path and print description\n",
    "        with gzip.open(os.path.join(DATASET_FOLDER, subdir, \"model_training_description.gz\"), 'rb') as f:\n",
    "            tmp_description = pickle.load(f)\n",
    "            if check_dict_conditions(tmp_description, conditions):  # check if the description satisfies our conditions\n",
    "                model_descriptions.append(tmp_description)      \n",
    "                model_descriptions_paths.append(os.path.join(DATASET_FOLDER, subdir))\n",
    "                print(\"Path: \", subdir)\n",
    "                for key, value in model_descriptions[-1].items():\n",
    "                    print(key,\": \", value)\n",
    "                print(\"\\n\")\n",
    "\n",
    "                with gzip.open(os.path.join(DATASET_FOLDER, subdir, \"predictions.gz\"), 'rb') as g:\n",
    "                    testset_predictions.append(pickle.load(g))       \n",
    "    else:\n",
    "        print(\"Encountered Invalid directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Get required ground truth\n",
    "(Requires grid_description only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable: ['dO18']\n"
     ]
    }
   ],
   "source": [
    "print(\"Target variable:\", dataset_description[\"target_variables\"])\n",
    "\n",
    "required_files = []\n",
    "\n",
    "if dataset_description[\"target_variables\"][0] == \"dO18\":\n",
    "    for filename in dataset_description[\"files_used\"]:\n",
    "        if \"isotopes\" in filename:\n",
    "            required_files.append(filename)\n",
    "else:\n",
    "    raise NotImplementedError(\"Currently only d18O is a valid target variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of datasets to which we want not to be missing at any timestep.\n",
    "dnames = [DIRECTORY_DATASETS_ORIGINAL+\"xnapa_isotopes.nc\",\\\n",
    "          DIRECTORY_DATASETS_ORIGINAL+\"xnapa_precip.nc\",\\\n",
    "          DIRECTORY_DATASETS_ORIGINAL+\"xnapa_slp.nc\",\\\n",
    "          DIRECTORY_DATASETS_ORIGINAL+\"xnapa_temp.nc\"]\n",
    "\n",
    "def get_shared_timesteps(dataset_names):\n",
    "    \"\"\"\n",
    "    Not all datasets share the same timesteps. The biggest problems occur in the slp dataset. We want to exclude all\n",
    "    time steps where one of the variables is missing\n",
    "    \"\"\"\n",
    "    \n",
    "    # get indices of elements that are shared for all variables.\n",
    "    from functools import reduce\n",
    "    ts = tuple([nc.Dataset(dataset_name,\"a\").variables[\"t\"][:].data for dataset_name in dataset_names])\n",
    "    common_dates = reduce(np.intersect1d, ts)\n",
    "    \n",
    "    return common_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "isotopes_dset = nc.Dataset(required_files[0], \"a\")\n",
    "\n",
    "lat = isotopes_dset.variables[\"latitude\"][:].data[1:-1]\n",
    "lon = isotopes_dset.variables[\"longitude\"][:]\n",
    "\n",
    "t = isotopes_dset.variables[\"t\"][:].data\n",
    "t_bnds = isotopes_dset.variables[\"t_bnds\"][:]\n",
    "\n",
    "c_dates = get_shared_timesteps(dnames)\n",
    "# get the corresponding indices:\n",
    "indices = []\n",
    "for j, t_ in enumerate(isotopes_dset.variables[\"t\"][:].data):\n",
    "    if t_ in c_dates:\n",
    "        indices.append(j)\n",
    "indices = np.array(indices)\n",
    "index_mask = np.logical_and(isotopes_dset.variables[\"t\"][indices].data // 360 >= 654, \\\n",
    "                            isotopes_dset.variables[\"t\"][indices].data // 360 < 1654)    \n",
    "indices = indices[index_mask]  \n",
    "\n",
    "d18O = np.squeeze(isotopes_dset.variables[\"dO18\"][:].data)[indices,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d18O_train = d18O[dataset_description[\"indices_train\"],...]\n",
    "d18O_test = d18O[dataset_description[\"indices_test\"],...]\n",
    "\n",
    "t_train = t[dataset_description[\"indices_train\"],...]\n",
    "t_test = t[dataset_description[\"indices_test\"],...]\n",
    "\n",
    "t_bnds_train = t_bnds[dataset_description[\"indices_train\"],...]\n",
    "t_bnds_test = t_bnds[dataset_description[\"indices_test\"],...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) undo the standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to compare with the original dataset \n",
    "# we need to rescale the prediction based on the standardization that we used in the model\n",
    "\n",
    "rescaled_predictions = []\n",
    "\n",
    "for i, description in enumerate(model_descriptions):\n",
    "    rescaled_predictions.append([])\n",
    "    for j, mode in enumerate(description[\"S_MODE_TARGETS\"]):\n",
    "        if mode == \"Global\":\n",
    "            std = np.mean(np.std(d18O_train, axis=(0), keepdims=True), axis=(1,2), keepdims=True)\n",
    "            std[std==0] = 1\n",
    "            mean = np.mean(d18O_train, axis=(0,1,2), keepdims=True)\n",
    "            rescaled_predictions[-1].append((testset_predictions[i][\"predictions\"][:,j,...] * std) + mean)             \n",
    "        elif mode == \"Pixelwise\":        \n",
    "            std = np.std(d18O_train, axis=(0), keepdims=True)\n",
    "            std[std==0] = 1\n",
    "            mean = np.mean(d18O_train, axis=(0), keepdims=True)\n",
    "            rescaled_predictions[-1].append((testset_predictions[i][\"predictions\"][:,j,...] * std) + mean)   \n",
    "        elif mode == \"Global_mean_pixelwise_std\":\n",
    "            std = np.mean(np.std(d18O_train, axis=(0), keepdims=True), axis=(1,2), keepdims=True)\n",
    "            std[std==0] = 1\n",
    "            mean = np.mean(d18O_train, axis=(0), keepdims=True)\n",
    "            rescaled_predictions[-1].append((testset_predictions[i][\"predictions\"][:,j,...] * std) + mean)           \n",
    "        elif mode == \"Pixelwise_mean_global_std\":\n",
    "            std = np.std(d18O_train, axis=(0), keepdims=True)\n",
    "            std[std==0] = 1\n",
    "            mean = np.mean(d18O_train, axis=(0,1,2), keepdims=True)\n",
    "            rescaled_predictions[-1].append((testset_predictions[i][\"predictions\"][:,j,...] * std) + mean)  \n",
    "        elif mode == \"None\":\n",
    "            rescaled_predictions[-1].append(testset_predictions[i][\"predictions\"])\n",
    "        else:\n",
    "            raise NotImplementedError(\"{} is not a valid keyword for standardization\".format(mode))\n",
    "    rescaled_predictions[-1] = np.stack(rescaled_predictions[-1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tocopy = ['longitude', 'latitude',]\n",
    "dimscopy =['t', 'bnds', 'longitude', 'latitude']\n",
    "\n",
    "\n",
    "\n",
    "for i, model_description_path in enumerate(model_descriptions_paths):\n",
    "    for filename in required_files:\n",
    "        original_dimensions  = nc.Dataset(filename).variables[\"dO18\"].dimensions\n",
    "        necessary_dimensions = (original_dimensions[0], original_dimensions[2], original_dimensions[3])\n",
    "        original_dataype     = nc.Dataset(filename).variables[\"dO18\"].datatype\n",
    "\n",
    "        \n",
    "        netcdf4_path = os.path.splitext(model_description_path)[0]+\"_flat.nc\"\n",
    "\n",
    "        src = nc.Dataset(filename)\n",
    "        dst = nc.Dataset(netcdf4_path, \"w\")\n",
    "        # copy global attributes all at once via dictionary\n",
    "        dst.setncatts(src.__dict__)\n",
    "        # copy dimensions\n",
    "        for name, dimension in src.dimensions.items():\n",
    "            if name in dimscopy:\n",
    "                dst.createDimension(name, (len(dimension) if not dimension.isunlimited() else None))\n",
    "        # copy all file data except for the excluded\n",
    "        for name, variable in src.variables.items():\n",
    "            if name in tocopy:\n",
    "                x = dst.createVariable(name, variable.datatype, variable.dimensions)\n",
    "                dst[name][:] = src[name][:]\n",
    "                # copy variable attributes all at once via dictionary\n",
    "                dst[name].setncatts(src[name].__dict__)\n",
    "\n",
    "        target_var_attribute_dict = nc.Dataset(filename).variables[\"dO18\"].__dict__\n",
    "        dst.createVariable(\"dO18\", original_dataype, necessary_dimensions)\n",
    "        dst.variables[\"dO18\"].setncatts(target_var_attribute_dict)\n",
    "        dst.createVariable(\"t\", \"float64\", (\"t\"))\n",
    "        dst.createVariable(\"t_bnds\", \"float64\", (\"t\",\"bnds\"))\n",
    "        dst.variables[\"t\"][:] = t_test\n",
    "        dst.variables[\"t_bnds\"][:] = t_bnds_test\n",
    "        tmp = np.pad(np.squeeze(rescaled_predictions[i]),((0,0),(1,1),(0,0)), 'constant', \\\n",
    "                     constant_values=target_var_attribute_dict[\"missing_value\"])\n",
    "        dst.variables[\"dO18\"][:] = tmp\n",
    "\n",
    "        # print(dst.)\n",
    "        dst.close()\n",
    "        src.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
