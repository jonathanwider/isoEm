{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2adc7e17",
   "metadata": {},
   "source": [
    "# Crossprediction - Yearly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "52732d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from predict import *\n",
    "from datasets import *\n",
    "from train import *\n",
    "from evaluate import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da67423b",
   "metadata": {},
   "source": [
    "### Create HadCM3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2058c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\",\n",
    "                                   ]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1, -1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\"\"\"\n",
    "description[\"RESOLUTION\"] = 5\n",
    "description[\"INTERPOLATE_CORNERS\"] = True\n",
    "description[\"INTERPOLATION\"] = \"cons1\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e50bacd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "Specified dataset already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14492/1541587748.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreate_yearly_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Uni\\IsoEm\\datasets.py\u001b[0m in \u001b[0;36mcreate_yearly_dataset\u001b[1;34m(description, dataset_folder, output_folder)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_if_folder_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Specified dataset already exists.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: Specified dataset already exists."
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995553fd",
   "metadata": {},
   "source": [
    "### Create GISS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28429da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description_GISS = {}\n",
    "\n",
    "description_GISS[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                        \"tsurf\", \n",
    "                                        \"prec\"]\n",
    "\n",
    "description_GISS[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                              \"prec\": [\"prec\"]}\n",
    "\n",
    "description_GISS[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description_GISS[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                           \"tsurf\", \n",
    "                                           \"prec\",\n",
    "                                           ]\n",
    "\n",
    "description_GISS[\"CLIMATE_MODEL\"] = \"GISS\"\n",
    "description_GISS[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description_GISS[\"START_YEAR\"] = 850\n",
    "description_GISS[\"END_YEAR\"] = 1850\n",
    "description_GISS[\"LATITUDES_SLICE\"] = [1, -1]\n",
    "\n",
    "description_GISS[\"TEST_FRACTION\"] = 0.1\n",
    "description_GISS[\"DO_SHUFFLE\"] = False\n",
    "description_GISS[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\"\"\"\n",
    "description_GISS[\"RESOLUTION\"] = 5\n",
    "description_GISS[\"INTERPOLATE_CORNERS\"] = True\n",
    "description_GISS[\"INTERPOLATION\"] = \"cons1\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "description_GISS[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ea5cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_yearly_dataset(description_GISS, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f07090",
   "metadata": {},
   "source": [
    "### Create iCESM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "252e892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description_iCESM = {}\n",
    "\n",
    "description_iCESM[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                        \"tsurf\", \n",
    "                                        \"prec\"]\n",
    "\n",
    "description_iCESM[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                              \"prec\": [\"prec\"]}\n",
    "\n",
    "description_iCESM[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description_iCESM[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                           \"tsurf\", \n",
    "                                           \"prec\",\n",
    "                                           ]\n",
    "\n",
    "description_iCESM[\"CLIMATE_MODEL\"] = \"iCESM\"\n",
    "description_iCESM[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description_iCESM[\"START_YEAR\"] = 850\n",
    "description_iCESM[\"END_YEAR\"] = 1850\n",
    "description_iCESM[\"LATITUDES_SLICE\"] = [1, -1]\n",
    "\n",
    "description_iCESM[\"TEST_FRACTION\"] = 0.1\n",
    "description_iCESM[\"DO_SHUFFLE\"] = False\n",
    "description_iCESM[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\"\"\"\n",
    "description_iCESM[\"RESOLUTION\"] = 5\n",
    "description_iCESM[\"INTERPOLATE_CORNERS\"] = True\n",
    "description_iCESM[\"INTERPOLATION\"] = \"cons1\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "description_iCESM[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32337bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yearly_dataset(description_iCESM, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3600cd9",
   "metadata": {},
   "source": [
    "### Create isoGSM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "196aeb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description_isoGSM = {}\n",
    "\n",
    "description_isoGSM[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                        \"tsurf\", \n",
    "                                        \"prec\"]\n",
    "\n",
    "description_isoGSM[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                              \"prec\": [\"prec\"]}\n",
    "\n",
    "description_isoGSM[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description_isoGSM[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                           \"tsurf\", \n",
    "                                           \"prec\",\n",
    "                                           ]\n",
    "\n",
    "description_isoGSM[\"CLIMATE_MODEL\"] = \"isoGSM\"\n",
    "description_isoGSM[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description_isoGSM[\"START_YEAR\"] = 850\n",
    "description_isoGSM[\"END_YEAR\"] = 1850\n",
    "description_isoGSM[\"LATITUDES_SLICE\"] = [1, -1]\n",
    "\n",
    "description_isoGSM[\"TEST_FRACTION\"] = 0.1\n",
    "description_isoGSM[\"DO_SHUFFLE\"] = False\n",
    "description_isoGSM[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\"\"\"\n",
    "description_isoGSM[\"RESOLUTION\"] = 5\n",
    "description_isoGSM[\"INTERPOLATE_CORNERS\"] = True\n",
    "description_isoGSM[\"INTERPOLATION\"] = \"cons1\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "description_isoGSM[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a269d66d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description_isoGSM, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e946c",
   "metadata": {},
   "source": [
    "### Create ECHAM5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "499c57ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description_ECHAM5 = {}\n",
    "\n",
    "description_ECHAM5[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                        \"tsurf\", \n",
    "                                        \"prec\"]\n",
    "\n",
    "description_ECHAM5[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                              \"prec\": [\"prec\"]}\n",
    "\n",
    "description_ECHAM5[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description_ECHAM5[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                           \"tsurf\", \n",
    "                                           \"prec\",\n",
    "                                           ]\n",
    "\n",
    "description_ECHAM5[\"CLIMATE_MODEL\"] = \"ECHAM5\"\n",
    "description_ECHAM5[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description_ECHAM5[\"START_YEAR\"] = 850\n",
    "description_ECHAM5[\"END_YEAR\"] = 1850\n",
    "description_ECHAM5[\"LATITUDES_SLICE\"] = [1, -1]\n",
    "\n",
    "description_ECHAM5[\"TEST_FRACTION\"] = 0.1\n",
    "description_ECHAM5[\"DO_SHUFFLE\"] = False\n",
    "description_ECHAM5[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\"\"\"\n",
    "description_ECHAM5[\"RESOLUTION\"] = 5\n",
    "description_ECHAM5[\"INTERPOLATE_CORNERS\"] = True\n",
    "description_ECHAM5[\"INTERPOLATION\"] = \"cons1\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "description_ECHAM5[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "374da362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description_ECHAM5, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05f383",
   "metadata": {},
   "source": [
    "### Train UNet on iHadCM3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ce0351f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\",\n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\"\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "# training parameters\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 4 # this changes compared to standard UNet\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 1e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,128,128)\n",
    "\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "592ba3a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch [1], Iter [91/101] Loss: 0.6637\n",
      "Epoch [2], Iter [91/101] Loss: 0.6675\n",
      "Epoch [3], Iter [91/101] Loss: 0.5930\n",
      "Epoch [4], Iter [91/101] Loss: 0.5710\n",
      "Epoch [5], Iter [91/101] Loss: 0.6934\n",
      "Epoch [6], Iter [91/101] Loss: 0.5823\n",
      "Epoch [7], Iter [91/101] Loss: 0.5856\n",
      "Epoch [8], Iter [91/101] Loss: 0.5405\n",
      "Epoch [9], Iter [91/101] Loss: 0.5803\n",
      "Epoch [10], Iter [91/101] Loss: 0.5368\n",
      "Epoch [11], Iter [91/101] Loss: 0.5514\n",
      "Epoch [12], Iter [91/101] Loss: 0.5311\n",
      "Epoch [13], Iter [91/101] Loss: 0.5186\n",
      "Epoch [14], Iter [91/101] Loss: 0.5136\n",
      "Epoch [15], Iter [91/101] Loss: 0.5214\n",
      "Epoch [16], Iter [91/101] Loss: 0.5221\n",
      "Epoch [17], Iter [91/101] Loss: 0.4998\n",
      "Epoch [18], Iter [91/101] Loss: 0.4980\n",
      "Epoch [19], Iter [91/101] Loss: 0.5526\n",
      "Epoch [20], Iter [91/101] Loss: 0.5379\n",
      "Test MSE: 0.6241970062255859\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1544: RuntimeWarning: overflow encountered in multiply\n",
      "  sqr = np.multiply(arr, arr, out=arr)\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "Starting training\n",
      "Epoch [1], Iter [91/101] Loss: 0.6598\n",
      "Epoch [2], Iter [91/101] Loss: 0.7830\n",
      "Epoch [3], Iter [91/101] Loss: 0.5727\n",
      "Epoch [4], Iter [91/101] Loss: 0.6258\n",
      "Epoch [5], Iter [91/101] Loss: 0.5996\n",
      "Epoch [6], Iter [91/101] Loss: 0.5704\n",
      "Epoch [7], Iter [91/101] Loss: 0.5850\n",
      "Epoch [8], Iter [91/101] Loss: 0.5689\n",
      "Epoch [9], Iter [91/101] Loss: 0.5284\n",
      "Epoch [10], Iter [91/101] Loss: 0.5386\n",
      "Epoch [11], Iter [91/101] Loss: 0.5390\n",
      "Epoch [12], Iter [91/101] Loss: 0.5238\n",
      "Epoch [13], Iter [91/101] Loss: 0.5522\n",
      "Epoch [14], Iter [91/101] Loss: 0.5074\n",
      "Epoch [15], Iter [91/101] Loss: 0.5217\n",
      "Epoch [16], Iter [91/101] Loss: 0.5189\n",
      "Epoch [17], Iter [91/101] Loss: 0.5216\n",
      "Epoch [18], Iter [91/101] Loss: 0.4972\n",
      "Test MSE: 0.619145393371582\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "Starting training\n",
      "Epoch [1], Iter [91/101] Loss: 0.6275\n",
      "Epoch [2], Iter [91/101] Loss: 0.6070\n",
      "Epoch [3], Iter [91/101] Loss: 0.6136\n",
      "Epoch [4], Iter [91/101] Loss: 0.6095\n",
      "Epoch [5], Iter [91/101] Loss: 0.5954\n",
      "Epoch [6], Iter [91/101] Loss: 0.5902\n",
      "Epoch [7], Iter [91/101] Loss: 0.5776\n",
      "Epoch [8], Iter [91/101] Loss: 0.5451\n",
      "Epoch [9], Iter [91/101] Loss: 0.5504\n",
      "Epoch [10], Iter [91/101] Loss: 0.5112\n",
      "Epoch [11], Iter [91/101] Loss: 0.5360\n",
      "Epoch [12], Iter [91/101] Loss: 0.5457\n",
      "Test MSE: 0.6398264765739441\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "Starting training\n",
      "Epoch [1], Iter [91/101] Loss: 0.8221\n",
      "Epoch [2], Iter [91/101] Loss: 0.6331\n",
      "Epoch [3], Iter [91/101] Loss: 0.5839\n",
      "Epoch [4], Iter [91/101] Loss: 0.5773\n",
      "Epoch [5], Iter [91/101] Loss: 0.5755\n",
      "Epoch [6], Iter [91/101] Loss: 0.5708\n",
      "Epoch [7], Iter [91/101] Loss: 0.5441\n",
      "Epoch [8], Iter [91/101] Loss: 0.5750\n",
      "Epoch [9], Iter [91/101] Loss: 0.5757\n",
      "Epoch [10], Iter [91/101] Loss: 0.5477\n",
      "Epoch [11], Iter [91/101] Loss: 0.5156\n",
      "Epoch [12], Iter [91/101] Loss: 0.5269\n",
      "Epoch [13], Iter [91/101] Loss: 0.5336\n",
      "Epoch [14], Iter [91/101] Loss: 0.5827\n",
      "Epoch [15], Iter [91/101] Loss: 0.5080\n",
      "Test MSE: 0.6222359538078308\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "Starting training\n",
      "Epoch [1], Iter [91/101] Loss: 0.6254\n",
      "Epoch [2], Iter [91/101] Loss: 0.6221\n",
      "Epoch [3], Iter [91/101] Loss: 0.5980\n",
      "Epoch [4], Iter [91/101] Loss: 0.5960\n",
      "Epoch [5], Iter [91/101] Loss: 0.5754\n",
      "Epoch [6], Iter [91/101] Loss: 0.5624\n",
      "Epoch [7], Iter [91/101] Loss: 0.6874\n",
      "Epoch [8], Iter [91/101] Loss: 0.5962\n",
      "Epoch [9], Iter [91/101] Loss: 0.5446\n",
      "Epoch [10], Iter [91/101] Loss: 0.5532\n",
      "Epoch [11], Iter [91/101] Loss: 0.5396\n",
      "Epoch [12], Iter [91/101] Loss: 0.5331\n",
      "Epoch [13], Iter [91/101] Loss: 0.5416\n",
      "Epoch [14], Iter [91/101] Loss: 0.6042\n",
      "Epoch [15], Iter [91/101] Loss: 0.5108\n",
      "Epoch [16], Iter [91/101] Loss: 0.5330\n",
      "Epoch [17], Iter [91/101] Loss: 0.5110\n",
      "Epoch [18], Iter [91/101] Loss: 0.4896\n",
      "Epoch [19], Iter [91/101] Loss: 0.5088\n",
      "Epoch [20], Iter [91/101] Loss: 0.4790\n",
      "Test MSE: 0.6144453287124634\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "Starting training\n",
      "Epoch [1], Iter [91/101] Loss: 0.6590\n",
      "Epoch [2], Iter [91/101] Loss: 0.6269\n",
      "Epoch [3], Iter [91/101] Loss: 0.6165\n",
      "Epoch [4], Iter [91/101] Loss: 0.5938\n",
      "Epoch [5], Iter [91/101] Loss: 0.5898\n",
      "Epoch [6], Iter [91/101] Loss: 0.5670\n",
      "Epoch [7], Iter [91/101] Loss: 0.5480\n",
      "Epoch [8], Iter [91/101] Loss: 0.6004\n",
      "Epoch [9], Iter [91/101] Loss: 0.5297\n",
      "Epoch [10], Iter [91/101] Loss: 1.3172\n",
      "Epoch [11], Iter [91/101] Loss: 0.5396\n",
      "Epoch [12], Iter [91/101] Loss: 0.6141\n",
      "Epoch [13], Iter [91/101] Loss: 0.5422\n",
      "Epoch [14], Iter [91/101] Loss: 0.5279\n",
      "Epoch [15], Iter [91/101] Loss: 0.5127\n",
      "Epoch [16], Iter [91/101] Loss: 0.5984\n",
      "Epoch [17], Iter [91/101] Loss: 0.5230\n",
      "Epoch [18], Iter [91/101] Loss: 0.4959\n",
      "Epoch [19], Iter [91/101] Loss: 0.4832\n",
      "Epoch [20], Iter [91/101] Loss: 0.4811\n",
      "Epoch [21], Iter [91/101] Loss: 0.4711\n",
      "Epoch [22], Iter [91/101] Loss: 0.4964\n",
      "Epoch [23], Iter [91/101] Loss: 0.4631\n",
      "Epoch [24], Iter [91/101] Loss: 0.4634\n",
      "Test MSE: 0.6215145587921143\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "Starting training\n",
      "Epoch [1], Iter [91/101] Loss: 0.6470\n",
      "Epoch [2], Iter [91/101] Loss: 0.6200\n",
      "Epoch [3], Iter [91/101] Loss: 0.6324\n",
      "Epoch [4], Iter [91/101] Loss: 0.6620\n",
      "Epoch [5], Iter [91/101] Loss: 0.5673\n",
      "Epoch [6], Iter [91/101] Loss: 0.5879\n",
      "Epoch [7], Iter [91/101] Loss: 0.5624\n",
      "Epoch [8], Iter [91/101] Loss: 0.5706\n",
      "Epoch [9], Iter [91/101] Loss: 0.5714\n",
      "Epoch [10], Iter [91/101] Loss: 0.5569\n",
      "Epoch [11], Iter [91/101] Loss: 0.5746\n",
      "Epoch [12], Iter [91/101] Loss: 0.5340\n",
      "Epoch [13], Iter [91/101] Loss: 0.5207\n",
      "Epoch [14], Iter [91/101] Loss: 0.5316\n",
      "Epoch [15], Iter [91/101] Loss: 0.4827\n",
      "Epoch [16], Iter [91/101] Loss: 0.4977\n",
      "Epoch [17], Iter [91/101] Loss: 0.4929\n",
      "Epoch [18], Iter [91/101] Loss: 0.4869\n",
      "Epoch [19], Iter [91/101] Loss: 0.4865\n",
      "Epoch [20], Iter [91/101] Loss: 0.4574\n",
      "Test MSE: 0.6289946436882019\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "Starting training\n",
      "Epoch [1], Iter [91/101] Loss: 0.6737\n",
      "Epoch [2], Iter [91/101] Loss: 0.6616\n",
      "Epoch [3], Iter [91/101] Loss: 0.6108\n",
      "Epoch [4], Iter [91/101] Loss: 0.7144\n",
      "Epoch [5], Iter [91/101] Loss: 0.5732\n",
      "Epoch [6], Iter [91/101] Loss: 0.5615\n",
      "Epoch [7], Iter [91/101] Loss: 0.5529\n",
      "Epoch [8], Iter [91/101] Loss: 0.5952\n",
      "Epoch [9], Iter [91/101] Loss: 0.5647\n",
      "Epoch [10], Iter [91/101] Loss: 0.5625\n",
      "Epoch [11], Iter [91/101] Loss: 0.5362\n",
      "Epoch [12], Iter [91/101] Loss: 0.5203\n",
      "Epoch [13], Iter [91/101] Loss: 0.5488\n",
      "Epoch [14], Iter [91/101] Loss: 0.5223\n",
      "Epoch [15], Iter [91/101] Loss: 0.4995\n",
      "Epoch [16], Iter [91/101] Loss: 0.5105\n",
      "Epoch [17], Iter [91/101] Loss: 0.5017\n",
      "Epoch [18], Iter [91/101] Loss: 0.4797\n",
      "Epoch [19], Iter [91/101] Loss: 0.4746\n",
      "Epoch [20], Iter [91/101] Loss: 0.4826\n",
      "Epoch [21], Iter [91/101] Loss: 0.4636\n",
      "Epoch [22], Iter [91/101] Loss: 0.4618\n",
      "Epoch [23], Iter [91/101] Loss: 0.4517\n",
      "Epoch [24], Iter [91/101] Loss: 0.4564\n",
      "Test MSE: 0.6180621385574341\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "Starting training\n",
      "Epoch [1], Iter [91/101] Loss: 0.6663\n",
      "Epoch [2], Iter [91/101] Loss: 0.6037\n",
      "Epoch [3], Iter [91/101] Loss: 0.5945\n",
      "Epoch [4], Iter [91/101] Loss: 0.5911\n",
      "Epoch [5], Iter [91/101] Loss: 0.6020\n",
      "Epoch [6], Iter [91/101] Loss: 0.6434\n",
      "Epoch [7], Iter [91/101] Loss: 0.5767\n",
      "Epoch [8], Iter [91/101] Loss: 0.5649\n",
      "Epoch [9], Iter [91/101] Loss: 0.5373\n",
      "Epoch [10], Iter [91/101] Loss: 0.6327\n",
      "Epoch [11], Iter [91/101] Loss: 0.5412\n",
      "Epoch [12], Iter [91/101] Loss: 0.5274\n",
      "Epoch [13], Iter [91/101] Loss: 0.5276\n",
      "Epoch [14], Iter [91/101] Loss: 0.5222\n",
      "Epoch [15], Iter [91/101] Loss: 0.5113\n",
      "Epoch [16], Iter [91/101] Loss: 0.4682\n",
      "Epoch [17], Iter [91/101] Loss: 0.5162\n",
      "Epoch [18], Iter [91/101] Loss: 0.4828\n",
      "Epoch [19], Iter [91/101] Loss: 0.4823\n",
      "Epoch [20], Iter [91/101] Loss: 0.4779\n",
      "Epoch [21], Iter [91/101] Loss: 0.4798\n",
      "Epoch [22], Iter [91/101] Loss: 0.4591\n",
      "Test MSE: 0.6224232912063599\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "Starting training\n",
      "Epoch [1], Iter [91/101] Loss: 0.6451\n",
      "Epoch [2], Iter [91/101] Loss: 0.7172\n",
      "Epoch [3], Iter [91/101] Loss: 0.6069\n",
      "Epoch [4], Iter [91/101] Loss: 0.5713\n",
      "Epoch [5], Iter [91/101] Loss: 0.5452\n",
      "Epoch [6], Iter [91/101] Loss: 0.7822\n",
      "Epoch [7], Iter [91/101] Loss: 0.5740\n",
      "Epoch [8], Iter [91/101] Loss: 0.5562\n",
      "Epoch [9], Iter [91/101] Loss: 0.5462\n",
      "Epoch [10], Iter [91/101] Loss: 0.5368\n",
      "Epoch [11], Iter [91/101] Loss: 0.5373\n",
      "Epoch [12], Iter [91/101] Loss: 0.5400\n",
      "Epoch [13], Iter [91/101] Loss: 0.5248\n",
      "Epoch [14], Iter [91/101] Loss: 0.5327\n",
      "Epoch [15], Iter [91/101] Loss: 0.5338\n",
      "Epoch [16], Iter [91/101] Loss: 0.5049\n",
      "Epoch [17], Iter [91/101] Loss: 0.5234\n",
      "Epoch [18], Iter [91/101] Loss: 0.4879\n",
      "Epoch [19], Iter [91/101] Loss: 0.4744\n",
      "Epoch [20], Iter [91/101] Loss: 0.4752\n",
      "Epoch [21], Iter [91/101] Loss: 0.4652\n",
      "Epoch [22], Iter [91/101] Loss: 0.4502\n",
      "Epoch [23], Iter [91/101] Loss: 0.4352\n",
      "Epoch [24], Iter [91/101] Loss: 0.4688\n",
      "Test MSE: 0.6327361464500427\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "n_runs=10\n",
    "for i in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = i\n",
    "    unet = train_unet(description, model_training_description, output_folder)           \n",
    "    predict_save_unet(description, model_training_description, output_folder, unet, output_folder)\n",
    "    predict_save_unet(description_iCESM, model_training_description, output_folder, unet, output_folder)\n",
    "    predict_save_unet(description_GISS, model_training_description, output_folder, unet, output_folder)\n",
    "    predict_save_unet(description_isoGSM, model_training_description, output_folder, unet, output_folder)\n",
    "    predict_save_unet(description_ECHAM5, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a6bc6a",
   "metadata": {},
   "source": [
    "### Train linreg on iHadCM3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f74a446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"LinReg_Pixelwise\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = False\n",
    "# model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\",\n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c325671",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = train_linreg_pixelwise(description, model_training_description, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e31a1a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions\n",
      "writing descriptions\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1544: RuntimeWarning: overflow encountered in multiply\n",
      "  sqr = np.multiply(arr, arr, out=arr)\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "predict_save_linreg_pixelwise(description, model_training_description, output_folder, models, output_folder)\n",
    "predict_save_linreg_pixelwise(description_iCESM, model_training_description, output_folder, models, output_folder)\n",
    "predict_save_linreg_pixelwise(description_GISS, model_training_description, output_folder, models, output_folder)\n",
    "predict_save_linreg_pixelwise(description_isoGSM, model_training_description, output_folder, models, output_folder)\n",
    "predict_save_linreg_pixelwise(description_ECHAM5, model_training_description, output_folder, models, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c3a29e",
   "metadata": {},
   "source": [
    "### Train new PCA baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d37d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Crossprediction\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\",\n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\"\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"PCA_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = False\n",
    "\n",
    "model_training_description[\"REGTYPE\"] = \"linreg\"\n",
    "\n",
    "n_pc_range = np.logspace(np.log10(3), np.log10(700), 20)\n",
    "n_pc_in, n_pc_out = np.meshgrid(n_pc_range, n_pc_range)\n",
    "n_pc_in = n_pc_in.flatten().astype(\"int\")\n",
    "n_pc_out = n_pc_out.flatten().astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1f9557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best results: N_PC_IN: 222 N_PC_OUT: 125, R2_mean, validationset: [0.17122209340467706]706]\n",
      "Retrain including validation set.\n",
      "Result on test set: [0.17883165687822988]\n"
     ]
    }
   ],
   "source": [
    "from train_tune_pca import train_tune_pca\n",
    "pca, pca_targets, model = train_tune_pca(description, model_training_description, output_folder, \\\n",
    "                                                    n_pc_in=n_pc_in, n_pc_out=n_pc_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3c6b77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions\n",
      "writing descriptions\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1544: RuntimeWarning: overflow encountered in multiply\n",
      "  sqr = np.multiply(arr, arr, out=arr)\n",
      "C:\\Users\\49159\\Anaconda3\\envs\\GrouPyTorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "predict_save_pca(description, model_training_description, output_folder, pca, pca_targets, model, output_folder)\n",
    "predict_save_pca(description_iCESM, model_training_description, output_folder, pca, pca_targets, model, output_folder)\n",
    "predict_save_pca(description_GISS, model_training_description, output_folder, pca, pca_targets, model, output_folder)\n",
    "predict_save_pca(description_isoGSM, model_training_description, output_folder, pca, pca_targets, model, output_folder)\n",
    "predict_save_pca(description_ECHAM5, model_training_description, output_folder, pca, pca_targets, model, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0 (default, Nov  6 2019, 16:00:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "90b409070de10f2c3c5a8c504ecede612c695480a2027d21529fbe1a33a534d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
