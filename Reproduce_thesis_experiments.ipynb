{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd1b770",
   "metadata": {},
   "source": [
    "# Reimplement thesis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e90607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "from train import *\n",
    "from predict import *\n",
    "from evaluate import *\n",
    "from util import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d62b8e1",
   "metadata": {},
   "source": [
    "## 1) Create yearly datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f047f5b9",
   "metadata": {},
   "source": [
    "### tas, pr, oro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d10fe2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\", \n",
    "                                \"precip\",\n",
    "                                \"oro\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"],\n",
    "                                      \"oro\": [\"ht\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "624fd208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512d24d",
   "metadata": {},
   "source": [
    "## Tas, pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80769317",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\", \n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c02346b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7a6fe",
   "metadata": {},
   "source": [
    "### tas, pr, slp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "832fa64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\", \n",
    "                                \"precip\",\n",
    "                                \"slp\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"],\n",
    "                                      \"slp\": [\"p\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d667a126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3254bb9e",
   "metadata": {},
   "source": [
    "### tas only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b0669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "154cd2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916970ee",
   "metadata": {},
   "source": [
    "### pr only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c23b7388",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ab0c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef46d1a",
   "metadata": {},
   "source": [
    "### slp only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b7e15d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"slp\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"slp\": [\"p\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "027ca037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5cce60",
   "metadata": {},
   "source": [
    "### pr, tas precip weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e9ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\", \n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = True\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cb889c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_precip_weighted_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b338477",
   "metadata": {},
   "source": [
    "### pr, tas ico grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31b74e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\", \n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Ico\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "description[\"RESOLUTION\"] = 5\n",
    "description[\"INTERPOLATE_CORNERS\"] = True\n",
    "description[\"INTERPOLATION\"] = \"cons1\"\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f42125f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n",
      "done\n",
      "writing dataset description\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "create_yearly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ea85e",
   "metadata": {},
   "source": [
    "## 2) Run experiments yearly dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed8d56",
   "metadata": {},
   "source": [
    "### 4.2.1 Modifications to flat UNet\n",
    "\n",
    "Start by selecting the tas, pr dataset without precipitation weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcf2fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\", \n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f8117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 5e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbaabda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [\"MSELoss\", \"AreaWeightedMSELoss\"]\n",
    "use_coord_conv = [False, True]\n",
    "use_cylindrical_padding = [False, True]\n",
    "n_runs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28270b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss False False 0\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6557\n",
      "Epoch [2], Iter [91/100] Loss: 0.5712\n",
      "Epoch [3], Iter [91/100] Loss: 0.6023\n",
      "Epoch [4], Iter [91/100] Loss: 0.5961\n",
      "Epoch [5], Iter [91/100] Loss: 0.5699\n",
      "Epoch [6], Iter [91/100] Loss: 0.5561\n",
      "Epoch [7], Iter [91/100] Loss: 0.5205\n",
      "Epoch [8], Iter [91/100] Loss: 0.5594\n",
      "Epoch [9], Iter [91/100] Loss: 0.5128\n",
      "Epoch [10], Iter [91/100] Loss: 0.4911\n",
      "Epoch [11], Iter [91/100] Loss: 0.4878\n",
      "Epoch [12], Iter [91/100] Loss: 0.4895\n",
      "Epoch [13], Iter [91/100] Loss: 0.4894\n",
      "Epoch [14], Iter [91/100] Loss: 0.4628\n",
      "Test MSE: 0.5992493033409119\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "MSELoss False False 1\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6553\n",
      "Epoch [2], Iter [91/100] Loss: 0.6439\n",
      "Epoch [3], Iter [91/100] Loss: 0.6331\n",
      "Epoch [4], Iter [91/100] Loss: 0.5686\n",
      "Epoch [5], Iter [91/100] Loss: 0.5887\n",
      "Epoch [6], Iter [91/100] Loss: 0.5612\n",
      "Epoch [7], Iter [91/100] Loss: 0.5254\n",
      "Epoch [8], Iter [91/100] Loss: 0.5143\n",
      "Epoch [9], Iter [91/100] Loss: 0.5136\n",
      "Epoch [10], Iter [91/100] Loss: 0.4972\n",
      "Epoch [11], Iter [91/100] Loss: 0.4848\n",
      "Epoch [12], Iter [91/100] Loss: 0.5006\n",
      "Epoch [13], Iter [91/100] Loss: 0.4925\n",
      "Epoch [14], Iter [91/100] Loss: 0.4531\n",
      "Epoch [15], Iter [91/100] Loss: 0.4541\n",
      "Test MSE: 0.6149067878723145\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "MSELoss False False 2\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6300\n",
      "Epoch [2], Iter [91/100] Loss: 0.6411\n",
      "Epoch [3], Iter [91/100] Loss: 0.5822\n",
      "Epoch [4], Iter [91/100] Loss: 0.5678\n",
      "Epoch [5], Iter [91/100] Loss: 0.5905\n",
      "Epoch [6], Iter [91/100] Loss: 0.6485\n",
      "Epoch [7], Iter [91/100] Loss: 0.5585\n",
      "Epoch [8], Iter [91/100] Loss: 0.5083\n",
      "Epoch [9], Iter [91/100] Loss: 0.6059\n",
      "Epoch [10], Iter [91/100] Loss: 0.4910\n",
      "Epoch [11], Iter [91/100] Loss: 0.5139\n",
      "Epoch [12], Iter [91/100] Loss: 0.4822\n",
      "Epoch [13], Iter [91/100] Loss: 0.4669\n",
      "Epoch [14], Iter [91/100] Loss: 0.4596\n",
      "Epoch [15], Iter [91/100] Loss: 0.4464\n",
      "Epoch [16], Iter [91/100] Loss: 0.4449\n",
      "Epoch [17], Iter [91/100] Loss: 0.4312\n",
      "Test MSE: 0.6015509963035583\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "MSELoss False True 0\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6534\n",
      "Epoch [2], Iter [91/100] Loss: 0.6429\n",
      "Epoch [3], Iter [91/100] Loss: 0.6112\n",
      "Epoch [4], Iter [91/100] Loss: 0.5961\n",
      "Epoch [5], Iter [91/100] Loss: 0.5564\n",
      "Epoch [6], Iter [91/100] Loss: 0.5510\n",
      "Epoch [7], Iter [91/100] Loss: 0.5467\n",
      "Epoch [8], Iter [91/100] Loss: 0.5289\n",
      "Epoch [9], Iter [91/100] Loss: 0.5333\n",
      "Epoch [10], Iter [91/100] Loss: 0.5109\n",
      "Epoch [11], Iter [91/100] Loss: 0.5474\n",
      "Epoch [12], Iter [91/100] Loss: 0.4747\n",
      "Epoch [13], Iter [91/100] Loss: 0.4703\n",
      "Epoch [14], Iter [91/100] Loss: 0.4499\n",
      "Epoch [15], Iter [91/100] Loss: 0.4455\n",
      "Epoch [16], Iter [91/100] Loss: 0.4439\n",
      "Epoch [17], Iter [91/100] Loss: 0.4306\n",
      "Test MSE: 0.5977465510368347\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "MSELoss False True 1\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6916\n",
      "Epoch [2], Iter [91/100] Loss: 0.6069\n",
      "Epoch [3], Iter [91/100] Loss: 0.6133\n",
      "Epoch [4], Iter [91/100] Loss: 0.5733\n",
      "Epoch [5], Iter [91/100] Loss: 0.5568\n",
      "Epoch [6], Iter [91/100] Loss: 0.5422\n",
      "Epoch [7], Iter [91/100] Loss: 0.5573\n",
      "Epoch [8], Iter [91/100] Loss: 0.5230\n",
      "Epoch [9], Iter [91/100] Loss: 0.5118\n",
      "Epoch [10], Iter [91/100] Loss: 0.5171\n",
      "Epoch [11], Iter [91/100] Loss: 0.4839\n",
      "Epoch [12], Iter [91/100] Loss: 0.4979\n",
      "Epoch [13], Iter [91/100] Loss: 0.4528\n",
      "Epoch [14], Iter [91/100] Loss: 0.4566\n",
      "Epoch [15], Iter [91/100] Loss: 0.4604\n",
      "Epoch [16], Iter [91/100] Loss: 0.4627\n",
      "Epoch [17], Iter [91/100] Loss: 0.4643\n",
      "Test MSE: 0.6029780507087708\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "MSELoss False True 2\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6997\n",
      "Epoch [2], Iter [91/100] Loss: 0.6354\n",
      "Epoch [3], Iter [91/100] Loss: 0.6387\n",
      "Epoch [4], Iter [91/100] Loss: 0.5758\n",
      "Epoch [5], Iter [91/100] Loss: 0.5496\n",
      "Epoch [6], Iter [91/100] Loss: 0.5501\n",
      "Epoch [7], Iter [91/100] Loss: 0.5180\n",
      "Epoch [8], Iter [91/100] Loss: 0.5095\n",
      "Epoch [9], Iter [91/100] Loss: 0.5090\n",
      "Epoch [10], Iter [91/100] Loss: 0.5022\n",
      "Epoch [11], Iter [91/100] Loss: 0.5006\n",
      "Epoch [12], Iter [91/100] Loss: 0.4815\n",
      "Epoch [13], Iter [91/100] Loss: 0.4762\n",
      "Epoch [14], Iter [91/100] Loss: 0.4418\n",
      "Test MSE: 0.5897265672683716\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "MSELoss True False 0\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6330\n",
      "Epoch [2], Iter [91/100] Loss: 0.6325\n",
      "Epoch [3], Iter [91/100] Loss: 0.5935\n",
      "Epoch [4], Iter [91/100] Loss: 0.5888\n",
      "Epoch [5], Iter [91/100] Loss: 0.5840\n",
      "Epoch [6], Iter [91/100] Loss: 0.5730\n",
      "Epoch [7], Iter [91/100] Loss: 0.5903\n",
      "Epoch [8], Iter [91/100] Loss: 0.5795\n",
      "Epoch [9], Iter [91/100] Loss: 0.5388\n",
      "Epoch [10], Iter [91/100] Loss: 0.5459\n",
      "Epoch [11], Iter [91/100] Loss: 0.5314\n",
      "Epoch [12], Iter [91/100] Loss: 0.5155\n",
      "Epoch [13], Iter [91/100] Loss: 0.5170\n",
      "Epoch [14], Iter [91/100] Loss: 0.5072\n",
      "Epoch [15], Iter [91/100] Loss: 0.5077\n",
      "Epoch [16], Iter [91/100] Loss: 0.4775\n",
      "Epoch [17], Iter [91/100] Loss: 0.4861\n",
      "Epoch [18], Iter [91/100] Loss: 0.4677\n",
      "Epoch [19], Iter [91/100] Loss: 0.4439\n",
      "Epoch [20], Iter [91/100] Loss: 0.4630\n",
      "Epoch [21], Iter [91/100] Loss: 0.4391\n",
      "Test MSE: 0.5894666910171509\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "MSELoss True False 1\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6576\n",
      "Epoch [2], Iter [91/100] Loss: 0.6190\n",
      "Epoch [3], Iter [91/100] Loss: 0.6131\n",
      "Epoch [4], Iter [91/100] Loss: 0.5714\n",
      "Epoch [5], Iter [91/100] Loss: 0.5767\n",
      "Epoch [6], Iter [91/100] Loss: 0.5509\n",
      "Epoch [7], Iter [91/100] Loss: 0.5523\n",
      "Epoch [8], Iter [91/100] Loss: 0.5391\n",
      "Epoch [9], Iter [91/100] Loss: 0.5414\n",
      "Epoch [10], Iter [91/100] Loss: 0.5211\n",
      "Epoch [11], Iter [91/100] Loss: 0.5416\n",
      "Epoch [12], Iter [91/100] Loss: 0.5361\n",
      "Epoch [13], Iter [91/100] Loss: 0.5141\n",
      "Epoch [14], Iter [91/100] Loss: 0.5251\n",
      "Epoch [15], Iter [91/100] Loss: 0.4875\n",
      "Epoch [16], Iter [91/100] Loss: 0.4922\n",
      "Epoch [17], Iter [91/100] Loss: 0.4750\n",
      "Test MSE: 0.5780728459358215\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "MSELoss True False 2\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6065\n",
      "Epoch [2], Iter [91/100] Loss: 0.6135\n",
      "Epoch [3], Iter [91/100] Loss: 0.6107\n",
      "Epoch [4], Iter [91/100] Loss: 0.5801\n",
      "Epoch [5], Iter [91/100] Loss: 0.5429\n",
      "Epoch [6], Iter [91/100] Loss: 0.5629\n",
      "Epoch [7], Iter [91/100] Loss: 0.5539\n",
      "Epoch [8], Iter [91/100] Loss: 0.5586\n",
      "Epoch [9], Iter [91/100] Loss: 0.5428\n",
      "Epoch [10], Iter [91/100] Loss: 0.5418\n",
      "Epoch [11], Iter [91/100] Loss: 0.5077\n",
      "Epoch [12], Iter [91/100] Loss: 0.5076\n",
      "Epoch [13], Iter [91/100] Loss: 0.5152\n",
      "Epoch [14], Iter [91/100] Loss: 0.5023\n",
      "Test MSE: 0.5847901701927185\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "MSELoss True True 0\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6278\n",
      "Epoch [2], Iter [91/100] Loss: 0.6273\n",
      "Epoch [3], Iter [91/100] Loss: 0.6361\n",
      "Epoch [4], Iter [91/100] Loss: 0.6109\n",
      "Epoch [5], Iter [91/100] Loss: 0.5967\n",
      "Epoch [6], Iter [91/100] Loss: 0.5614\n",
      "Epoch [7], Iter [91/100] Loss: 0.6548\n",
      "Epoch [8], Iter [91/100] Loss: 0.5525\n",
      "Epoch [9], Iter [91/100] Loss: 0.5461\n",
      "Epoch [10], Iter [91/100] Loss: 0.5434\n",
      "Epoch [11], Iter [91/100] Loss: 0.5370\n",
      "Epoch [12], Iter [91/100] Loss: 0.5365\n",
      "Epoch [13], Iter [91/100] Loss: 0.5190\n",
      "Epoch [14], Iter [91/100] Loss: 0.5111\n",
      "Epoch [15], Iter [91/100] Loss: 0.5177\n",
      "Epoch [16], Iter [91/100] Loss: 0.4837\n",
      "Epoch [17], Iter [91/100] Loss: 0.4665\n",
      "Epoch [18], Iter [91/100] Loss: 0.4849\n",
      "Epoch [19], Iter [91/100] Loss: 0.4677\n",
      "Epoch [20], Iter [91/100] Loss: 0.4683\n",
      "Epoch [21], Iter [91/100] Loss: 0.4661\n",
      "Test MSE: 0.5856404304504395\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "MSELoss True True 1\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6597\n",
      "Epoch [2], Iter [91/100] Loss: 0.6206\n",
      "Epoch [3], Iter [91/100] Loss: 0.5924\n",
      "Epoch [4], Iter [91/100] Loss: 0.6222\n",
      "Epoch [5], Iter [91/100] Loss: 0.5690\n",
      "Epoch [6], Iter [91/100] Loss: 0.6043\n",
      "Epoch [7], Iter [91/100] Loss: 0.5613\n",
      "Epoch [8], Iter [91/100] Loss: 0.5723\n",
      "Epoch [9], Iter [91/100] Loss: 0.5391\n",
      "Epoch [10], Iter [91/100] Loss: 0.5312\n",
      "Epoch [11], Iter [91/100] Loss: 0.5286\n",
      "Epoch [12], Iter [91/100] Loss: 0.5345\n",
      "Epoch [13], Iter [91/100] Loss: 0.5225\n",
      "Epoch [14], Iter [91/100] Loss: 0.5167\n",
      "Epoch [15], Iter [91/100] Loss: 0.4774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Iter [91/100] Loss: 0.5306\n",
      "Epoch [17], Iter [91/100] Loss: 0.5111\n",
      "Epoch [18], Iter [91/100] Loss: 0.4890\n",
      "Epoch [19], Iter [91/100] Loss: 0.4641\n",
      "Epoch [20], Iter [91/100] Loss: 0.4502\n",
      "Epoch [21], Iter [91/100] Loss: 0.4768\n",
      "Test MSE: 0.5856525301933289\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "MSELoss True True 2\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6789\n",
      "Epoch [2], Iter [91/100] Loss: 0.6087\n",
      "Epoch [3], Iter [91/100] Loss: 0.6692\n",
      "Epoch [4], Iter [91/100] Loss: 0.5736\n",
      "Epoch [5], Iter [91/100] Loss: 0.5668\n",
      "Epoch [6], Iter [91/100] Loss: 0.5842\n",
      "Epoch [7], Iter [91/100] Loss: 0.5479\n",
      "Epoch [8], Iter [91/100] Loss: 0.5400\n",
      "Epoch [9], Iter [91/100] Loss: 0.5473\n",
      "Epoch [10], Iter [91/100] Loss: 0.5479\n",
      "Epoch [11], Iter [91/100] Loss: 0.5281\n",
      "Epoch [12], Iter [91/100] Loss: 0.5174\n",
      "Epoch [13], Iter [91/100] Loss: 0.5119\n",
      "Epoch [14], Iter [91/100] Loss: 0.4971\n",
      "Epoch [15], Iter [91/100] Loss: 0.4896\n",
      "Epoch [16], Iter [91/100] Loss: 0.5018\n",
      "Epoch [17], Iter [91/100] Loss: 0.4773\n",
      "Epoch [18], Iter [91/100] Loss: 0.4725\n",
      "Epoch [19], Iter [91/100] Loss: 0.4787\n",
      "Test MSE: 0.5821563005447388\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "AreaWeightedMSELoss False False 0\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6422\n",
      "Epoch [2], Iter [91/100] Loss: 0.6097\n",
      "Epoch [3], Iter [91/100] Loss: 0.6030\n",
      "Epoch [4], Iter [91/100] Loss: 0.5871\n",
      "Epoch [5], Iter [91/100] Loss: 0.5700\n",
      "Epoch [6], Iter [91/100] Loss: 0.5682\n",
      "Epoch [7], Iter [91/100] Loss: 0.5396\n",
      "Epoch [8], Iter [91/100] Loss: 0.5416\n",
      "Epoch [9], Iter [91/100] Loss: 0.5196\n",
      "Epoch [10], Iter [91/100] Loss: 0.5144\n",
      "Epoch [11], Iter [91/100] Loss: 0.4708\n",
      "Epoch [12], Iter [91/100] Loss: 0.4778\n",
      "Epoch [13], Iter [91/100] Loss: 0.4489\n",
      "Test MSE: 0.6013065576553345\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "AreaWeightedMSELoss False False 1\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6617\n",
      "Epoch [2], Iter [91/100] Loss: 0.5886\n",
      "Epoch [3], Iter [91/100] Loss: 0.5829\n",
      "Epoch [4], Iter [91/100] Loss: 0.5334\n",
      "Epoch [5], Iter [91/100] Loss: 0.5422\n",
      "Epoch [6], Iter [91/100] Loss: 0.5383\n",
      "Epoch [7], Iter [91/100] Loss: 0.5197\n",
      "Epoch [8], Iter [91/100] Loss: 0.4965\n",
      "Epoch [9], Iter [91/100] Loss: 0.5239\n",
      "Epoch [10], Iter [91/100] Loss: 0.4737\n",
      "Epoch [11], Iter [91/100] Loss: 0.4751\n",
      "Epoch [12], Iter [91/100] Loss: 0.4738\n",
      "Epoch [13], Iter [91/100] Loss: 0.4563\n",
      "Epoch [14], Iter [91/100] Loss: 0.4417\n",
      "Test MSE: 0.5895647406578064\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "AreaWeightedMSELoss False False 2\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6532\n",
      "Epoch [2], Iter [91/100] Loss: 0.5966\n",
      "Epoch [3], Iter [91/100] Loss: 0.5609\n",
      "Epoch [4], Iter [91/100] Loss: 0.5584\n",
      "Epoch [5], Iter [91/100] Loss: 0.5530\n",
      "Epoch [6], Iter [91/100] Loss: 0.5458\n",
      "Epoch [7], Iter [91/100] Loss: 0.5084\n",
      "Epoch [8], Iter [91/100] Loss: 0.6172\n",
      "Epoch [9], Iter [91/100] Loss: 0.4940\n",
      "Epoch [10], Iter [91/100] Loss: 0.4987\n",
      "Epoch [11], Iter [91/100] Loss: 0.5111\n",
      "Epoch [12], Iter [91/100] Loss: 0.4781\n",
      "Epoch [13], Iter [91/100] Loss: 0.4629\n",
      "Test MSE: 0.5894160866737366\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "AreaWeightedMSELoss False True 0\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6533\n",
      "Epoch [2], Iter [91/100] Loss: 0.6185\n",
      "Epoch [3], Iter [91/100] Loss: 0.5969\n",
      "Epoch [4], Iter [91/100] Loss: 0.5823\n",
      "Epoch [5], Iter [91/100] Loss: 0.5510\n",
      "Epoch [6], Iter [91/100] Loss: 0.5621\n",
      "Epoch [7], Iter [91/100] Loss: 0.5128\n",
      "Epoch [8], Iter [91/100] Loss: 0.4962\n",
      "Epoch [9], Iter [91/100] Loss: 0.5129\n",
      "Epoch [10], Iter [91/100] Loss: 0.4985\n",
      "Epoch [11], Iter [91/100] Loss: 0.4816\n",
      "Epoch [12], Iter [91/100] Loss: 0.4746\n",
      "Epoch [13], Iter [91/100] Loss: 0.4615\n",
      "Epoch [14], Iter [91/100] Loss: 0.4646\n",
      "Epoch [15], Iter [91/100] Loss: 0.4353\n",
      "Epoch [16], Iter [91/100] Loss: 0.4489\n",
      "Epoch [17], Iter [91/100] Loss: 0.4314\n",
      "Test MSE: 0.6024303436279297\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "AreaWeightedMSELoss False True 1\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6822\n",
      "Epoch [2], Iter [91/100] Loss: 0.6089\n",
      "Epoch [3], Iter [91/100] Loss: 0.5993\n",
      "Epoch [4], Iter [91/100] Loss: 0.5791\n",
      "Epoch [5], Iter [91/100] Loss: 0.6175\n",
      "Epoch [6], Iter [91/100] Loss: 0.5364\n",
      "Epoch [7], Iter [91/100] Loss: 0.5300\n",
      "Epoch [8], Iter [91/100] Loss: 0.5107\n",
      "Epoch [9], Iter [91/100] Loss: 0.5145\n",
      "Epoch [10], Iter [91/100] Loss: 0.4825\n",
      "Epoch [11], Iter [91/100] Loss: 0.4968\n",
      "Epoch [12], Iter [91/100] Loss: 0.4635\n",
      "Epoch [13], Iter [91/100] Loss: 0.4512\n",
      "Epoch [14], Iter [91/100] Loss: 0.4591\n",
      "Test MSE: 0.5858697295188904\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "AreaWeightedMSELoss False True 2\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6727\n",
      "Epoch [2], Iter [91/100] Loss: 0.6258\n",
      "Epoch [3], Iter [91/100] Loss: 0.6219\n",
      "Epoch [4], Iter [91/100] Loss: 0.6148\n",
      "Epoch [5], Iter [91/100] Loss: 0.5247\n",
      "Epoch [6], Iter [91/100] Loss: 0.5298\n",
      "Epoch [7], Iter [91/100] Loss: 0.6238\n",
      "Epoch [8], Iter [91/100] Loss: 0.5441\n",
      "Epoch [9], Iter [91/100] Loss: 0.5030\n",
      "Epoch [10], Iter [91/100] Loss: 0.4866\n",
      "Epoch [11], Iter [91/100] Loss: 0.4856\n",
      "Epoch [12], Iter [91/100] Loss: 0.4785\n",
      "Test MSE: 0.5907261967658997\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "AreaWeightedMSELoss True False 0\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6545\n",
      "Epoch [2], Iter [91/100] Loss: 0.6626\n",
      "Epoch [3], Iter [91/100] Loss: 0.6120\n",
      "Epoch [4], Iter [91/100] Loss: 0.5819\n",
      "Epoch [5], Iter [91/100] Loss: 0.5565\n",
      "Epoch [6], Iter [91/100] Loss: 0.5653\n",
      "Epoch [7], Iter [91/100] Loss: 0.5516\n",
      "Epoch [8], Iter [91/100] Loss: 0.5186\n",
      "Epoch [9], Iter [91/100] Loss: 0.5375\n",
      "Epoch [10], Iter [91/100] Loss: 0.4982\n",
      "Epoch [11], Iter [91/100] Loss: 0.5164\n",
      "Epoch [12], Iter [91/100] Loss: 0.5022\n",
      "Epoch [13], Iter [91/100] Loss: 0.5063\n",
      "Epoch [14], Iter [91/100] Loss: 0.4978\n",
      "Epoch [15], Iter [91/100] Loss: 0.4828\n",
      "Epoch [16], Iter [91/100] Loss: 0.4798\n",
      "Epoch [17], Iter [91/100] Loss: 0.4712\n",
      "Epoch [18], Iter [91/100] Loss: 0.4564\n",
      "Epoch [19], Iter [91/100] Loss: 0.4568\n",
      "Epoch [20], Iter [91/100] Loss: 0.4655\n",
      "Test MSE: 0.5880132913589478\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "AreaWeightedMSELoss True False 1\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6861\n",
      "Epoch [2], Iter [91/100] Loss: 0.6266\n",
      "Epoch [3], Iter [91/100] Loss: 0.6050\n",
      "Epoch [4], Iter [91/100] Loss: 0.6215\n",
      "Epoch [5], Iter [91/100] Loss: 0.5746\n",
      "Epoch [6], Iter [91/100] Loss: 0.5463\n",
      "Epoch [7], Iter [91/100] Loss: 0.5449\n",
      "Epoch [8], Iter [91/100] Loss: 0.5518\n",
      "Epoch [9], Iter [91/100] Loss: 0.5300\n",
      "Epoch [10], Iter [91/100] Loss: 0.5263\n",
      "Epoch [11], Iter [91/100] Loss: 0.5093\n",
      "Epoch [12], Iter [91/100] Loss: 0.4906\n",
      "Epoch [13], Iter [91/100] Loss: 0.4878\n",
      "Epoch [14], Iter [91/100] Loss: 0.4689\n",
      "Epoch [15], Iter [91/100] Loss: 0.4584\n",
      "Epoch [16], Iter [91/100] Loss: 0.4759\n",
      "Epoch [17], Iter [91/100] Loss: 0.4383\n",
      "Epoch [18], Iter [91/100] Loss: 0.4509\n",
      "Test MSE: 0.5852338671684265\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "AreaWeightedMSELoss True False 2\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6617\n",
      "Epoch [2], Iter [91/100] Loss: 0.6461\n",
      "Epoch [3], Iter [91/100] Loss: 0.6142\n",
      "Epoch [4], Iter [91/100] Loss: 0.5877\n",
      "Epoch [5], Iter [91/100] Loss: 0.6006\n",
      "Epoch [6], Iter [91/100] Loss: 0.5903\n",
      "Epoch [7], Iter [91/100] Loss: 0.5302\n",
      "Epoch [8], Iter [91/100] Loss: 0.5379\n",
      "Epoch [9], Iter [91/100] Loss: 0.5348\n",
      "Epoch [10], Iter [91/100] Loss: 0.5216\n",
      "Epoch [11], Iter [91/100] Loss: 0.5105\n",
      "Epoch [12], Iter [91/100] Loss: 0.5104\n",
      "Epoch [13], Iter [91/100] Loss: 0.4927\n",
      "Epoch [14], Iter [91/100] Loss: 0.4922\n",
      "Epoch [15], Iter [91/100] Loss: 0.5088\n",
      "Epoch [16], Iter [91/100] Loss: 0.4727\n",
      "Epoch [17], Iter [91/100] Loss: 0.4720\n",
      "Epoch [18], Iter [91/100] Loss: 0.4686\n",
      "Epoch [19], Iter [91/100] Loss: 0.4338\n",
      "Epoch [20], Iter [91/100] Loss: 0.4363\n",
      "Test MSE: 0.5825716257095337\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "AreaWeightedMSELoss True True 0\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6688\n",
      "Epoch [2], Iter [91/100] Loss: 0.6415\n",
      "Epoch [3], Iter [91/100] Loss: 0.6179\n",
      "Epoch [4], Iter [91/100] Loss: 0.5580\n",
      "Epoch [5], Iter [91/100] Loss: 0.6800\n",
      "Epoch [6], Iter [91/100] Loss: 0.5929\n",
      "Epoch [7], Iter [91/100] Loss: 0.5531\n",
      "Epoch [8], Iter [91/100] Loss: 0.5319\n",
      "Epoch [9], Iter [91/100] Loss: 0.5457\n",
      "Epoch [10], Iter [91/100] Loss: 0.5442\n",
      "Epoch [11], Iter [91/100] Loss: 0.5180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Iter [91/100] Loss: 0.5544\n",
      "Epoch [13], Iter [91/100] Loss: 0.4937\n",
      "Epoch [14], Iter [91/100] Loss: 0.4979\n",
      "Epoch [15], Iter [91/100] Loss: 0.5106\n",
      "Epoch [16], Iter [91/100] Loss: 0.4995\n",
      "Test MSE: 0.5715983510017395\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "AreaWeightedMSELoss True True 1\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6646\n",
      "Epoch [2], Iter [91/100] Loss: 0.6353\n",
      "Epoch [3], Iter [91/100] Loss: 0.6011\n",
      "Epoch [4], Iter [91/100] Loss: 0.6169\n",
      "Epoch [5], Iter [91/100] Loss: 0.5961\n",
      "Epoch [6], Iter [91/100] Loss: 0.5896\n",
      "Epoch [7], Iter [91/100] Loss: 0.5170\n",
      "Epoch [8], Iter [91/100] Loss: 0.5749\n",
      "Epoch [9], Iter [91/100] Loss: 0.5350\n",
      "Epoch [10], Iter [91/100] Loss: 0.5355\n",
      "Epoch [11], Iter [91/100] Loss: 0.5367\n",
      "Epoch [12], Iter [91/100] Loss: 0.5183\n",
      "Epoch [13], Iter [91/100] Loss: 0.5220\n",
      "Epoch [14], Iter [91/100] Loss: 0.4972\n",
      "Epoch [15], Iter [91/100] Loss: 0.5017\n",
      "Epoch [16], Iter [91/100] Loss: 0.4947\n",
      "Epoch [17], Iter [91/100] Loss: 0.4879\n",
      "Epoch [18], Iter [91/100] Loss: 0.4769\n",
      "Epoch [19], Iter [91/100] Loss: 0.4731\n",
      "Test MSE: 0.5769268274307251\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n",
      "AreaWeightedMSELoss True True 2\n",
      "Starting training\n",
      "Epoch [1], Iter [91/100] Loss: 0.6249\n",
      "Epoch [2], Iter [91/100] Loss: 0.5755\n",
      "Epoch [3], Iter [91/100] Loss: 0.5652\n",
      "Epoch [4], Iter [91/100] Loss: 0.5515\n",
      "Epoch [5], Iter [91/100] Loss: 0.5643\n",
      "Epoch [6], Iter [91/100] Loss: 0.5580\n",
      "Epoch [7], Iter [91/100] Loss: 0.5545\n",
      "Epoch [8], Iter [91/100] Loss: 0.5463\n",
      "Epoch [9], Iter [91/100] Loss: 0.5317\n",
      "Epoch [10], Iter [91/100] Loss: 0.5310\n",
      "Epoch [11], Iter [91/100] Loss: 0.5170\n",
      "Epoch [12], Iter [91/100] Loss: 0.5094\n",
      "Epoch [13], Iter [91/100] Loss: 0.5133\n",
      "Epoch [14], Iter [91/100] Loss: 0.4948\n",
      "Epoch [15], Iter [91/100] Loss: 0.4821\n",
      "Epoch [16], Iter [91/100] Loss: 0.4791\n",
      "Epoch [17], Iter [91/100] Loss: 0.4569\n",
      "Epoch [18], Iter [91/100] Loss: 0.4674\n",
      "Test MSE: 0.5805860161781311\n",
      "writing predictions\n",
      "writing descriptions\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for l in loss:\n",
    "    for c_conv in use_coord_conv:\n",
    "        for c_pad in use_cylindrical_padding:\n",
    "            for i in range(n_runs):\n",
    "                print(l, c_conv, c_pad, i)\n",
    "                model_training_description[\"USE_CYLINDRICAL_PADDING\"] = c_pad\n",
    "                model_training_description[\"USE_COORD_CONV\"] = c_conv\n",
    "                model_training_description[\"LOSS\"] = l  # \"MSELoss\" # \"AreaWeightedMSELoss\"\n",
    "                model_training_description[\"RUN_NR\"] = i\n",
    "                unet = train_unet(description, model_training_description, output_folder)\n",
    "                predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e757923",
   "metadata": {},
   "source": [
    "### 4.2.2 Comparing results for different architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf587d",
   "metadata": {},
   "source": [
    "We will need to implement the interpolation before we can reproduce the whole table. Until then: Only compare ico architectures on ico grid and flat architectures on flat grid.\n",
    "\n",
    "Results for modified and unmodified flat UNet are already obtained in last cell.(4.2.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad454efa",
   "metadata": {},
   "source": [
    "### Flat grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "974f0df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\", \n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eef2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"PCA_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = False\n",
    "# model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "model_training_description[\"N_PC_PREDICTORS\"] = 450\n",
    "model_training_description[\"N_PC_TARGETS\"] = 300\n",
    "model_training_description[\"REGTYPE\"] = \"lasso\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f45df65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions\n",
      "writing descriptions\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "pca, pca_targets, model = train_pca(description, model_training_description, output_folder)\n",
    "predict_save_pca(description, model_training_description, output_folder, pca, pca_targets, model, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdc721a",
   "metadata": {},
   "source": [
    "### Icosahedral grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74e59925",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\", \n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Ico\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "description[\"RESOLUTION\"] = 5\n",
    "description[\"INTERPOLATE_CORNERS\"] = True\n",
    "description[\"INTERPOLATION\"] = \"cons1\"\n",
    "\n",
    "description[\"TIMESCALE\"] = \"YEARLY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca80ed",
   "metadata": {},
   "source": [
    "Ico baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebe580f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"PCA_Ico\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = False\n",
    "# model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "model_training_description[\"N_PC_PREDICTORS\"] = 450\n",
    "model_training_description[\"N_PC_TARGETS\"] = 300\n",
    "model_training_description[\"REGTYPE\"] = \"lasso\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1780209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions\n",
      "writing descriptions\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "pca, pca_targets, model = train_pca(description, model_training_description, output_folder)\n",
    "predict_save_pca(description, model_training_description, output_folder, pca, pca_targets, model, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d98681c",
   "metadata": {},
   "source": [
    "Ico UNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ecbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Ico\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 5e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "model_training_description[\"LOSS\"] = \"MSELoss\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab785a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "for i in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = i\n",
    "    unet = train_unet(description, model_training_description, output_folder)\n",
    "    predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562f8305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96fea732",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = netCDF4.Dataset(\"Datasets/iHadCM3/Original/isotopes.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440289f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = np.array([1,2,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35ae8cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f45ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
