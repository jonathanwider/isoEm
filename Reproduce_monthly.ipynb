{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b39d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "from train import *\n",
    "from predict import *\n",
    "from evaluate import *\n",
    "from util import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ca94f",
   "metadata": {},
   "source": [
    "# Test monthly stuff from thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a7d2c4",
   "metadata": {},
   "source": [
    "## Create datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25699a6",
   "metadata": {},
   "source": [
    "All months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9104faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_monthly\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\", \n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "description[\"TIMESCALE\"] = \"MONTHLY\"\n",
    "description[\"MONTHS_USED\"] = np.sort([0,1,2,3,4,5,6,7,8,9,10,11]).tolist()\n",
    "description[\"MONTHS_USED_IN_PREDICTION\"] = np.sort([0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbfd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variables\n",
      "writing pickle\n"
     ]
    }
   ],
   "source": [
    "create_monthly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59152597",
   "metadata": {},
   "source": [
    "All months, use lagged months in predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_monthly\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\", \n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "description[\"TIMESCALE\"] = \"MONTHLY\"\n",
    "description[\"MONTHS_USED\"] = np.sort([0,1,2,3,4,5,6,7,8,9,10,11]).tolist()\n",
    "description[\"MONTHS_USED_IN_PREDICTION\"] = np.sort([0,-1]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_monthly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9269fa6",
   "metadata": {},
   "source": [
    "Individual dataset for each month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b8c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_monthly\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\", \n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "description[\"TIMESCALE\"] = \"MONTHLY\"\n",
    "description[\"MONTHS_USED_IN_PREDICTION\"] = np.sort([0]).tolist()\n",
    "\n",
    "for i in range(12):\n",
    "    description[\"MONTHS_USED\"] = np.sort([i]).tolist()\n",
    "    create_monthly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b7ddb1",
   "metadata": {},
   "source": [
    "# Run experiments on these datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a0f44",
   "metadata": {},
   "source": [
    "All months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeef675",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_monthly\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\", \n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "description[\"TIMESCALE\"] = \"MONTHLY\"\n",
    "description[\"MONTHS_USED\"] = np.sort([0,1,2,3,4,5,6,7,8,9,10,11]).tolist()\n",
    "description[\"MONTHS_USED_IN_PREDICTION\"] = np.sort([0]).tolist()\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 5e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 3\n",
    "for i in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = i\n",
    "    unet = train_unet(description, model_training_description, output_folder)\n",
    "    predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f49001",
   "metadata": {},
   "source": [
    "All months, use previous timestep in prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ea423",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Reproduce_monthly\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\",\n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"MONTHLY\"\n",
    "description[\"MONTHS_USED\"] = np.sort([0,1,2,3,4,5,6,7,8,9,10,11]).tolist()\n",
    "description[\"MONTHS_USED_IN_PREDICTION\"] = np.sort([0,-1]).tolist()\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\",\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 5e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 3\n",
    "for i in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = i\n",
    "    unet = train_unet(description, model_training_description, output_folder)\n",
    "    predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f9ed24",
   "metadata": {},
   "source": [
    "Individual models for different cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14faaf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_monthly\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"temp\",\n",
    "                                \"precip\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"temp\": [\"temp_1\"],\n",
    "                                      \"precip\": [\"precip\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"dO18\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"temp\", \n",
    "                                   \"precip\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 654\n",
    "description[\"END_YEAR\"] = 1654\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"TEST_FRACTION\"] = 0.1\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"MONTHLY\"\n",
    "description[\"MONTHS_USED_IN_PREDICTION\"] = np.sort([0]).tolist()\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 5e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5545de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 3\n",
    "for j in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = j\n",
    "    for i in range(12):\n",
    "        description[\"MONTHS_USED\"] = np.sort([i]).tolist()\n",
    "        unet = train_unet(description, model_training_description, output_folder)\n",
    "        predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
