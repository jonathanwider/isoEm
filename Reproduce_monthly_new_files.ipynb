{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734354f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "from train import *\n",
    "from predict import *\n",
    "from evaluate import *\n",
    "from util import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ed05f4",
   "metadata": {},
   "source": [
    "# Test monthly stuff from thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5771afb0",
   "metadata": {},
   "source": [
    "## Create datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce1deb",
   "metadata": {},
   "source": [
    "All months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f5af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_monthly\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "description[\"TIMESCALE\"] = \"MONTHLY\"\n",
    "description[\"MONTHS_USED\"] = np.sort([0,1,2,3,4,5,6,7,8,9,10,11]).tolist()\n",
    "description[\"MONTHS_USED_IN_PREDICTION\"] = np.sort([0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698616dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_monthly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a472a41",
   "metadata": {},
   "source": [
    "All months, use lagged months in predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7443bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_monthly\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "description[\"TIMESCALE\"] = \"MONTHLY\"\n",
    "description[\"MONTHS_USED\"] = np.sort([0,1,2,3,4,5,6,7,8,9,10,11]).tolist()\n",
    "description[\"MONTHS_USED_IN_PREDICTION\"] = np.sort([0,-1]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb355d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_monthly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde7093",
   "metadata": {},
   "source": [
    "Individual dataset for each month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_monthly\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "description[\"TIMESCALE\"] = \"MONTHLY\"\n",
    "description[\"MONTHS_USED_IN_PREDICTION\"] = np.sort([0]).tolist()\n",
    "\n",
    "for i in range(12):\n",
    "    description[\"MONTHS_USED\"] = np.sort([i]).tolist()\n",
    "    create_monthly_dataset(description, base_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1161e75b",
   "metadata": {},
   "source": [
    "# Run experiments on these datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575dddea",
   "metadata": {},
   "source": [
    "All months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d06c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_monthly\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\", \n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "description[\"TIMESCALE\"] = \"MONTHLY\"\n",
    "description[\"MONTHS_USED\"] = np.sort([0,1,2,3,4,5,6,7,8,9,10,11]).tolist()\n",
    "description[\"MONTHS_USED_IN_PREDICTION\"] = np.sort([0]).tolist()\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 5e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f34180",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 5\n",
    "for i in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = i\n",
    "    unet = train_unet(description, model_training_description, output_folder)\n",
    "    predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd8528",
   "metadata": {},
   "source": [
    "All months, use previous timestep in prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528da814",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_monthly\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\",\n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"MONTHLY\"\n",
    "description[\"MONTHS_USED\"] = np.sort([0,1,2,3,4,5,6,7,8,9,10,11]).tolist()\n",
    "description[\"MONTHS_USED_IN_PREDICTION\"] = np.sort([0,-1]).tolist()\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\",\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 5e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))*2\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b418b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 5\n",
    "for i in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = i\n",
    "    unet = train_unet(description, model_training_description, output_folder)\n",
    "    predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d605fc5",
   "metadata": {},
   "source": [
    "Individual models for different cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fab9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_monthly\"\n",
    "\n",
    "description = {}\n",
    "\n",
    "description[\"DATASETS_USED\"] = [\"isotopes\", \n",
    "                                \"tsurf\",\n",
    "                                \"prec\"]\n",
    "\n",
    "description[\"PREDICTOR_VARIABLES\"] = {\"tsurf\": [\"tsurf\"],\n",
    "                                      \"prec\": [\"prec\"]}\n",
    "\n",
    "description[\"TARGET_VARIABLES\"] = {\"isotopes\": [\"d18O\"]}\n",
    "\n",
    "description[\"DATASETS_NO_GAPS\"] = [\"isotopes\", \n",
    "                                   \"tsurf\", \n",
    "                                   \"prec\", \n",
    "                                   \"slp\"]\n",
    "\n",
    "description[\"CLIMATE_MODEL\"] = \"iHadCM3\"\n",
    "description[\"GRID_TYPE\"] = \"Flat\"\n",
    "\n",
    "description[\"START_YEAR\"] = 850\n",
    "description[\"END_YEAR\"] = 1850\n",
    "description[\"LATITUDES_SLICE\"] = [1,-1]\n",
    "\n",
    "description[\"SPLIT_YEAR\"] = 1750\n",
    "description[\"DO_SHUFFLE\"] = False\n",
    "description[\"PRECIP_WEIGHTING\"] = False\n",
    "\n",
    "\n",
    "description[\"TIMESCALE\"] = \"MONTHLY\"\n",
    "description[\"MONTHS_USED_IN_PREDICTION\"] = np.sort([0]).tolist()\n",
    "\n",
    "### MODEL_TRAINING ###############################################\n",
    "\n",
    "model_training_description = {}\n",
    "model_training_description[\"S_MODE_PREDICTORS\"] = [\"Pixelwise\",\"Pixelwise\"] # how to standardize the given variables\n",
    "model_training_description[\"S_MODE_TARGETS\"] = [\"Pixelwise\"]\n",
    "\n",
    "model_training_description[\"DATASET_FOLDER\"] = output_folder\n",
    "\n",
    "model_training_description[\"MODEL_TYPE\"] = \"UNet_Flat\"\n",
    "model_training_description[\"CREATE_VALIDATIONSET\"] = True\n",
    "model_training_description[\"SHUFFLE_VALIDATIONSET\"] = True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"NUM_EPOCHS\"] = \"early_stopping\"  # 20\n",
    "model_training_description[\"PATIENCE\"] = 5\n",
    "model_training_description[\"BATCH_SIZE\"] = 8\n",
    "model_training_description[\"LEARNING_RATE\"] = 5e-3  # 0.002637 # 5e-3  # use either this or default ADAM learning rate\n",
    "\n",
    "# model parameters\n",
    "model_training_description[\"DEPTH\"] = 3\n",
    "model_training_description[\"IN_CHANNELS\"] = len(util.flatten(description[\"PREDICTOR_VARIABLES\"].values()))\n",
    "model_training_description[\"CHANNELS_FIRST_CONV\"] = 32\n",
    "model_training_description[\"OUT_CHANNELS\"] = len(util.flatten(description[\"TARGET_VARIABLES\"].values()))\n",
    "model_training_description[\"FMAPS\"] = (32,32,64,64)\n",
    "\n",
    "\n",
    "model_training_description[\"ACTIVATION\"] = torch.nn.ReLU\n",
    "model_training_description[\"NORMALIZATION\"] = torch.nn.BatchNorm2d  # IcoBatchNorm2d \n",
    "\n",
    "\n",
    "model_training_description[\"OPTIMIZER\"] = \"Adam\"\n",
    "\n",
    "model_training_description[\"DEVICE\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_training_description[\"USE_CYLINDRICAL_PADDING\"] = True\n",
    "model_training_description[\"USE_COORD_CONV\"] = True\n",
    "model_training_description[\"LOSS\"] = \"Masked_AreaWeightedMSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a7011",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 5\n",
    "for j in range(n_runs):\n",
    "    model_training_description[\"RUN_NR\"] = j\n",
    "    for i in range(12):\n",
    "        description[\"MONTHS_USED\"] = np.sort([i]).tolist()\n",
    "        unet = train_unet(description, model_training_description, output_folder)\n",
    "        predict_save_unet(description, model_training_description, output_folder, unet, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f2e6a",
   "metadata": {},
   "source": [
    "# Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323b9843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_folder = \"Datasets\"\n",
    "output_folder = \"Output/Reproduce_monthly\"\n",
    "\n",
    "c_all = {\n",
    "    \"DATASET_DESCRIPTION\": {'MONTHS_USED': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "                            'MONTHS_USED_IN_PREDICTION': [0]},\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {}\n",
    "}\n",
    "\n",
    "descriptions, predictions, gt, masks = load_data_for_comparison(output_folder, c_all, do_split=True)\n",
    "\n",
    "c_all_use_p = {\n",
    "    \"DATASET_DESCRIPTION\": {'MONTHS_USED': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "                            'MONTHS_USED_IN_PREDICTION': [-1, 0]},\n",
    "    \"MODEL_TRAINING_DESCRIPTION\": {}\n",
    "}\n",
    "\n",
    "descriptions_p, predictions_p, gt_p, masks_p = load_data_for_comparison(output_folder, c_all_use_p, do_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_single = []\n",
    "\n",
    "for i in range(12):\n",
    "    r2_single.append([])\n",
    "    c_single = {\n",
    "        \"DATASET_DESCRIPTION\": {'MONTHS_USED': [i],\n",
    "                                'MONTHS_USED_IN_PREDICTION': [0]},\n",
    "        \"MODEL_TRAINING_DESCRIPTION\": {}\n",
    "    }\n",
    "    descriptions_s, predictions_s, gt_s, masks_s = load_data_for_comparison(output_folder, c_single, do_split=True)\n",
    "    for j in range(3):\n",
    "        r2 = get_r2(predictions_s[j][i], gt_s[j][i], masks_s[j][i])\n",
    "        r2_single[-1].append(get_weighted_average(r2, descriptions[j][\"DATASET_DESCRIPTION\"])[0])\n",
    "        \n",
    "r2_single = np.mean(np.array(r2_single),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be339ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_all = []\n",
    "r2_all_use_p = []\n",
    "\n",
    "for j in range(3):\n",
    "    r2_all.append([])\n",
    "    r2_all_use_p.append([])\n",
    "    for i in range(12):\n",
    "        r2 = get_r2(predictions[j][i], gt[j][i], masks[j][i])\n",
    "        r2_p = get_r2(predictions_p[j][i], gt_p[j][i], masks_p[j][i])\n",
    "        r2_all[-1].append(get_weighted_average(r2, descriptions[j][\"DATASET_DESCRIPTION\"])[0])\n",
    "        r2_all_use_p[-1].append(get_weighted_average(r2_p, descriptions_p[j][\"DATASET_DESCRIPTION\"])[0])\n",
    "        \n",
    "r2_all = np.mean(np.array(r2_all),axis=0)\n",
    "r2_all_use_p = np.mean(np.array(r2_all_use_p),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1264aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(r2_all, label=\"UNet, all\")\n",
    "plt.plot(r2_all_use_p, label=\"UNet, all, use previous month\")\n",
    "plt.plot(r2_single, label=\"UNet, single\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('GrouPyTorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "90b409070de10f2c3c5a8c504ecede612c695480a2027d21529fbe1a33a534d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
